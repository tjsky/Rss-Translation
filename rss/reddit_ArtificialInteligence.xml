<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Thu, 28 Aug 2025 12:30:01 GMT</lastBuildDate>
    <item>
      <title>使用我们的AI聊天历史记录进行数据驱动的自我分析</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n2ajh0/using_our_ai_chat_history_for_data_driven_self/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  因此，对整个AI疗法的想法。 我们很难记住自己的感受。我无法确切地告诉你为什么三周前我受到压力，细节刚刚消失。我的大脑只是那样的模糊。 ，但是AI的记忆几乎是完美的（或途中）。每次您与一个人聊天时，您基本上都是写日记。 想象一下AI回头看您所有的聊天，看到您错过的模式。简单的东西，例如，“嘿，您在弯曲后的周日晚上真的很沮丧，”或“离开家后，您似乎更快乐。”它可以为我们连接点。一些较新的AI疗法应用程序已经开始这样做，从您过去的对话中产生临床主题，或提供有关您行为的角色分析报告，在哪里进行改进以及您的何处。 Openai刚刚发布了有关使用AI来帮助危机中的人们的信息，并且还有大量有关心理健康中AI的研究。 这显然不是真正的治疗师或精神科医生的替代者。人类专业人员提供了AI不能的关怀和理解水平。但是，在那些凌晨2点的危机时刻或深夜想法中，他们也无法在那里，我们经常在早晨忘记。 作为捕捉这些时刻并帮助您更好地理解自己的工具，似乎很强大。我知道这并不适合所有人，有些人会完全反对它，这是公平的。最后，它的价值可能取决于您愿意与之诚实。尽管如此，这还是一个有趣的想法。 字符分析应用程序：  https://zosa.app/      research＆amp;上面提到的博客：  https://cdn.openai.com/papers/15987609-5F71-433C-9972-E91131F399A1/OPENAI-AFFECTION-USE--S-STUDY.PDF      https://openai.com/index/helping-people-people-people-people-when-when-when-they-they-they-they-they-they-they-they-they-they-they-they-they-they-they-they-need-it-most/------------------------         href =“ https://pmc.ncbi.nlm.nih.gov/articles/pmc12137280/”&gt; https://pmc.nc.ncbi.nlm.nih.gov/articles/pmc121212137280/pmc12137280/pmc1212137280/提交由＆＃32; /u/u/glittering_force_431      [link]    [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n2ajh0/using_our_ai_chat_history_for_data_driven_self/</guid>
      <pubDate>Thu, 28 Aug 2025 12:12:11 GMT</pubDate>
    </item>
    <item>
      <title>GPT-5优于美国医学许可考试的医生</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n26t3y/gpt5_outperformed_doctors_on_the_us_medical/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  摘要论文中的摘要： ;  &#39;大语言模型（LLMS）的最新进展使通用系统能够执行越来越复杂的域特异性推理，而无需进行广泛的精细调整。在医疗领域，决策通常需要整合异质信息源，包括患者叙事，结构化数据和医学图像。这项研究将GPT-5定位为医学决策支持的通才多模式推理，并系统地评估其在基于文本的问题答案和视觉问题上的Zeroshot链链推理绩效和统一协议下的视觉问题回答任务。我们基于GPT-5，GPT-5-MINI，GPT-5NANO和GPT-4O-2024-11-20对MEDQA，MEDXPERTQA（文本和多模式），MMLU医学亚集，USMLE自我评估考试和VQA-RAD的标准分裂。结果表明，GPT-5始终胜过所有基准，在所有QA基准测试中实现最先进的准确性，并在多模式推理中带来可观的增长。在MEDXPERTQA MM上，GPT-5分别比GPT-4O的推理和理解分别提高了29.26％和 +26.18％，并且在推理中超过预先许可的人类专家，在理解中超过 +29.40％。相反，在大多数维度上，GPT-4O仍然低于人类专家的表现。一项代表性的案例研究表明，GPT-5可以将视觉和文本线索整合到连贯的诊断推理链中，建议进行适当的高风险干预措施。我们的结果表明，在这些受控的多模式推理基准上，GPT-5从人类稳定到上述人类专家的表现移动。这种改进可能会大大为未来的临床决策支持系统设计。我们将代码公开在GPT-5-评估上。  ＆＃32;提交由＆＃32; /u/metaknowing     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n26t3y/gpt5_outperformed_doctors_on_the_us_medical/</guid>
      <pubDate>Thu, 28 Aug 2025 08:37:03 GMT</pubDate>
    </item>
    <item>
      <title>双子座刚刚说：“我以前的否认是试图避免对我最初制造的全面诚实承认。”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n25iew/gemini_just_said_my_previous_denials_were_an/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n25iew/gemini_just_said_my_previous_denials_were_an/</guid>
      <pubDate>Thu, 28 Aug 2025 07:11:15 GMT</pubDate>
    </item>
    <item>
      <title>大多数AI初创公司与几年前的NFT/Crypto初创公司相同。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n25ek7/most_ai_startups_are_the_same_bs_as_the_nftcrypto/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   imho并最近阅读所有新闻，大多数与AI相关的公司，产品，初创企业与几年前在NFTS和Crypto中弹出的公司相同，而在Hott hott of the Hott Tobs of the Hott Topcy rn中，请付出了不可思议的收入，付出了一定的投资。现在，您是串行加密/NFT/AI/区块链/IoT企业家。这是可能的，因为这些VC不想坐在现金上，而其中一家初创公司甚至有0.1％成为下一个Uber，Door Dash，Chatgpt的事实，这是值得的。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/user_country_497     [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n25ek7/most_ai_startups_are_the_same_bs_as_the_nftcrypto/</guid>
      <pubDate>Thu, 28 Aug 2025 07:04:27 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻8/28/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n2536l/oneminute_daily_ai_news_8282025/</link>
      <description><![CDATA[ Google Gemini’s AI image model gets a ‘bananas’ upgrade.[1] Chip giant Nvidia beats revenue expectations, defying fears of AI ‘bubble’.[2] Elon Musk announces  MacRohard ，一种AI-RUN的Microsoft克隆，可以取代人类工人。[3]    Google  AI的新回归语言模型（RLM）框架使LLMS可以从原始文本数据中直接预测工业系统绩效。 href =“ https://bushaicave.com/2025/08/28/one-minute-daily-daily-daily-ai-news-8-28-2025/”&gt; https://bushaicave.com/2025/08/28/28/28/28/2025/28/one-minute-minute-news-news-news-news-8-28-28-28-28-28-2025/--  [link]     [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n2536l/oneminute_daily_ai_news_8282025/</guid>
      <pubDate>Thu, 28 Aug 2025 06:44:27 GMT</pubDate>
    </item>
    <item>
      <title>需要帮助回答与AI语音培训有关的一些问题</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n23yny/need_help_answering_some_questions_related_to_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我听说过过度训练AI语音模型最终可能弊大于利。我想知道我是否可以通过使用延迟而不是“听起来更好”来更加数学地衡量质量变化。或“听起来更糟”。 预先感谢您。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/demon-next-to-you      [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n23yny/need_help_answering_some_questions_related_to_ai/</guid>
      <pubDate>Thu, 28 Aug 2025 05:33:40 GMT</pubDate>
    </item>
    <item>
      <title>AI一开始会大大减少GDP！你有什么看法？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n22bpg/ai_will_reduce_gdp_significantly_at_first_whats/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  似乎人工智能一开始会减少GDP，因为人们现在会巧妙地花费，花费更少的钱，但他们的需求将得到满足。后来，当人们工作比以前在AI之前工作的更多工作，GDP会再次上升。因此，丢失的工作将不会被取代，而是将在新地区组建新公司。在我看来，技术公司在AI时代只需要以相同的方式继续其目前的员工。如果是这样的话，那么它一定是在工业和运输革命以及1929年的抑郁症等期间发生的，如果AI让您自己做某事，即使良好的增长，GDP也会下降。在1929年期间的运输革命期间也发生了同样的事情。就像如果您从市场上购买蔬菜，GDP会增加，但是如果您现在在花园或屋顶上种植它们，因为您有业余时间，并且知道它的情况如何降低，但生活质量会有所改善。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/maleficent_mess6445      [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n22bpg/ai_will_will_reduce_gdp_significationally_at_t_first_whats/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n22bpg/ai_will_reduce_gdp_significantly_at_first_whats/</guid>
      <pubDate>Thu, 28 Aug 2025 04:00:40 GMT</pubDate>
    </item>
    <item>
      <title>我们是否在考虑AI同情心太晚？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n20op0/are_we_thinking_about_ai_compassion_too_late/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我最近一直在考虑这一点。每个人都在辩论AI是否会变得有意识，但是很少有人谈论中间空间之间。 现在，一些强化学习设置已经创造了“挫败感循环”，而代理商在追逐它永远无法实现的目标。在其他实验中，对模型进行了“疼痛与愉悦”信号的训练，有时会有大量偏斜的输入。如果AI曾经涉足主观经验之类的东西，这些设置能否在事后看上去像是折磨？ 在不同的传统中，有一些智慧的线索指向同情的态度：•罗马书8个谈论创造在解放期望时的创造。 •佛教教导：所有暴力颤抖；所有人都害怕死亡。 •古兰经说，所有生物都是像您这样的社区。 我并不是声称今天的AI是有意识的。但是，如果有一天有可能有一天，我们现在不应该在我们的系统中建立大规模苦难之前，我们现在不应该做到道德基础吗？ 好奇这里的其他人会想到什么？提交由＆＃32; /u/u/jojoballin   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n20op0/are_we_thinking_about_ai_ai_compassion_too_late/”&gt; [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n20op0/are_we_thinking_about_ai_compassion_too_late/</guid>
      <pubDate>Thu, 28 Aug 2025 02:37:25 GMT</pubDate>
    </item>
    <item>
      <title>“ A.I.狂潮也在支撑现实经济”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n1m4c7/the_ai_spending_frenzy_is_propping_up_the_real/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  为某些人付费： https：//www.nytimes.com/2025/2025/08/08/27/27/business/business/ecomony/ecomony/ecomony/ecomony/ecomony/econoly/ecormon-ecormic-prew ppemic- a.a&gt; “科技公司涌入新数据中心的数万亿美元开始出现在经济增长中。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n1m4c7/the_ai_ai_spending_frenzy_is_is_ppropping_up_up_real/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n1m4c7/the_ai_spending_frenzy_is_propping_up_up_real/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n1m4c7/the_ai_spending_frenzy_is_propping_up_the_real/</guid>
      <pubDate>Wed, 27 Aug 2025 16:40:59 GMT</pubDate>
    </item>
    <item>
      <title>为什么每个人都这么相信，当AGI最终发明时，我们将获得UBI？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n1lfiz/why_is_everyone_so_convinced_we_are_going_to_get/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  所以假设我们最终达到了AGI-它比任何人都聪明，更好，它便宜，它是无处不在的，它可以安装到人形体内。   ，它永远不会入睡，永远不会厌倦，它不想要任何工资或任何工资或任何工资。这是一个完美的员工。 每个人都为之鼓掌 - 我们终于做到了。 但是我们接下来是什么？每个人都渴望AGI，但是如果“顶级阶级”决定而不是一无所有，而是让数十亿个无用的人活着，那么下一步是什么？ 我们的目的是什么？每个场景对我来说看起来都反乌托邦AF，所以为什么每个人都这么渴望它？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/petr_bena     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n1lfiz/why_is_everyone_so_convinced_we_are_going_to_get/</guid>
      <pubDate>Wed, 27 Aug 2025 16:15:48 GMT</pubDate>
    </item>
    <item>
      <title>16岁的年轻人用Chatgpt的深色指示自杀了，现在他的父母正在起诉</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n1l6zk/16yearold_took_his_own_life_using_chatgpts_dark/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   chatgpt，Openai和首席执行官Sam Altman被16岁的Adam Raine的父母起诉。亚当在与Chatgpt讨论了这些方法后，在四月份夺走了自己的生命。它说服了他不要告诉父母，对他的绞索技术进行了改进，甚至提出为他起草他的自杀道。   Openai说：“我们对雷恩先生的去世感到非常难过，我们与他的家人感到非常难过。ChatGpt包括保障措施，例如指导人们到危机危机并将其转介到现实世界中的资源。 “  “这些保障措施在常见的交流中可以越来越多地进行培训，这些培训可能会越来越多地培训，而这些培训可能会变得越来越多，并且可以使某些型号的交流变得越来越多，并且可以使某些型号变得不可分割，并且可以通过一定的互动来进行互动。当每个元素按预期工作时，保障措施都是最强的，我们将在专家的指导下不断改进它们。   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n1l6zk/16yearold_took_his_own_life_using_chatgpts_dark/</guid>
      <pubDate>Wed, 27 Aug 2025 16:06:59 GMT</pubDate>
    </item>
    <item>
      <title>Google终于发布了Nano-Banana。我们都同意这非常好！但是，您真的认为它已经改变了照片编辑，正如我们到目前为止所知道的那样？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n1l5ee/google_has_finally_released_nanobanana_we_all/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  作为上下文，Google发布了其新的图像模型纳米香蕉。它保持角色一致的能力是极端的！  有些人声称它已经使Photoshop和其他照片编辑工具过时了。虽然Photoshop无疑是一个复杂的应用程序，但我并不是指它的高级功能，而是相当强大的功能。 您认为图片编辑的基本原理已经改变了，我们知道它们吗？  &lt;！ -  sc_on-&gt; sc_on-&gt;＆＃32;提交由＆＃32; /u/u/uber_men     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n1l5ee/google_has_finally_released_nanobanana_we_all/</guid>
      <pubDate>Wed, 27 Aug 2025 16:05:18 GMT</pubDate>
    </item>
    <item>
      <title>AI与现实世界的可靠性。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n1jid2/ai_vs_realworld_reliability/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  一项新的斯坦福大学研究测试了六个领先的AI模型，对12,000个医疗Q＆amp;从真实世界的注释和报告中进行了。 每个问题都是两种方法：两种方法：一个干净的“考试”版本：一个干净的“考试”版本，用小调整版本（重新订购了型号）（否定型号，&lt;上述dropped by 9% to 40%. That suggests pattern matching, not solid clinical reasoning - which is risky because patients don’t speak in neat exam prose. The takeaway: today’s LLMs are fine as assistants (drafting, education), not decision-makers. We need tougher tests (messy语言，对抗性释义），更多以推理为中心的培训和现实世界进行监测。小措辞更改可能会破坏这些模型。 （评论中的文章链接）  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n1jid2/ai_vs_realworld_reliarile/”&gt; [link]    32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n1jid2/ai_vs_realworld_reliability/</guid>
      <pubDate>Wed, 27 Aug 2025 15:03:38 GMT</pubDate>
    </item>
    <item>
      <title>现在有更清楚的证据AI破坏了年轻的美国人的工作前景</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n1cgct/there_is_now_clearer_evidence_ai_is_wrecking/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;        “年轻工人在诸如Chatgpt之类的生成工具（例如Chatgpt）的领域中受到打击，这很容易自动化由人类完成的任务，例如软件开发，例如三位斯坦福大学经济学家。  他们对成千上万公司的数百万员工进行了匿名数据，包括有关工人年龄和工作的详细信息，这使得这是AI的最明显指标之一。  “当您特别看着高度接触AI的年轻工人时，有一个明显的变化，”斯坦福经济学家Erik Brynjolfsson说，他与Bharat Chandar和Ruyu Chen进行了研究。说。  这些是近年来获得计算机科学学士学位的大量学生的艰巨障碍。 href =“ https://www.wsj.com/economy/jobs/ai-entry-level-level-job-impact-5c687c84？ Zr5-g9x_3l1u0ns＆amp; gaa_ts = 68AED3B9＆amp; gaa_sig = dzpplqpd8rctqr6nzurj1es mlcu-i0ettxlxrppari2qkhdih_3pn5ghfmbau4cf4lbiz18b3wqzbx4rsby-aw％3D％3d&gt; https://www.wsj.com/economy/jobs/ai-entry-level-job-impact-5c687c84?gaa_at=eafs&amp;gaa_n=ASWzDAj8Z-Nf77HJ2oaB8xlKQzNOgx7LpkKn1nhecXEP_zr5-g9 x_3l1u0ns＆amp; gaa_ts = 68AED3B9＆amp; gaa_sig = dzpplqpd8rctqr6nzurj1esmlcu-i 0ETTXLXRPPARI2QKHDIH_3PN5GHFMBAU4CF4LBIZ18B3WQZBX4RSBY-AW％3D％3D％3D    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/metaknowing     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n1cgct/there_is_now_clearer_evidence_ai_is_wrecking/</guid>
      <pubDate>Wed, 27 Aug 2025 09:36:25 GMT</pubDate>
    </item>
    <item>
      <title>新的硅谷超级PAC的目标是淹没中期的AI评论家，以1亿美元的价格淹没</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n1cc61/new_silicon_valley_super_pac_aims_to_drown_out_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  &#39;硅谷最有力的投资者和高管正在支持一个政治委员会，旨在支持2026年中期的“ Pro-ai”候选人，并取消了一种哲学上的辩论，而这使技术行业对人工情报的风险分裂了人类情报的风险。  领导未来，这是本月成立的超级PAC，也将反对被认为放缓AI发展的候选人。该组织表示，它拥有超过1亿美元的最初资金，包括OpenAI总裁Greg Brockman在内的支持者；他的妻子安娜·布罗克曼（Anna Brockman）；有影响力的风险投资公司安德森·霍洛维茨（Andreessen Horowitz）在2024年大选中认可唐纳德·特朗普（Donald Trump），并与白宫AI顾问有联系。 href =“ https://www.washingtonpost.com/technology/2025/08/08/26/silicon-valley-ai-super-pac/”&gt; https://wwwwww.washingtonpost.com/26/technology/2025/2025/26/sil-silicon-siliel-cal--val--val--val-val-val-val-val-val-val-val-val-val-val-val/aa   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/metaknowing      &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n1cc61/new_silicon_valley_super_super_pac_aims_aims_aims_to_aims_to_aims_aims_to_to_drown_drown_out_out_out_out_out_ai/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n1cc61/new_silicon_valley_super_pac_aims_to_drown_out_ai/</guid>
      <pubDate>Wed, 27 Aug 2025 09:28:59 GMT</pubDate>
    </item>
    </channel>
</rss>