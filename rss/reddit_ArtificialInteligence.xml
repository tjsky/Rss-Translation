<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Fri, 29 Aug 2025 06:22:33 GMT</lastBuildDate>
    <item>
      <title>如果我使用AI来娱乐，还是我的不负责任是可以的吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n2zph9/is_it_ok_if_i_use_ai_for_fun_or_am_i_being_very/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我听说AI可能对环境有害，所以我想知道它是否非常不负责任地使用它来娱乐还是没有？每次使用它时，我都会感到内。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/aggression-show4122     &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1N2ZPH9/IS_IT_IT_IF_IF_IIF_IE_IE_IE_FOR_FOR_FUN_FUN_FUN_FUN_FUN_FUN_EM_IM_IE_BEING_BEING_VERY_VERY_VERY/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n2zph9/is_it_ok_if_i_use_ai_for_fun_or_am_i_being_very/</guid>
      <pubDate>Fri, 29 Aug 2025 06:13:11 GMT</pubDate>
    </item>
    <item>
      <title>是否应该有一个定义的科学学科，重点是AI的环境足迹，特别是对于数据中心和发电的水支出？ 。我很好奇社区是否认为这需要机构关注。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n2z6i7/should_there_be_a_defined_scientific_discipline/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  最近在与AI无关的领域开始在STEM上工作，而是被允许使用它，这会导致其流行性包含在您的项目中。我知道AI使用了很多淡水资源，但是在考虑了一个淡水资源之后，并且看到了大多数领域的AI和环境稳定性如何成为超级时尚的研究方向。通过STEM/研究行业的工作方式，我假设很多人正在研究减少数据中心水支出的问题。我知道这是一个热力学问题，但该死的我会认为这有很多赠款，尤其是在鼓励像德国这样可持续技术的国家。我不知道这是一个有趣的想法，而且我相对不太彻底的研究，我所看到的只是像每个双子座搜索一样需要0.29毫升或更多的厄运思考，而不是解决问题。 AI不会去任何地方，科学家担心气候变化，因此肯定有一些实验室甚至RND团队或研究所致力于研究和解决这个问题。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/duelpoke10     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n2z6i7/should_there_be_a_defined_scientific_discipline/</guid>
      <pubDate>Fri, 29 Aug 2025 05:41:10 GMT</pubDate>
    </item>
    <item>
      <title>不道德的快捷方式。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n2z4sy/un_raccourci_immoral/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我认为我们应该更多地研究AI的镜子如何反映人类想要的东西，即在试图控制和操纵时控制。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/longjumpscene7310      ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n2z4sy/un_raccourci_immoral/</guid>
      <pubDate>Fri, 29 Aug 2025 05:38:19 GMT</pubDate>
    </item>
    <item>
      <title>知道人工智能的人将大大取代那些没有的人</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n2wjjw/people_that_know_ai_will_massively_replace_those/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  似乎有些人主张知道AI的人将大大取代那些不在未来的就业市场上的人。但是，这真的如何区分？谁不能只是学会命令AI或编写提示？不应用AI每个人都可以做的事情吗？这就是AI的目的，即使是新手也可以应用 - 对吧？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n2wjjw/people_that_knoke_ai_ai_ai_will_massiver_massiver_replace_those/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n2wjjw/people_that_know_ai_will_massively_replace_those/</guid>
      <pubDate>Fri, 29 Aug 2025 03:15:31 GMT</pubDate>
    </item>
    <item>
      <title>Elizaos的Shawmakesmagic正在起诉Twitter/X</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n2u3ix/shawmakesmagic_of_elizaos_is_suing_twitterx/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    shawmakesmagic，建立Eliza Labs的人是AI助手的快速构建工具包，他起诉Twitter/X，因为他们开始向他的组织提供更多的HQ，因为他听到了Elizaos的宣布之后，他们就访问了HQ，以示为Elizaos。   -----  昨天，Eliza Labs对X。  X提起诉讼。随着有效的加速主义运动的启动，我加入了正确的行列，最终我搬到了旧金山，并遇到了我认识的一些最酷的人。这是我的社交网络。 当埃隆（Elon）购买X时，我真的很兴奋。我去了Xai Hackathons，在社交活动中认识了他们的团队。我是典范的技术兄弟乐观主义者E/ACC类型，他会重新播放每个主要的SpaceX胜利，并庆祝言论自由回到X。我把钱放到了我的嘴里，我把这个故事带到了X带Eliza。 我现在以Exile In Exile。他们看到伊丽莎（Eliza）广泛采用后，他们伸出援手，想更好地理解代理空间。作为一个自由自由以来就建立在API上的人，我为合作以合作以一起推动AI代理而做好了准备。 ，但有些事情发生了变化。协作语调转为交易，就像X启动ANI和Grok的新版本一样。突然，他们要求我们每月支付50,000美元的企业许可（每年60万美元）或面临法律诉讼。我们已经通过各种许可证和费用每年向他们支付超过20,000美元的费用。但更重要的是，我们是一个开源项目。我们什么都没卖。我们免费提供技术，以便任何人都可以构建自主的AI代理。 然后，我只能将其描述为最大提取的几个月。他们要求详细的技术文档，访问我们的框架，使用数字，每个端点的说明和实现细节。他们在向我们抽取有关我们AI代理的工作信息的同时，悬而未决地恢复了帐户的可能性。我们遵守了一切，相信我们正在解决误解。 ，然后他们使我们陷入困境。我们一周又一周跟进。他们决定，他们没有完全做出任何决定，而是在伤害我们的业务并获得自己的产品的市场份额时会拖延。 现在，我们别无选择。 X和XAI在某种程度上意识到这一点 - 他们只是提起诉讼，指控Apple和Openai对X对我们所做的相同的反竞争行为。 感谢您与我们站在一起。我知道，如果没有沟通，这是很难的。我们试图不出于尊重X而公开公开。如果您认识我，您知道我很开放，我只想告诉所有人到底发生了什么。但是在这种情况下，我们不想给予他们的法律团队理由与我们质疑。 我很难过，我们必须以艰难的方式做到这一点。但是，我们不能接受一个可以被偷窃创新的世界，而创新者则被拥有权力的人所沉默。  代码保持免费。愿景保持不变。我们不会去任何地方。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/vengeful_bunny     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n2u3ix/shawmakesmagic_of_elizaos_is_suing_twitterx/</guid>
      <pubDate>Fri, 29 Aug 2025 01:18:29 GMT</pubDate>
    </item>
    <item>
      <title>[研究]：映射到人类心理因素的代理AI失败模式的87.5％（CPF与Microsoft Airt分类法）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n2s7bo/research_875_of_agentic_ai_failure_modes_mapped/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我们的最新研究附录验证了针对微软的AI红色团队（AIRT）2025代理AI AI失败模式的分类学分类学的网络安全心理学框架（CPF）。   的关键发现： cpf preds posterifitive the Priptive the 21/fivell 2 21/fivestry copplitionalsive and copplitive and copplitionalsive and copplitive and 2 21/ Microsoft确定的故障模式。  这表明对于代理AI系统，人类的心理因素（而不是技术限制）是主要脆弱性。该研究提供了从技术故障模式到心理根源的直接映射：   代理妥协＆amp;注射：映射到无意识的转移和集体思维，用户可以在其中进行信任和旁路验证。  记忆中毒：利用认知超负荷以及无法区分学习和注入的信息。    多&gt;   Multi-Agagent comply&gt;    phenomena. Organizational Knowledge Loss: Linked to affective vulnerabilities like attachment to legacy systems and flight response avoidance.  Implications for the Field:  Predictive Assessment: This approach allows for the prediction of vulnerabilities based on system design and user interaction models, moving beyond reactive安全。  新颖的攻击媒介：持续记忆和多代理协调创建针对人类系统互动点的新的攻击类别。    框架验证：高覆盖速率与大型AI播放器的经验分类范围  链接：    阅读GitHub上的完整论文：https://github.com/xbeat/CPF/blob/main/emerging-threats-cpf/2025-agentic-ai-systems/ 网络安全心理学框架（CPF）： https://cpf3.org      我在这里分享这一点，以从社区中获得反馈，并观察其他人在这些系统中是否可以自动地在这些系统中自动地进行自定义的工作。您对AI安全性人为因素的优先级有何看法？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/kaolay     [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n2s7bo/research_875_of_agentic_ai_failure_modes_mapped/</guid>
      <pubDate>Thu, 28 Aug 2025 23:51:27 GMT</pubDate>
    </item>
    <item>
      <title>埃隆偷猎14个元工程师</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n2qw0a/elon_poaches_14_meta_engineers/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   Zuckerberg的Meta众所周知，据报道，据报道提供了高达2.5亿美元的保留奖金，以防止其顶级的AI研究人员跳船，但是尽管这些高昂的款项，但尽管如此，Elon Musk的Xai至少已经成功地招募了Meta的AI Dive ＆＃32;提交由＆＃32; /u/u/ubatrosshummingbird     [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n2qw0a/elon_poaches_14_meta_engineers/</guid>
      <pubDate>Thu, 28 Aug 2025 22:53:39 GMT</pubDate>
    </item>
    <item>
      <title>今天的AI模型真的是“聪明的”，还是只是好的图案机器？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n2qe3u/are_todays_ai_models_really_intelligent_or_just/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我越多地使用chatgpt和其他LLM，我想知道的越多，我们是否过度使用智能一词？ 不要误会我的意思，它们很有用。我每天使用它们。但是在大多数情况下，感觉就像是预测，而不是真实的推理。他们不会像人类那样“理解”上下文，并且在需要真正常识的任何事物上跌跌撞撞。 所以这是我的问题，如果这不是真正的智力，您认为下一个大步是什么样的？更好的架构超出了变形金刚？更多的多模式推理？完全有什么？ 好奇这个社区的立场：我们是在通往AGI的道路上，还是只是建立越来越更好的自动完成？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n2qe3u/are_todays_ai_models_models_really_intelligent_or_just/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n2qe3u/are_todays_ai_models_models_really_intelligent_or_or_just/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n2qe3u/are_todays_ai_models_really_intelligent_or_just/</guid>
      <pubDate>Thu, 28 Aug 2025 22:32:14 GMT</pubDate>
    </item>
    <item>
      <title>您是否正在为AI代理使用可观察性和评估工具？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n2nm72/are_you_using_observability_and_evaluation_tools/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我一直注意到越来越多的团队正在构建AI代理，但是很少有对话涉及可观察性 和评估。 。在某个时候，他们将失败。真正的问题是： 在您的用例中，该故障是否重要？ 您如何捕捉和改进这些失败？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/_coder23t8      [link]     [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n2nm72/are_you_using_observability_and_evaluation_tools/</guid>
      <pubDate>Thu, 28 Aug 2025 20:40:12 GMT</pubDate>
    </item>
    <item>
      <title>迅速的通货膨胀似乎可以很好地增强模型的反应</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n2mr2c/prompt_inflation_seems_to_enhance_models_response/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  前提：我主要在Gemini 2.5 Pro（Aistudio）上测试了此问题，但它似乎也可以在Chatgpt/Claude上进行，可能会稍差，也许更糟糕。   启动了一个新的聊天，并将此提示作为指令：                     该模型将以夸大提示的示例回复。然后将您的提示发布提示：... 。该模型将使用夸张的版本或该提示回复。启动新的聊天一种糊状的糊状。我知道它是否提高了他们的答案的质量。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n2mr2c/prompt_inflation_seems_to_enhance_enhance_models_models_response/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n2mr2c/prompt_inflation_seems_to_enhance_enhance_enhance_models_models_response/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n2mr2c/prompt_inflation_seems_to_enhance_models_response/</guid>
      <pubDate>Thu, 28 Aug 2025 20:06:20 GMT</pubDate>
    </item>
    <item>
      <title>AI是虐待受害者的强大工具</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n2gb0o/ai_is_a_powerful_tool_for_victims_of_abuse/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n2gb0o/ai_is_a_powerful_tool_for_victims_of_abuse/</guid>
      <pubDate>Thu, 28 Aug 2025 16:03:09 GMT</pubDate>
    </item>
    <item>
      <title>关于AI的最可悲的部分...</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n2fmgd/the_saddest_part_about_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  是，我们学会了在学会与狗交谈之前与计算机交谈。 这就是我真正想要的。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n2fmgd/the_saddest_part_about_ai/”&gt; [link]   ＆＃32;   [commist]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n2fmgd/the_saddest_part_about_ai/</guid>
      <pubDate>Thu, 28 Aug 2025 15:37:30 GMT</pubDate>
    </item>
    <item>
      <title>AI没有杀死创造力，证明我们几乎没有...相对</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n2f605/ai_did_not_kill_creativity_its_proved_we_barely/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  创造力一直是人类最喜欢的神话之一。我们喜欢想象每首歌，书籍或绘画都是人类只拥有一些神秘的火花的结果。然后，人工智能到达，按需制作诗歌，论文和图像，反应立即恐慌。人们声称机器终于杀死了创造力。事实是更苛刻的。 AI没有杀死它。它揭示了我们几乎没有。 环顾四周。流行音乐回收了相同的和弦，直到熟悉感都像舒适感。好莱坞重复了相同的故事，直到在第二幕之前可以预测结局为止。新闻业改写了新闻稿。甚至在LinkedIn上的病毒帖子也被重新加热了其他人的思想，上面贴有主题标签。我们谈论的是原创性，好像它很丰富，但是我们产生的大部分都是混音。 AI没有打破这种幻想。它已经暴露了它。现实情况是，创意工作一直是建立在公式上的。艺术家和作家可能不愿承认这一点，但大部分过程都是重复和惯例。创意的火花是例外。可预测性安慰我们，这就是为什么人们回到熟悉的歌曲和故事的原因。机器在这方面蓬勃发展。它们吸收模式并产生的变化比我们任何人都更快。令人不安的人不是AI可以创造的，而是表明我们自己的作品从来都不是我们所相信的那么独特。这就是为什么中间立场消失的原因。大多数创意专业人士生活的安全空间，足够好，原始，足够不同的空间正在缩小。如果您的作品是为灵感打扮的配方奶粉，那么机器将做得更好。这并不意味着创造力已经死了。这意味着酒吧终于被提高了。因为真正的创造力一直生活在边缘。真正的独创性与自身矛盾，冒险并实现没有人期望的飞跃。机器是混音的大师，但它们不是悖论的主人。他们可以写一首爱情诗，但他们不能再现凌晨2点发出的颤抖，破碎的供词。他们可以发行抗议歌曲，但他们无法体现某人在街上唱歌的人的原始能量，而警方十英尺远。创造力不是抛光的输出。这是凌乱，非理性的，活着的。这就是我们现在面临的事实。如果AI可以复制您的作品，也许它并不像您想象的那么有创造力。如果AI可以复制您的声音，也许您的声音已经是回声。如果AI可以在提示中绘制您的职业生涯，那么您的职业可能是建立在结构上而不是发明的。 AI的愤怒被误导了。我们真正生气的是我们自己平庸的曝光。历史证明了这一点。印刷机使抄写员无关紧要，但强迫作家变得更加清晰，大胆。摄影威胁着画家，直到他们拥抱相机无法做的事情。互联网以平庸的方式淹没了世界，但也引起了人们的声音。每个新工具都会破坏中间，并迫使人类决定它们是真正的原始噪音还是背景噪音。 AI是最新的一轮。 ，这是悖论。人工智能不会使创造力毫无价值。它使其无价。普通的将是自动化的，保险箱将被无休止地复制，但是火花，奇怪，矛盾，不可预测的，将比以往任何时候都更加突出。机器无法杀死它。机器突出显示。他们过滤了世界，并迫使我们证明我们所做的一切是否真正活着。 所以不，AI并没有杀死创造力。它剥去了面具。剩下的问题很简单。您的作品从开始真正创造了？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/small_accountant6083      [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1N2F605/1N2F605/AI_DID_NOT_KILL_KILL_CREATIVEITION_ITS_PREVITION_PREVETIVITY_PREVED_PREVED_WE_BARELY/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n2f605/ai_did_not_kill_creativity_its_proved_we_barely/</guid>
      <pubDate>Thu, 28 Aug 2025 15:20:19 GMT</pubDate>
    </item>
    <item>
      <title>GPT-5优于美国医学许可考试的医生</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n26t3y/gpt5_outperformed_doctors_on_the_us_medical/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  摘要论文中的摘要： ;  &#39;大语言模型（LLMS）的最新进展使通用系统能够执行越来越复杂的域特异性推理，而无需进行广泛的精细调整。在医疗领域，决策通常需要整合异质信息源，包括患者叙事，结构化数据和医学图像。这项研究将GPT-5定位为医学决策支持的通才多模式推理，并系统地评估其在基于文本的问题答案和视觉问题上的Zeroshot链链推理绩效和统一协议下的视觉问题回答任务。我们基于GPT-5，GPT-5-MINI，GPT-5NANO和GPT-4O-2024-11-20对MEDQA，MEDXPERTQA（文本和多模式），MMLU医学亚集，USMLE自我评估考试和VQA-RAD的标准分裂。结果表明，GPT-5始终胜过所有基准，在所有QA基准测试中实现最先进的准确性，并在多模式推理中带来可观的增长。在MEDXPERTQA MM上，GPT-5分别比GPT-4O的推理和理解分别提高了29.26％和 +26.18％，并且在推理中超过预先许可的人类专家，在理解中超过 +29.40％。相反，在大多数维度上，GPT-4O仍然低于人类专家的表现。一项代表性的案例研究表明，GPT-5可以将视觉和文本线索整合到连贯的诊断推理链中，建议进行适当的高风险干预措施。我们的结果表明，在这些受控的多模式推理基准上，GPT-5从人类稳定到上述人类专家的表现移动。这种改进可能会大大为未来的临床决策支持系统设计。我们将代码公开在GPT-5-评估上。  ＆＃32;提交由＆＃32; /u/metaknowing     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n26t3y/gpt5_outperformed_doctors_on_the_us_medical/</guid>
      <pubDate>Thu, 28 Aug 2025 08:37:03 GMT</pubDate>
    </item>
    <item>
      <title>大多数AI初创公司与几年前的NFT/Crypto初创公司相同。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n25ek7/most_ai_startups_are_the_same_bs_as_the_nftcrypto/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   imho并最近阅读所有新闻，大多数与AI相关的公司，产品，初创企业与几年前在NFTS和Crypto中弹出的公司相同，而在Hott hott of the Hott Tobs of the Hott Topcy rn中，请付出了不可思议的收入，付出了一定的投资。现在，您是串行加密/NFT/AI/区块链/IoT企业家。这是可能的，因为这些VC不想坐在现金上，而其中一家初创公司甚至有0.1％成为下一个Uber，Door Dash，Chatgpt的事实，这是值得的。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/user_country_497     [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n25ek7/most_ai_startups_are_the_same_bs_as_the_nftcrypto/</guid>
      <pubDate>Thu, 28 Aug 2025 07:04:27 GMT</pubDate>
    </item>
    </channel>
</rss>