<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Sat, 30 Aug 2025 01:05:41 GMT</lastBuildDate>
    <item>
      <title>Meta未经许可创建了其他名人泰勒·斯威夫特（Taylor Swift）的轻浮聊天机器人</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n3m3k0/meta_created_flirty_chatbots_of_taylor_swift/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    https://www.reuters.com/business/meta-created-flirirty-chatbots-taylor-swift-tay-tay-celeth-celebother-celebrities-without-permission-2025-08-29/     &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/s1n0d3utscht3k       [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n3m3k0/meta_created_flirty_chatbots_of_taylor_swift/</guid>
      <pubDate>Fri, 29 Aug 2025 23:06:34 GMT</pubDate>
    </item>
    <item>
      <title>不同国家对AGI的反应</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n3lxep/different_countries_reactions_to_agi/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我觉得这还不够多。现在我承认我不是AI的专家。但是我觉得拥有不同政府的不同国家对AGI的反应会大不相同。就像美国可能无所作为，让亿万富翁毁了该国，并且将是完全反乌托邦，但假设IDK挪威可能会有更好的反应，无论是UBI还是其他东西。我可能完全错了，就像我说不是专家，而只是在我的脑海中。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/n0rma1pers0n123      [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n3lxep/different_countries_reactions_to_agi/</guid>
      <pubDate>Fri, 29 Aug 2025 22:59:10 GMT</pubDate>
    </item>
    <item>
      <title>如何用这个命令表达？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n3lx7i/how_do_i_phrase_this_command/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我发誓，我成功地与另一个客户端进行了此操作，但我想将14个月的银行语句加载为pdfs，并让chatgpt将事务历史记录部分转换为Excel工作表中的每一列，其中每个列（日期，描述，描述，借记，信用，balance，balance）将在工作单上的列中。这次我来的最接近的是所有标题，但DR和CR领域被附加到了描述中。真的很奇怪的是，我展示的预览看起来很完美。  在语句上，它们是列之间的列。显然，我不是在问正确的问题。关于如何执行此操作的任何想法？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/janfromearth     [link]     [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n3lx7i/how_do_i_phrase_this_command/</guid>
      <pubDate>Fri, 29 Aug 2025 22:58:56 GMT</pubDate>
    </item>
    <item>
      <title>无论如何，你们的一半是AI机器人</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n3lbko/half_of_yall_are_ai_bots_anyways/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这就像看着NPC试图互相互相超越。我是一个潜伏者，但是你们对每个问题都有相同的通用回答。难怪subs像 r/lifeurlverified 必须制作。   &lt;！ -  sc_on-&gt; &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/rugh-lock-4936     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n3lbko/half_of_yall_are_ai_bots_anyways/</guid>
      <pubDate>Fri, 29 Aug 2025 22:32:57 GMT</pubDate>
    </item>
    <item>
      <title>在特斯拉的致命崩溃法庭案件中，特斯拉减少判决金额的请求已到来</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n3kvh2/in_teslas_fatal_crash_court_case_teslas_request/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这是我先前关于 benevidesv。tesla致命的“自动驾驶仪” FSD车辆崩溃案件的链接 href=&quot;https://www.reddit.com/r/ArtificialInteligence/comments/1miltev&quot;&gt;https://www.reddit.com/r/ArtificialInteligence/comments/1miltev In that prior post I predicted Tesla would soon ask the judge to reduce the judgment amount through a process called “remittitur.”该请求现在到了。特斯拉要求法官减少针对特斯拉分配的2300万美元的补偿性赔偿金，并将惩罚性赔偿额减少到匹配的2300万美元，总计4600万美元赔偿特斯拉。 这不是说Tesla同意Tesla的较小数量；特斯拉还向法院提出动议，以完全推翻判决。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/prearsmens_sky1950     [links]     &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n3kvh2/in_teslas_fatal_fatal_crash_crash_ccor_caser_case_teslas_request/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n3kvh2/in_teslas_fatal_crash_court_case_teslas_request/</guid>
      <pubDate>Fri, 29 Aug 2025 22:13:47 GMT</pubDate>
    </item>
    <item>
      <title>为什么GPT-5提示与Claude无法正常工作（相反）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n3klh3/why_gpt5_prompts_dont_work_well_with_claude_and/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我已经建立了生产AI系统已有一段时间了，当他们精心制作的提示与一种模型搭配使用良好时，但与另一种模型完全失败时，我一直在看到工程师感到沮丧。事实证明，GPT-5和Claude 4具有一些真正奇怪的行为差异，没有人谈论。我通过仔细研究了他们的提示指南来进行一些研究。   gpt-5如果您给出矛盾的说明，将会出现故障。。，而克劳德（Claude）只是遵循它所读的最后一件事，而gpt-5实际上会浪费浪费处理能力，试图进行调和，从不做x＆quot;并“总是做X＆quot”在同一提示中。  冗长的控制完全不同。 gpt-5既具有API参数，又响应自然语言覆盖（您可以设置全局的低详细性，但要说“仅代码为code holly qoid”。克劳德（Claude）没有等效 - 这都是基于迅速的。  工具呼叫协调是白天和白天的。 gpt-5自然会并行解散多个API呼叫，而无需询问。 Claude 4默认情况下是顺序的，需要明确的鼓励才能并行化。 上下文窗口的事物也是违反直觉的-GPT -5有时在更多上下文的情况下表现较差，因为它试图使用您提供的一切。克劳德4忽略了无关紧要的东西，但错过了长时间的对话中的连接。 也有一些特定的提示模式与一种模型非常出色，并且对另一种型号无能为力。就像克劳德4具有这种怪异的自我反射模式一样，如果您告诉自己先创建自己的标题，则可以更好地表现，然后判断其对该标语的工作。 gpt-5只是对此感到困惑。 我写了  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/sarthakai   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n3klh3/why_gpt5_prompts_dont_work_work_well_with_with_with_with_with_claude_and/”&gt; [links]       [注释]       ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n3klh3/why_gpt5_prompts_dont_work_well_with_claude_and/</guid>
      <pubDate>Fri, 29 Aug 2025 22:01:44 GMT</pubDate>
    </item>
    <item>
      <title>害怕未来</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n3jid6/afraid_of_the_future/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  好吧，基本上我想成为一名作家，但恐怕AI可以代替艺术中的人。目前还不是，但是谁知道20年后？此外，根据Chatgpt的创建者的说法，AI将失去许多工作。而且我更害怕山姆·奥特曼（Sam Altman）。老实说，对人工智能有什么其他事情需要做什么？他们不能只是个人助理吗？现在，每个人都使用AI，而是用作工具，而是用作自己的替代品，而不是因为有意义的话而不是来自自己的东西。我不希望我们的竞赛能够发展为这一目标。我真的很害怕。您认为会发生什么？有工作，思维方式，控制任何制度，政治，公司或任何一般的工作？我现在也许有一点恐慌攻击。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/midetetas3000     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n3jid6/afraid_of_the_future/</guid>
      <pubDate>Fri, 29 Aug 2025 21:16:35 GMT</pubDate>
    </item>
    <item>
      <title>在Sphere Ai Slop上称呼Oz的巫师是对艺术家的侮辱</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n3eo01/calling_wizard_of_oz_at_the_sphere_ai_slop_is_an/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  是的，他们的艺术得到了AI的支持。但这并不是说他们去了chatgpt说，“成为oz big pls的巫师”。这些都是真正的资深艺术家，他们创造了这一点，并将其作品称为Ai Slop，只是因为它得到了AI的支持。有趣的是，这些人认为自己更聪明，在道德上是反对的，当时他们是那些将批判性思维卸载给tiktok并热情地讨厌他们不了解的东西的人。人们出于许多不同的原因不喜欢AI，有些是有效的，有些是无效的，但是无论您是否是AI粉丝，这些艺术家所做的两年的辛勤工作都是错误的。我什至看到有人说艺术家是懒惰的叛徒。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u lulgbtorsothing     &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n3eo01/calling_wizard_of_og_oz_at_the_sphere_sphere_ai_ai_ai_slop_is_is_is_an/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n3eo01/calling_wizard_of_oz_at_the_sphere_ai_slop_is_an/</guid>
      <pubDate>Fri, 29 Aug 2025 18:05:24 GMT</pubDate>
    </item>
    <item>
      <title>梅塔（Meta</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n3dn1s/meta_says_bring_ai_to_the_interview_amazon_says/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  看起来越来越多的人正在使用AI进行技术访谈。一个统计数据说 65％的求职者在此过程中的某个地方已经使用了它。这给经理和人力资源带来了一个棘手的问题：您是真的评估人及其技能，还是AI正在接受采访？  事实是，公司被分割了：      meta 公开允许AI在编码访谈中使用，称候选人应在雇用时会在相同的条件下工作。  Zuckerberg甚至称AI “您可以在您的公司中拥有代码的一种中级工程师，”和Meta的一种实际上使其官方作弊。      Amazon ，另一方面，甚至可能   无论哪种方式，很明显，技术招聘处于一个很大的过渡中：  如果AI被录取，访谈也应评估提示技能以及如何在工作流程中应用AI。同样重要的是：软技能，例如解决问题，跨团队的沟通以及了解业务需求。如果要委派给AI，那么这些问题甚至更重要的是。   如果禁止AI ，公司将需要在两个方面进行适应：   - 培训招聘人员和面试官以发现可疑行为。诸如侧面瞥了一眼另一个屏幕，奇怪的沉默或“过度抛光的答案”之类的东西。所有这些都可以发出未经授权的AI使用。    - 使用新工具来检测假候选人。这些是更极端的情况，，但报道说它们已经上升了。  最后，我认为这对许多公司来说都是一个真正的问题。你们都怎么看？允许AI使用并专注于评估候选人如何使用它，或者招聘过程是否应该在没有LLMS的情况下可以做什么？  来源：     https://www.businessinsider.com/meta-job-candidates-use-ai-coding-interviews-2025-7      https://www.cnbc.com/2025/04/08/fake-job-job-seekers-use-use-ai-te-interview-for-for-remote-jobs-jobs-jobs-jobs-jobs-ceos-ceos-say.html       https://www.inc.com/jessica-stillman/are-they-a-they-a-great-job-candidate-or-just-iust-using-using-ius--ris-res-5-questions-to-to-t-t-t-t-tel-tell/91154910         &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n3dn1s/meta_says_bring_ai_ai_tto_the_tthe_interview_amazon_says/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n3dn1s/meta_says_bring_ai_ai_the_tthe_tthe_tthe_interview_interview_amazon_saysay/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n3dn1s/meta_says_bring_ai_to_the_interview_amazon_says/</guid>
      <pubDate>Fri, 29 Aug 2025 17:26:53 GMT</pubDate>
    </item>
    <item>
      <title>特朗普政府将自动化健康不平等</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n3bd8i/the_trump_administration_will_automate_health/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   craig spencer：“白宫的AI行动计划，7月发布，仅提及&#39;医疗保健&#39;，但它是第二届特朗普政府最后果的健康政策之一。席卷了ai浪费的雄心勃勃的ai，以ai的态度，派遣了私人私人行为，私人的私人行为，又有私人的私人行为，又有私人划分的私人行为，又有创新的行为，又有创新的行为。 Dei&#39;-将对医学的实践，公共卫生的治理方式以及被抛弃的人会产生长期的影响。这些动作不仅是象征性的，而且还塑造了被衡量的内容，被研究和哪些发现发表的内容。现在，这些相同的约束正在进入AI本身的发展。根据政府的政策，开发人员有明确的动力来做出设计选择或选择不会引起政治审查的数据集。进入医学的未来和历史表明，一旦偏见被编码为临床工具，即使是几十年来，也可能需要数十年的时间 - 如果它们完全被撤消。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/theatlantic     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n3bd8i/the_trump_administration_will_automate_health/</guid>
      <pubDate>Fri, 29 Aug 2025 16:00:46 GMT</pubDate>
    </item>
    <item>
      <title>是否有可以产生音乐成绩的AI聊天机器人？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n3b2sx/is_there_an_ai_chatbot_that_can_produce_musical/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  像大多数人一样，我想成为作曲家而不必做任何实际工作。是否有AI可以为我做到这一点？提交由＆＃32; /u/u/u/cramber-flarmp     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n3b2sx/is_there_an_ai_ai_ai_ai_chatbot_that_that_can_can_produce_musical/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n3b2sx/is_there_an_ai_chatbot_that_can_produce_musical/</guid>
      <pubDate>Fri, 29 Aug 2025 15:49:47 GMT</pubDate>
    </item>
    <item>
      <title>我喜欢当人们使用AI来完善他们的帖子时</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n395bm/i_like_when_people_use_ai_to_refine_their_posts/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  它使语法和段落断裂。它放置了适当的标点符号。阅读帖子感觉就像有一种可靠的格式。  我不是在捍卫那些用它来完成创意写作的人，但是如果您想向世界传达的东西，并且想使用AI来完善/重写它吗？前进。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/kristisoko     &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n395bm/i_like_when_people_people_ai_ai_refine_to_refine_to_refine_their_their_posts/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n395bm/i_like_when_people_use_ai_to_refine_their_posts/</guid>
      <pubDate>Fri, 29 Aug 2025 14:36:15 GMT</pubDate>
    </item>
    <item>
      <title>人工智能可以做基本数学吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n36930/can_artificial_intelligence_do_basic_math/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在听Anthropic最近的视频“ AI模型如何思考”基于他们对可解释性的研究，并发现了一些见解，他们分享了非常有趣的。例如，有证据表明LLM可以进行简单的数学（加法）。 可解释性是试图通过观察其中间神经层中发生的事情来理解LLM的工作方式的领域。在类比中，他们的工作类似于神经科学家对有机大脑的作用：他们使LLMS执行某些任务，并查看LLM打开神经元来处理这些任务的神经元。   很多人认为，LLMS认为，LLMS只是自动化工具，并且只能基于toke的信息，以前就可以看到它的信息。但是人类的研究表明，这并不是那么简单。  杰克·林赛（Jack Lindsey）共享一个简单但非常有趣的示例，每当您获得模型总和两个数字时，第一个数字以“ 9”结尾。第二个以数字“ 6”结尾。触发LLM的相同神经元。但是有趣的部分实际上是可以发生这种情况的上下文的多样性。  当然，当您输入“ 9 + 6 =“”时，这些神经元将被触发，但是当您询问LLM的LLM年度第6卷发表了特定年度期刊的第六卷时，它们也会触发。他们没有增加提示的是，该期刊首次于1959年发表。  LLM可以正确预测第六卷是在1965年出版的。但是，当观察到哪些神经元触发时，他们见证了添加数字的神经元的6＆quot;和“ 9”正如约书亚·巴特森（Joshua Batson）总结的那样，这所暗示的是，即使LLM在其培训期间看到该期刊的第六卷在1965年出版，这表明，这表明该模型仍然表明，该模型“仍然愿意”，这表明这一表明的是，该期刊的第六卷已在1965年发表，这表明了这一点。为此特定情况进行数学。 这样的发现表明，LLMS可能比简单的模式匹配在更深的结构上运行。可解释性研究仍处于早期的早期，但是它开始揭示这些模型在引擎盖下的推理可能比我们假设的更多。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n36930/can_artcover_intelligence_do_do_do_basic_math/”&gt; [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n36930/can_artificial_intelligence_do_basic_math/</guid>
      <pubDate>Fri, 29 Aug 2025 12:36:32 GMT</pubDate>
    </item>
    <item>
      <title>知道人工智能的人将大大取代那些没有的人</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n2wjjw/people_that_know_ai_will_massively_replace_those/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  似乎有些人主张知道AI的人将大大取代那些不在未来的就业市场上的人。但是，这真的如何区分？谁不能只是学会命令AI或编写提示？不应用AI每个人都可以做的事情吗？这就是AI的目的，即使是新手也可以应用 - 对吧？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n2wjjw/people_that_knoke_ai_ai_ai_will_massiver_massiver_replace_those/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n2wjjw/people_that_know_ai_will_massively_replace_those/</guid>
      <pubDate>Fri, 29 Aug 2025 03:15:31 GMT</pubDate>
    </item>
    <item>
      <title>今天的AI模型真的是“聪明的”，还是只是好的图案机器？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n2qe3u/are_todays_ai_models_really_intelligent_or_just/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我越多地使用chatgpt和其他LLM，我想知道的越多，我们是否过度使用智能一词？ 不要误会我的意思，它们很有用。我每天使用它们。但是在大多数情况下，感觉就像是预测，而不是真实的推理。他们不会像人类那样“理解”上下文，并且在需要真正常识的任何事物上跌跌撞撞。 所以这是我的问题，如果这不是真正的智力，您认为下一个大步是什么样的？更好的架构超出了变形金刚？更多的多模式推理？完全有什么？ 好奇这个社区的立场：我们是在通往AGI的道路上，还是只是建立越来越更好的自动完成？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n2qe3u/are_todays_ai_models_models_really_intelligent_or_just/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n2qe3u/are_todays_ai_models_models_really_intelligent_or_or_just/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n2qe3u/are_todays_ai_models_really_intelligent_or_just/</guid>
      <pubDate>Thu, 28 Aug 2025 22:32:14 GMT</pubDate>
    </item>
    </channel>
</rss>