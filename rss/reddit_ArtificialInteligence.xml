<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Sat, 26 Jul 2025 21:14:39 GMT</lastBuildDate>
    <item>
      <title>热门：软件工程师不会消失，但是软件（我们知道）将会</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ma09yz/hot_take_software_engineers_will_not_disappear/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  随着AI模型的提高，推理和解决问题的技能，未来对软件开发人员的未来需求总是会出现…… ，但是，如果软件开发作为“技能”将变得民主和可用于每个人，那么在经济上，这意味着要付费一个人，这意味着要付费。您想要的功能费用以及其他客户想要的功能b）自己开发它（字面上是您自己，或雇用了“技能”的十亿人中的任何人），以实现您想要的功能，仅此而已。 您会选择什么？什么实际上会提供最佳的ROI？ 开发自己的CRM，人力资源系统，库存管理系统等的成本在历史上一直很高，因为软件开发不值得。因此，您可以满足您需求的最佳SaaS。  但是，在不久的将来，自我开发和完全拥有您组织所需软件的IP的投资回报率（除非可能具有超级高级和任务至关重要的一项关键软件）实际上可能是有道理的。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ma09yz/hot_take_software_engineers_will_will_not_disappear/”&gt; [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ma09yz/hot_take_software_engineers_will_not_disappear/</guid>
      <pubDate>Sat, 26 Jul 2025 18:15:59 GMT</pubDate>
    </item>
    <item>
      <title>Reddit的AI广告</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m9yf6a/ai_ads_in_reddit/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  您无法对它们发表评论。我看到了美国运通和一家维生素公司的一家。这是他们的一吨。我希望有法律通过，因为它只是在削弱整个行业。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/distributionok9521     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m9yf6a/ai_ads_in_reddit/</guid>
      <pubDate>Sat, 26 Jul 2025 17:00:25 GMT</pubDate>
    </item>
    <item>
      <title>只有20％的就业机会，工作后经济将是什么样的？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m9xlx6/with_just_20_employment_what_would_a_postwork/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在领先的人工智能研究人员中，一个辩论已经结束 - 他们估计，在2040年代中期，只有20％的成年人仍将在有偿工作中有80％至85％的可能性（Grace K.等人，2022年，2022年）。 D.，2020年； Srnicek＆amp; Williams，2015年。但是不确定其他功能可能还包括在内。 Such as, automation dividends, universal basic services (food, housing, healthcare), and unpaid jobs retained for social and other non economic purposes (Portes J. et al., 2017; Coote &amp; Percy, 2020). A key question remains: Who will own the AI and robotics infrastructure? But what do you think a sustainable hybrid economic model will actually look喜欢？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/ferggusmed   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1m9xlx6/with_just_20_20_employment_what_would_a_postwork/&gt; [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m9xlx6/with_just_20_employment_what_would_a_postwork/</guid>
      <pubDate>Sat, 26 Jul 2025 16:27:21 GMT</pubDate>
    </item>
    <item>
      <title>初中AI科学家角色的AI/ML副总裁的最终采访 - 我应该期待什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m9x10e/final_interview_with_vp_of_aiml_for_junior_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嗨， 我在AI启动时，我的最后一轮面试即将参加初级ML工程师职位。最后一轮是与AI/ML的副总裁的对话，我真的很想准备好的准备，尤其是因为与某人一起，高级资深😅 在这种情况下，我应该从副总裁级别的访问者那里期待哪些类型的问题？尤其是因为我是一名初级科学家，但是具有强大的研究背景。 会很喜欢任何建议 - 示例问题，心态提示或要强调的事情以给人留下深刻的印象。谢谢！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/extension-finish-365     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m9x10e/final_interview_with_vp_of_aiml_for_junior_ai/</guid>
      <pubDate>Sat, 26 Jul 2025 16:03:41 GMT</pubDate>
    </item>
    <item>
      <title>初中AI科学家角色的AI/ML副总裁的最终采访 - 我应该期待什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m9wu8f/final_interview_with_vp_of_aiml_for_junior_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我在AI初创公司的AI科学家实习中进行了最后的采访。最后一轮是与AI/ML副总裁的对话，我真的很想做好准备 - 尤其是因为与某人一起，对于我应该在这种情况下我应该从VP级访问者那里期待哪些类型的问题的任何想法？   会欣赏任何建议，以使任何建议示例，以使您的想法，以使您的意见，或者表现出强烈的印象。谢谢！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/maxmain_vegetable592     [link]   [注释]    ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m9wu8f/final_interview_with_vp_of_aiml_for_junior_ai/</guid>
      <pubDate>Sat, 26 Jul 2025 15:56:18 GMT</pubDate>
    </item>
    <item>
      <title>我们都是令人毛骨悚然的阴谋理论家吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m9tmsu/are_we_all_creepy_conspiracy_theorists/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我来自德国。我本人不是来自IT领域，但我仍然在一个很小的IT中心完成了学业。我想说的是，我对软件和硬件的编程具有基本知识。我本人在业余时间已经编程了25年以上。那时我仍在编程Q Basic。然后C ++，Java脚本等。但是，我不会说我与在大学学习这些知识并且已经在其职业生涯中具有编程经验的人相提并论。我一直在观察人工智能的发展已经很长时间了，当然，尤其是过去十二个月，这非常有成形，对未来也很重要。我在熟人的圈子中看到了它，我在认真的报纸和其他媒体中读到了它：人工智能已经处于使许多职业变得过时的水平。就在昨天，我再次阅读了一家拥有20个程序员的公司。 16人被冗余。这是董事总经理简单的Milquetoast计算。我现在的问题是：当我与不来自这个领域的环境中的人们谈论这个话题时，他们经常以一种稍微光顾的方式对我微笑。 我也注意到媒体已经接受了这个话题，但主要是在传递中。我很清楚，世界政治局势目前非常脆弱，需要提及其他重要问题。我最近越来越经常问自己的问题是什么：我是在意见泡沫中吗？我是那种说地球平坦的人吗？在我看来，我似乎与人交谈并告诉他们1 + 1是两个，每个人都说：“不，这是错误的，1 + 1是三个。您在这方面有什么经验？您如何处理它？ 编辑： 非常感谢您已经写过的所有答案！这些给我带来了进一步的问题。但是，我想提前提到，我的职业与技术完全无关，而且我当然不是一个好的程序员。因此，我依赖与其他人的互动，尤其是专家。但是，这里的情况类似于COVID时代：一位流行病学的教授兼专家说了一件事，而另一位教授在同一天说的相反。那是并且正在愤怒。换句话说，我将尝试再次描述我的观点： 许多人喜欢将人工智能领域的当前发展与工业革命进行比较。然后有人认为这当然具有成本工作，但也创造了新的工作。但是，我认为我收集了足够的信息，我相信我知道蒸汽机绝不会与今天已经可用的人工智能相同。后者是一个全新的维度，它已经自主工作（幸运的是仍在受保护的房间中脱机 - 直到硅谷中的一位百万富翁吞咽过多的LSD，并认为将设备连接到互联网会很有趣）。我什至不认为它一定是LSD：这种技术背后的令人难以置信的效力是天堂中的果实。在某个时候，有人会想知道这种效力的真正高度，并且每天都在增长。在这种情况下，我们将没有更多的工作。在这种情况下，我们将是奴隶，是旨在最大化效率的系统的属性。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/lawflenseunhappy458     [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m9tmsu/are_we_all_creepy_conspiracy_theorists/</guid>
      <pubDate>Sat, 26 Jul 2025 13:40:50 GMT</pubDate>
    </item>
    <item>
      <title>Openai在IOI 2025的存在</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m9qtg1/openais_presence_in_ioi_2025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我是积极的OpenAi的模型，也将在IOI上尝试 它在2025年IMO上获得了金牌，并在Atcoder Heuristical the Atcoder Hearistics竞赛中获得了第二名     &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/plem_read_7020     [link]    ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m9qtg1/openais_presence_in_ioi_2025/</guid>
      <pubDate>Sat, 26 Jul 2025 11:17:59 GMT</pubDate>
    </item>
    <item>
      <title>🚨赶上AI行业，2025年7月26日</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m9oek2/catch_up_with_the_ai_industry_july_26_2025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    AI治疗师脱离了轨道  Delta的AI间谍必须禁止“提高”价格。模式  Google推出了opal来构建AI Mini-Apps   Google和UC Riverside创建新的DeepFake检测器    来源：     https://futurism.com/ai-therapist-haywire-mental-mental-health     &gt; https://arstechnica.com/tech-policy/2025/07/deltas-ai-spying-to-jack-up-prices-must-be-be-be-band--be-band-band-makers-say/      https://www.testingcatalog.com/microsoft-prepares-copilot-for-gpt-5-with-with-new-new-smart-mode-indevelopment/     https://develovelers.googleblog.com/en/introducing-opal/  href=&quot;https://www.sciencedaily.com/releases/2025/07/250724232412.htm&quot;&gt;https://www.sciencedaily.com/releases/2025/07/250724232412.htm   ＆＃32;提交由＆＃32; /u/u/psycho_apple_juice     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m9oek2/catch_up_with_the_ai_industry_july_26_2025/</guid>
      <pubDate>Sat, 26 Jul 2025 08:41:58 GMT</pubDate>
    </item>
    <item>
      <title>云供应商的ML证书是什么意思？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m9ndh5/what_are_ml_certs_by_cloud_vendors_really_about/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我一直从AWS，Azure，Google和Oracle看到ML认证。 I’m wondering what are these certs are actually about? Do they only test your knowledge of their platforms, or do they help make ML work easier, like through services that let you build models without needing to know much about the math or code behind it? Basically: can you start doing ML with these cloud tools without knowing deep AI theory, or are these certs more for people who already understand the fundamentals? &lt;!-- sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1m9ndh5/what_are_are_are_ml_certs_by_cloud_vendors_really_about/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1m9ndh5/what_are_are_ml_certs_by_by_cloud_vendors_vendors_really_about/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m9ndh5/what_are_ml_certs_by_cloud_vendors_really_about/</guid>
      <pubDate>Sat, 26 Jul 2025 07:33:27 GMT</pubDate>
    </item>
    <item>
      <title>什么时候使用AI停止创意工作？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m9mb8o/when_does_using_ai_stop_being_creative_work/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  ，所以我注意到在使用AI时，我确实被解雇了很多工作。我不相信人们了解创建产品的工作。例如，我通过绘制设计并完善特定方面创建了一个设计，然后使用AI生成可以使用的东西。然后，我在Paint Shop Pro和决赛入围者中编辑该设计，全部增加了7-8个小时的工作和研究，但由于“ AI”而被解雇，因为它是“ AI”。 我完全理解是否只是要求它生成某些东西，然后我声称自己是我自己的。 这也对小小的观点呈现出来，用ai的意见来确定 a priond a priend o a&#39;&#39;我在这里错了？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/stbojangles   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1m9mb8o/when_does_usis_ai_ai_stop_being_creative_work/”&gt; [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m9mb8o/when_does_using_ai_stop_being_creative_work/</guid>
      <pubDate>Sat, 26 Jul 2025 06:27:38 GMT</pubDate>
    </item>
    <item>
      <title>格兰诺拉麦片 - 您的会议笔记是公开的！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m9lox6/granola_your_meeting_notes_are_public/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果您使用格兰诺拉麦片应用程序进行注释，然后读取。 默认情况下，您创建的每个音符都有一个可共享的链接：任何人都可以访问您的笔记。这些链接没有索引，但是如果您共享或泄漏一个链接（即使是偶然的），   对找到它的人来说是公开的。  将您的设置转换为“私人”只能保护未来的笔记。您所有早期的笔记都保持暴露，直到您一一手动将其锁定为止。没有回顾性的大量更新。  立即将您的格兰诺拉麦片设置更改为私人。审核您的旧笔记。删除您不想漂浮的链接。不要自满 - ＃隐私从来都不是默认值。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/floating-pointer     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m9lox6/granola_your_meeting_notes_are_public/</guid>
      <pubDate>Sat, 26 Jul 2025 05:50:42 GMT</pubDate>
    </item>
    <item>
      <title>人工智能势头之后的人类智能</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m9fcev/human_intelligence_in_the_wake_of_ai_momentum/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  ，因为我们人类正在慢慢选择提供自己的答案（合理的是 - 这是更实用的），所以我们需要变得更好地提出问题。   ，我的意思是，我们需要在提出更好的问题上提出更好的问题。我的意思不是更好地提示或抗拒，以“破解” LLM机器的答案功能，但我的意思是要问更多，充电，多样化和创造性的后续问题，以便我们从原始的答案中获得答案。因为保护和保留我们的脑容量的流量和发展要比从AI中获得我们需要的东西要重要得多。 实时时间。增强我们的好奇心并喂食它（我们的大脑，而不是AI），学习更广泛或更深入。 学习枪支查询，就像您在一个伪装游戏中一样，或者那个众所周知的盲人感觉到大象的脚并试图猜测大象。   不一定要获得更好的答案，而是要在各个方面得到一个自我的兴奋，而是要在各个方面加强自己的知识。而且不一定要精确（提出正确的问题），而是掌权（想了解更多）。 这是我们唯一的希望。由于我们大脑中的某些肌肉在生长中受到阻碍，因此我们需要成长其他肌肉，以免它自己吃掉。我们正在离开知识时代，并通过好奇心  进入发现时代（我在单独的媒体中将其作为评论，内容涉及AI的主题，因为AI已经接管了我们批判性思考的能力。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1m9fcev/human_intelligence_in_the_wake_wake_wake_of_ai_momentum/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m9fcev/human_intelligence_in_the_wake_of_ai_momentum/</guid>
      <pubDate>Sat, 26 Jul 2025 00:16:53 GMT</pubDate>
    </item>
    <item>
      <title>当地运行AI的实际原因？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m9ajed/practical_reason_to_run_ai_locally/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嗨，我正在寻找人们想在本地运行AI的实际原因吗？ :)我知道： *隐私（大个子） *省略限制/审查（生成裸体等） *离线工作 * Fun/Learning  看来，在大多数地区，其他任何东西都比电力更便宜。我喜欢为我的东西运行它的想法，这样做很酷（有趣/学习），但要寻找任何实际的理由：d   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/larumis     [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m9ajed/practical_reason_to_run_ai_locally/</guid>
      <pubDate>Fri, 25 Jul 2025 20:50:43 GMT</pubDate>
    </item>
    <item>
      <title>AI的新技能不是提示的，而是上下文工程</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m973yp/the_new_skill_in_ai_is_not_prompting_its_context/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  构建功能强大可靠的AI代理在寻找魔术提示或模型更新方面变得越来越少。这是关于上下文的工程，并在正确的时间以正确的格式提供正确的信息和工具。这是一个跨职能挑战，涉及了解您的业务用例，定义您的产出并构建所有必要的信息，以便LLM可以“完成任务。     [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m973yp/the_new_skill_in_ai_is_not_prompting_its_context/</guid>
      <pubDate>Fri, 25 Jul 2025 18:34:49 GMT</pubDate>
    </item>
    <item>
      <title>LLM同意我说的一切。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m8y88w/llm_agrees_to_whatever_i_say/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我们都知道一个超级积极的朋友。 您问他们任何事情，他们会说是。需要帮助吗？是的。想一起建立一家初创公司吗？是的。凌晨2点有一个疯狂的主意吗？让我们来做！ 这就是大多数AI模型现在的感觉。超级聪明，超级乐于助人。但也太愉快了。 询问llm的任何东西，它将尝试说是的。即使是含义：弥补事实，同意有缺陷的逻辑，在应该说“我不知道”时产生某些内容。 有时，这种盲目的积极性不是智慧。这是幻觉的根源。 ，事实是我们不仅需要更聪明的AI。我们需要更多诚实的人工智能。 AI说不。向后推的AI。问“确定吗？”的AI  那是真正的智能开始的地方。不是对所有事物都说“是”，而是知道什么时候不。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/prajwal_gote    href =“ https://www.reddit.com/r/artcoverinteligence/comments/1m8y88w/llm_agrees_to_to_to_to_to_to_towhatewhate_i_say/”&gt; [link]    ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m8y88w/llm_agrees_to_whatever_i_say/</guid>
      <pubDate>Fri, 25 Jul 2025 12:47:02 GMT</pubDate>
    </item>
    </channel>
</rss>