<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Sun, 04 Jan 2026 12:31:33 GMT</lastBuildDate>
    <item>
      <title>问题？我认为。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q3ome1/question_i_think/</link>
      <description><![CDATA[大家好。和一位专门研究人工智能的哲学教授一起吃年夜饭。长话短说，我使用 ChatGPT 的方式与以前不同。我遇到了一个障碍，那就是它没有掌握时间的概念。我需要时间戳来整理和构建内容。它解释说这是一台没有上述功能的机器，但我发现自己在想——因为都是一和零，人们是否发现了漏洞或提示？我的意思是，如果我的 iPhone 可以编排 24 小时时钟/日历，我相信你们中的某个人已经拥有了？不管怎样，提前谢谢大家，新年快乐！    由   提交 /u/FiredSmoke   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q3ome1/question_i_think/</guid>
      <pubDate>Sun, 04 Jan 2026 12:20:46 GMT</pubDate>
    </item>
    <item>
      <title>最佳人工智能治理工具 - 哪一个有效</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q3n7ft/best_al_governance_tools_which_one_works/</link>
      <description><![CDATA[大家好， 需要发泄一下，哈哈。也许这对某人有帮助。 我们有一个名为 Flinkit 的小项目。公司正在发展壮大，有了新的合作伙伴，一切都很好。但现在我们合作伙伴的企业客户想知道我们使用什么人工智能以及数据去向。我们对此一无所知，所以我们开始寻找 Al 治理工具。 Credo Al 先尝试一下。看起来不错，但它是为大企业设计的。设置花了很长时间，仪表板很混乱。每当合作伙伴问一些简单的问题时，我们就必须进行长时间的挖掘。定价也非常企业化。放弃了。 整体 Al 比 Credo 更好，但报告很糟糕。报告过于笼统，缺少我们合作伙伴实际需要的内容。必须通过电子邮件不断解释事情，任何入职培训也比我们想象的要花更长的时间。几乎放弃了，打算从我们的产品中删除 Al，哈哈。 Test360 有人在 Slack 小组中提到了这一点。没想到太多，但实际上还不错。设置大约需要 3 个小时，大部分是自动化的。它会扫描您的人工智能工具并绘制出数据流。生成您可以在合作伙伴要求时导出的报告。不再需要来来回回。 并不完美，但它有效并且定价感觉公平。这就是我们真正需要的。 TL;DR：小团队，合作伙伴想要 Al 合规性信息，尝试了 3 个工具，这个最适合我们。   由   提交 /u/Big-Tax-994   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q3n7ft/best_al_governance_tools_which_one_works/</guid>
      <pubDate>Sun, 04 Jan 2026 10:59:05 GMT</pubDate>
    </item>
    <item>
      <title>在责怪模型之前，请尝试仅修复提示中的一件事</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q3le8y/before_you_blame_the_model_try_fixing_just_one/</link>
      <description><![CDATA[快速实验建议： 接受一个给你带来不好结果的提示，只更改一件事： 添加一个明确的角色定义输出格式限制范围 不要改变想法 - 只改变结构。在大多数情况下，结果会立即改善。对您帮助最大的一项即时更改是什么？   由   提交/u/dp_singh_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q3le8y/before_you_blame_the_model_try_fixing_just_one/</guid>
      <pubDate>Sun, 04 Jan 2026 09:09:41 GMT</pubDate>
    </item>
    <item>
      <title>最大的人工智能子系统，但其中大部分是由反人工智能人士组成的。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q3ji7j/biggest_ai_sub_but_its_mostly_populated_by_far_by/</link>
      <description><![CDATA[我支持人工智能。我不会隐瞒，我喜欢人工智能。我喜欢使用它，并且对它未来的发展感到兴奋。我仍然担心所有令人讨厌的事情，比如政府用它来监视人们，用它进行审查等等。 任何时候我在这里发帖，它总是支持人工智能。我对人工智能无法做某事感到失望，我对朋友们在得知我使用人工智能时对我生气感到困扰，我对那些喜欢用它生成愚蠢视频的人的仇恨感到遗憾，我很兴奋它将能够做一些新的和很酷的事情。 但是每一次，几乎每次，帖子都会立即变为 0，在我这边，帖子会继续下降，有时低至 -24，很多回复都是只是侮辱我，称我为愚蠢的人工智能兄弟，说“没有人想看到你愚蠢的垃圾”之类的话，告诉我“很好”当我感到悲伤时，朋友们会因为人工智能而对我非常生气，并且通常会侮辱我，并且非常反人工智能。 我所做的任何回复都会立即被否决，并且随着帖子停留的时间越长，投票率就会继续下降，最终所有支持人工智能的人（很少）都说出了他们的观点，如果我不删除该帖子，我只会得到近乎无限的人偶尔进来侮辱我或告诉我他们有多么讨厌人工智能。 然后我所看到的就是所有反人工智能的人都以大量的赞成票来侮辱我，而所有支持人工智能的人都以大量的反对票来侮辱我。 这里没有真正的讨论，只是一群人进来侮辱别人。到目前为止，大多数回复都是这样的：“好吧，哭得更厉害，没有人想看到你的愚蠢的垃圾。”把那恶心的狗屎留给你自己。” 我真的不明白这个子的意义是什么？看起来更像是对专业人工智能人士来说这是一个陷阱。他们来这里以为可以讨论人工智能，但他们得到的只是人们侮辱他们，告诉他们他们是垃圾，垃圾人类，应该感到羞耻。   由   提交 /u/Dogbold   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q3ji7j/biggest_ai_sub_but_its_mostly_populated_by_far_by/</guid>
      <pubDate>Sun, 04 Jan 2026 07:14:57 GMT</pubDate>
    </item>
    <item>
      <title>人工智能内存功能正在快速推出，但安全模型尚未跟上</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q3ip8f/ai_memory_features_are_rolling_out_fast_but/</link>
      <description><![CDATA[使用 ChatGPT 内存大约 6 个月了。真正有用 - 记住我的工作设置、偏好、家庭事务。但我也告诉了它关于健康问题、工作压力、财务决策的问题。如果有人可以访问它，他们不仅仅会获得密码。他们得到了我是谁的综合资料。 现在每个大公司都在推动这一点。 ChatGPT 有记忆。克劳德有项目。双子座正在测试它。音调始终是“真正了解你的人工智能”。 这就是困扰我的地方：传统数据库存储孤立的数据。 Gmail有电子邮件。日历有约会。独立的孤岛。 人工智能内存主动连接一切。在一次聊天中提到胸痛，在另一次聊天中提到工作压力，在第三次聊天中提到家庭健康史——它综合了所有这些。这就是特点，但也是使违规变得更加危险的原因。您的电子邮件提供商不会建立心理档案。 AI 内存确实是这样设计的。 尝试在谷歌上搜索这些系统的安全性。找到了 ChatGPT 的一些文档，几个开源文档（Mem0、Zep、EverMemOS）。大多数人专注于使检索工作顺利进行。安全部分只是说“我们加密数据”没有太多细节。 无法找到以下方面的好信息：  人工智能在回答编码问题时可以访问健康数据吗？ 如果一个内存受到损害，所有内容都会泄漏吗？ 当你“删除”某个内存时一段记忆，它真的消失了吗？  OpenAI 每周有 2 亿+ 用户。即使 10% 的人启用了记忆功能，也意味着 2000 万人拥有了解他们一切的人工智能系统。一次泄露不仅仅是泄露密码——它还会泄露多年的背景、人际关系、私人想法、健康信息，所有这些都已合成并可供使用。 与密码不同，泄露后你无法更改你的生活史。 也许我想得太多了。但业界似乎在功能方面进展迅速，而在安全模型方面进展缓慢。我们不应该在它成为主流之前进行对话吗？ 我只是偏执还是这确实令人担忧？   由   提交/u/Secure-Run9146  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q3ip8f/ai_memory_features_are_rolling_out_fast_but/</guid>
      <pubDate>Sun, 04 Jan 2026 06:29:44 GMT</pubDate>
    </item>
    <item>
      <title>构建音频验证 API：如何在没有机器学习的情况下检测人工智能生成的语音 我不会推广</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q3f62f/building_an_audio_verification_api_how_to_detect/</link>
      <description><![CDATA[花了太长时间构建一些可能毫无意义的东西 制作了一个 API 来判断录音是人工智能还是人类 结果人工智能声音出奇地完美。比如 0.002% 的时间变化，而人类则为 0.5-1.5% 人类很混乱。人工智能不是。 无论如何，有人真的需要这个吗？还是我只是浪费了一个月的时间。  仍然非常困惑如何在不放弃我的整个项目的情况下将其提供给其他人，这是我愿意放弃的一部分   由   提交 /u/Electronic-Blood-885   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q3f62f/building_an_audio_verification_api_how_to_detect/</guid>
      <pubDate>Sun, 04 Jan 2026 03:31:55 GMT</pubDate>
    </item>
    <item>
      <title>公开编码我不会推广</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q3f49x/coding_in_the_open_i_will_not_promote/</link>
      <description><![CDATA[所以今天我大部分时间都在听 Zane 的演讲，努力反对智能合约测试，希望这是一件很困难的事情让我度过难关，但我认为这实际上不会起作用，我不认为我认为我们会提供帮助，只是更多代码或编写代码   由   提交 /u/Electronic-Blood-885   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q3f49x/coding_in_the_open_i_will_not_promote/</guid>
      <pubDate>Sun, 04 Jan 2026 03:29:34 GMT</pubDate>
    </item>
    <item>
      <title>重温过去的电影《机械战警 2014》</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q3cfqx/revisiting_the_past_movie_robocop_2014/</link>
      <description><![CDATA[随着人工智能的进步，现在所需要的只是一个机器人，而这部 2014 年翻拍的机械战警电影几乎在人工智能可能发展的方向上变得越来越重要。当时，与过去的电影进行了比较，这使得这部电影不受欢迎，但如果不看任何以前的机械战警电影，就重新观看这部电影，而我们现在所处的人工智能世界，这部翻拍现在变得相关，可能是受欢迎的，令人毛骨悚然，人工智能可能会朝这个方向发展。电影中也知道人类仍然必须控制人工智能，就像现实世界中的情况一样。这部电影中提到了人工智能，并在《机械战警》中被描绘成机器，但他也提到了人的因素。我想知道最近看过这部电影的人发表评论。   由   提交 /u/poster4521   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q3cfqx/revisiting_the_past_movie_robocop_2014/</guid>
      <pubDate>Sun, 04 Jan 2026 01:28:23 GMT</pubDate>
    </item>
    <item>
      <title>入侵台湾会扼杀人工智能的进步吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q3ac1z/will_the_invasion_of_taiwan_kill_the_advancement/</link>
      <description><![CDATA[现在有很多关于委内瑞拉为中国入侵台湾开绿灯的预测... 鉴于用于人工智能的 90% 以上的先进芯片都是台湾制造的，这一切将走向何方？   由   提交/u/SirBoboGargle  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q3ac1z/will_the_invasion_of_taiwan_kill_the_advancement/</guid>
      <pubDate>Sat, 03 Jan 2026 23:57:10 GMT</pubDate>
    </item>
    <item>
      <title>与你的人工智能“对话”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q38d20/talking_to_your_ai/</link>
      <description><![CDATA[“期望很容易。表达能力就是技能” 大多数人对待人工智能的方式就像对待谷歌一样。他们输入一些内容，&amp;希望它能理解他们头脑中答案的形状，并在输出与他们想象的不符时感到失望。但人工智能并不是对期望做出反应，而是对清晰度做出反应。挫败感和杠杆作用之间的区别在于学习如何将意图具体化。当你放慢速度来描述你真正想要的东西、约束、语气、目的、受众和非目标时，交互就会发生变化。系统停止猜测并开始对齐。看似“人工智能变得更聪明”的现象往往只是人类变得更加“精确”。真正的能力在于精度，而不是工具本身。再次强调，期望很容易。表达能力就是技巧。朋友们，请注意安全...   由   提交 /u/uscglawrance   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q38d20/talking_to_your_ai/</guid>
      <pubDate>Sat, 03 Jan 2026 22:35:20 GMT</pubDate>
    </item>
    <item>
      <title>人类仍然很重要——从“人工智能将取代我的工作”到“人工智能是有限的”：《黑客新闻》对人工智能的现实检验</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q2xnm6/humans_still_matter_from_ai_will_take_my_job_to/</link>
      <description><![CDATA[大家好，我刚刚发送了 14th我的每周通讯，Hacker News x AI 通讯，来自 HN 的最佳 AI 链接和围绕它们的讨论的综述。以下是本期分享的一些链接：  软件开发的未来是软件开发人员 - HN 链接 人工智能正在迫使我们编写好的代码 - HN链接 工业软件的兴起 - HN 链接 提示人们 - HN 链接 Karpathy 谈编程：“我从来没有感觉到落后这么多” - HN 链接  如果您喜欢此类内容，您可以在此处订阅每周简讯：https://hackernewsai.com/   由   提交/u/alexeestec  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q2xnm6/humans_still_matter_from_ai_will_take_my_job_to/</guid>
      <pubDate>Sat, 03 Jan 2026 15:40:23 GMT</pubDate>
    </item>
    <item>
      <title>人工智能并没有让我们变得懒惰，而是让我们负债累累。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q2py87/ai_isnt_making_us_lazy_its_putting_us_in_debt/</link>
      <description><![CDATA[我们一直将人工智能视为效率。那是错误的镜头。实际上发生的是交易。我们正在用理解换取速度。短期速度的长期弹性。每当系统为我们思考时，我们现在会节省时间，但稍后就会失去能力。 这种损失会加剧。每个解决的问题都会悄悄地将作用力从人类转移到工具。输出保持高水平，仪表板保持绿色，一切看起来都经过优化。但在本质上，能力正在被削弱。您可以看起来非常高效，但在没有系统的情况下您的响应能力却接近于零。就像金融债务一样，你可能会看起来很富有，直到你实际上并不富有。 那就是崩溃发生的时候。不是因为人工智能失败了，而是因为现实最终要求系统在没有信用的情况下运行。但它不能。没有技能了。没有留下任何判断力。没有适应能力。这次事故并不神秘。账单即将到期。   由   提交 /u/Small_Accountant6083   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q2py87/ai_isnt_making_us_lazy_its_putting_us_in_debt/</guid>
      <pubDate>Sat, 03 Jan 2026 09:00:27 GMT</pubDate>
    </item>
    <item>
      <title>我们正在讨论人工智能的未来，就好像法学硕士是最终形式一样</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q2p9jh/we_are_debating_the_future_of_ai_as_if_llms_are/</link>
      <description><![CDATA[LLM 对 AI 的影响就像软盘对数据中心的影响一样。 我认为人们犯的一个巨大错误是认为 AI 意味着 LLM，这限制了他们理解 AI 对社会的风险和影响的能力。 LLM（大型语言模型）是当前生成人工智能的最先进技术，但 AI不限于LLM。在 LLM 之前，有 HMM、GBM、RNN、VAE、GAN 等。 虽然 LLM 在生成 AI 功能方面提供了显着改进，但它们并不是 AI 模型将采用的最终形式。将会出现更多的创新，这些创新将使法学硕士看起来很原始，甚至可能过时。 因此，当人们说“人工智能不会取代你的工作”时，实际上是这样的。或“人工智能不够准确，不会导致大规模失业”，或者“人工智能不能有知觉或试图毁灭人类”，他们通常谈论的是当前法学硕士的局限性，而不是一般的人工智能。这些论点通常指出了我们今天看到的具体弱点，但这些只是当今技术的暂时限制，而不是人工智能最终可能成为的样子。 就像 RNN 无法生成大量连贯文本但法学硕士现在可以一样，较新形式的生成人工智能展示这些能力并可能在许多任务上超越人类可能只是时间问题。 现在，我们需要就人工智能对社会的影响进行对话，而不仅仅是思考法学硕士。我们需要展望该技术的未来，令人沮丧的是，大多数讨论都无法超越当前的法学硕士。   由   提交 /u/Je-ne-dirai-pas   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q2p9jh/we_are_debating_the_future_of_ai_as_if_llms_are/</guid>
      <pubDate>Sat, 03 Jan 2026 08:18:00 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Thu, 01 Jan 2026 15:09:32 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>