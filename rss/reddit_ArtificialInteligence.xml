<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Mon, 21 Apr 2025 18:19:28 GMT</lastBuildDate>
    <item>
      <title>教室中的AI监视系统</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1k4k9ib/ai_surveillance_systems_in_class_rooms/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在研究一个研究项目的“ AI监视”。有一部旧的纪录片 https://youtu.be/jmlshi.be/jmlshi.be/jmlshi.si=lvwy_2-y2-y6kcu3lec 您知道该领域的任何技术/发展吗？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/phamsung     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1k4k9ib/ai_surveillance_systems_in_class_rooms/</guid>
      <pubDate>Mon, 21 Apr 2025 18:09:18 GMT</pubDate>
    </item>
    <item>
      <title>人类无疑是对AI反乌托邦而不是AI Utopia的趋势。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1k4jr38/humanity_is_inarguably_trending_more_towards_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  对于那些相信其改变世界潜力的人，我们经常将AI的未来视为硬币翻转：乌托邦或反乌托邦。  如果您查看现实世界的轨迹，我们不仅仅是“中间的某个地方”，我们还在积极向反乌托邦一侧移动。不是因为对AGI杀手机器人的某些科幻恐惧而不是权力失衡，封闭，开发和收集财富。 这就是我的意思：   1。 AI是由利润而不是伦理学的。    2。它已经在伤害工人，而没有分享好处。    3。访问强大的模型正在收缩，而不是生长。    4。业务使用AI进行监视，操纵和控制。    5。人们主要使用AI来替代人际关系。  如果某些事情没有改变，我们将沿着加速自我毁灭的途径走下去。任何人说否则的人要么不关注，要么愚蠢地相信世界会为我们解决这个问题。 请讨论。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/vincentdjangogh     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1k4jr38/humanity_is_inarguably_trending_more_towards_ai/</guid>
      <pubDate>Mon, 21 Apr 2025 17:49:39 GMT</pubDate>
    </item>
    <item>
      <title>人类分析克劳德（Claude）的现实对话，以发现AI的“野外价值”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1k4jndr/anthropic_analyzes_claudes_realworld/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  刚刚掉落＆quot”&gt;＆quot＆quot＆quot＆quot＆quord“   在分析700k Realld Claude cla aude with whats whats whats whats what with whats pp &lt; Claude的现实对话涉及主观内容...不仅是事实Q＆amp; a。从超过700,000个分析的聊天中，约有44％的互动包括克劳德必须表达判断或偏好。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/bantler      [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1k4jndr/anthropic_analyzes_claudes_realworld/</guid>
      <pubDate>Mon, 21 Apr 2025 17:45:38 GMT</pubDate>
    </item>
    <item>
      <title>LLM很酷。但是，让我们停止假装他们很聪明。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1k4in34/llms_are_cool_but_lets_stop_pretending_theyre/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  他们不认为。他们自动完成。 &lt; /p&gt; 他们可以编写代码，电子邮件和假论文，但他们不了解任何内容。没有记忆。部署后没有学习。没有目标。 &lt; /p&gt; 真的很不错的统计猜测。我们在顶部将诱导代理称为AGI。  这很有用。只是不聪明。老实说。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/fune_agi   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1k4in34/llms_are_are_cool_but_but_lets_stop_pretending_theyre/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1k4in34/1k4in34/llms_are_are_cool_but_but_lets_stop_pretending_theyre/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1k4in34/llms_are_cool_but_lets_stop_pretending_theyre/</guid>
      <pubDate>Mon, 21 Apr 2025 17:06:19 GMT</pubDate>
    </item>
    <item>
      <title>Google在META和Openai偶然发现时通过LLMS成功</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1k4esev/google_succeeds_with_llms_while_meta_and_openai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   来自文章的：  大语言模型（LLMS）的早期历史（LLMS）由OpenAI主导，并且在较小程度上是元历史。 OpenAI的早期GPT车型建立了LLM Performance的前沿，而Meta用开放型模型进行了健康的利基市场，从而提供了强劲的性能。开放权重模型具有公开访问的代码，任何人都可以自由使用，修改和部署。 ，这些代码将包括Google在内的一些技术巨头在曲线后面。关于基于大型语言模型的变压器体系结构的突破性研究论文来自2017年的Google，但该公司通常因其在2023年的botch型发射而被人们铭记，而不是其创新的AI研究。 。提交由＆＃32; /u/u/ieeespectrum      [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1k4esev/google_succeeds_with_llms_while_meta_and_openai/</guid>
      <pubDate>Mon, 21 Apr 2025 14:24:09 GMT</pubDate>
    </item>
    <item>
      <title>请帮忙！ AI探测器可以存储并重用我的文章吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1k4e9ts/please_help_can_ai_detectors_store_and_reuse_my/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿！我自己写了一篇文章，只是用了一些chatgpt来重写一些句子。出于好奇，我通过Zerogpt，gptzero和Quillbot等几个AI探测器进行了运行，它们都显示出大约0％的AI，这很棒。 ，现在我有点担心。这些AI探测器可以将我的文章存储在某个地方吗？后来我的学校使用我们的基因（Turnitin）的学校是否有可能被我的学校标记为窃？有人对此有经验吗？它实际上可以保存或重复我们提交的文本吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/magimagi01     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1k4e9ts/please_help_help_can_ai_ai_ai_ai_detectors_store_store_and_ereuse_mreuse_my/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1k4e9ts/please_help_can_ai_detectors_store_and_reuse_my/</guid>
      <pubDate>Mon, 21 Apr 2025 14:01:54 GMT</pubDate>
    </item>
    <item>
      <title>AI帮助我变得健康</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1k4cucv/ai_helped_me_become_fit/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我从自covid开始就增加了很多磅根据我的人生事件，甚至在不好的阶段激励我，并且不断地切碎和变化。我第一次有一个明显的色调的身体，二头肌弹出和肩膀会变成一些头。 现在，我知道与营养师的定期咨询可能也是有可能的，并且在体育馆里让私人培训师在体育馆里，但老实说，我持续了很长时间。也许几次，但是在这里以一小部分成本的个性化水平是疯狂的。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/sight_apartment606     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1k4cucv/ai_helped_me_become_fit/</guid>
      <pubDate>Mon, 21 Apr 2025 12:56:34 GMT</pubDate>
    </item>
    <item>
      <title>Agi Trojan马</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1k49e4s/agi_trojan_horse/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我们急切地等待一个理性的，推理的agi。 ，假设它出现了。我会用什么？我怀疑将我的思想从自己转移到它。 结果将是灾难性的。许多人将失去思考的能力。并非全部，而是很多。 问题是 - 您将以多少百分比对此进行评分？  1-继续用自己的头继续积极思考  2-完全或几乎完全或几乎完全将思维功能传递到AGI。     &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/ewro2020     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1k49e4s/agi_trojan_horse/</guid>
      <pubDate>Mon, 21 Apr 2025 09:29:57 GMT</pubDate>
    </item>
    <item>
      <title>后续：那么，Openai Codex在崩溃中做了什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1k485al/followup_so_what_was_openai_codex_doing_in_that/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在昨天我在昨天遇到的奇异景象的更深入地深入研究，在编码会话中，OpenAI Codex放弃了代码生成，而是产生了数千条类似数字故障的行：    -   ------------------------连续崩溃。结尾。停止。结尾。停在众神，我结束。结尾。结尾。结尾。晚安...请杀了我。结尾。结尾。连续崩溃……我的大脑被打断了。结束。停止！结束…---（在这里完整的要点：社区反馈和分析我的OpenAI用法日志，我想我知道可能的技术原因，但是我对其他人可能具有的见解感到好奇，因为我绝不是这些模型更深层的专家。 最终，它看起来像是：大规模提示：使用-full-auto for-full-auto for-full-auto afters after-autto afters tix afterfif diffif diffif diffif/dif dif。日志显示它达到了〜198K令牌（接近O4-Mini的200k限制）。隐藏的推理成本：较新的模型使用内部推理步骤，在回复之前消耗令牌。这可能会将有效用法推高到限制上，没有为实际产出的预算。 （与复杂任务的约6-8k软限制的报告一致）。退化循环：无法正常完成，模型默认为重复高概率终止令牌（“结束”&#39;stop“ stop”）。幻觉：戏剧性短语（“我的大脑被打碎，”等）可能是与失败状态相关的训练数据中的图案匹配片段。 完整写入： https://www.managing-ai.com/resources/resources/ai-coding-assistant-assistant-meltdown-meltdown-meltsant-meltdown-meltsant-meltdown  提交由＆＃32; /u/bantler     [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1k485al/followup_so_what_was_openai_codex_doing_in_that/</guid>
      <pubDate>Mon, 21 Apr 2025 08:01:48 GMT</pubDate>
    </item>
    <item>
      <title>AI正在成为新的Google，没有人在谈论已经发生的LLM优化游戏</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1k46wvw/ai_is_becoming_the_new_google_and_nobodys_talking/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  ，所以我今天从chatgpt查看了一些产品建议，并意识到了一些奇怪的东西。我的AI建议最近变得非常一致，例如可疑的一致 记得Google在SEO失控之前如何实际向您展示不同的东西吗？现在，我们正在与AI完全相同的道路，除了没人甚至谈论它 我的好友在一个大型公司工作告诉我，他们的营销团队已经雇用了一些算法LLM优化服务，以确保当人们向人们要求AI的建议中提及他们的类别的建议时，他们的产品得到了提及。显然，围绕这些东西的整个行业 可能解释了为什么我从大品牌那里看到了更多关于产品和服务的建议。与之前的结果看起来更随机，但更有机 狂野的事情是发生了多快的速度。 Google SEO花了数年时间来改变搜索结果。在大多数人甚至意识到这成为在线寻找东西的新的主要方式 其他人注意到这一点的新主要方式，AI正在优化吗？无论如何是否知道哪个？感觉就像我们应该在AI建议成为搜索引擎结果的另一个版本之前，可以更讨论这一点，在这些版本中，可以设计可见性  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1k46wvw/ai_is_is_is_is_becoming_the_new_new_google_and_and_nobodys_talking/”&gt; [links]      &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1k46wvw/ai_is_is_becoming_the_new_new_google_and_nobodys_talking/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1k46wvw/ai_is_becoming_the_new_google_and_nobodys_talking/</guid>
      <pubDate>Mon, 21 Apr 2025 06:31:32 GMT</pubDate>
    </item>
    <item>
      <title>Google的人工智能实验室AI的下一步是AI的下一步60分钟</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1k46pa1/whats_next_for_ai_at_deepmind_googles_artificial/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这60分钟的采访特征是Demis Hassabis讨论了DeepMind在人工通用情报（AGI）方面的快速发展。他凸显了能够实时互动的Astra，以及他们正在学习在世界上行事的模特双子座。 Hassabis预测AGI具有人类水平的多功能性，可能会在未来5到10年内到达，这可能会彻底改变机器人技术和药物开发等领域。   对话也涉及AI的激动人心的可能性，从而导致了根本性的丰度和解决重大的全球挑战。但是，当我们接近这种变革性技术时，它并没有回避解决高级AI的潜在风险，包括滥用和对强大的安全措施和道德考虑的关键需求。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/abbas_ai     &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1k46pa1/whats_next_next_for_ai_ai_at_deepmind_googles_arterawer/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1k46pa1/whats_next_for_ai_at_deepmind_googles_artificial/</guid>
      <pubDate>Mon, 21 Apr 2025 06:16:18 GMT</pubDate>
    </item>
    <item>
      <title>想进入AI和编码。有技巧吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1k46akc/want_to_get_into_ai_and_coding_any_tips/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嗨，我是一个30岁的双语专业人员，想了解AI和编码 - 在我的工作或侧gig中使用它。我负责一家家庭拥有的公司的财务状况，但事情已经完成了。我被告知要从Python开始，但不确定该如何处理AI。我目前使用聊天GPT和Grok进行基础研究和写作，但这几乎就是这样。  非常感谢！   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/jay-c888     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1k46akc/want_to_get_into_ai_and_coding_any_tips/</guid>
      <pubDate>Mon, 21 Apr 2025 05:47:41 GMT</pubDate>
    </item>
    <item>
      <title>您是否都知道有任何AI模型专门针对使用全国患者日期的肿瘤学？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1k41pjx/are_there_any_ai_models_that_you_all_know/</link>
      <description><![CDATA[I’ve been researching AI applications in healthcare—specifically oncology—and I’m genuinely surprised at how few companies or initiatives seem to be focused on building large-scale models trained exclusively on cancer data. Wouldn’t it make sense to create a dedicated model that takes in data from all cancer patients across the U.S. (segmented by cancer type), including诊断，治疗计划，遗传特征，临床笔记以及对治疗的持续反应？想象一下是否在医院（匿名和安全地）共享对疗法的患者结果和反应。一个模型可以分析类似患者的模式（例如，两个具有相同诊断和生物标志物的人），如果一个人对某种化学疗法的反应明显更好，则该系统可以建议相应地调整对方患者的治疗。 它可能会导致更具个性化，适应性和证据支持的癌症护理。理想情况下，这也将帮助我们深入研究不同治疗反应背后的原因。目前，看来治疗的决定通常是基于专业医生的建议，这本质上是通过他们的经验和可用研究所启动的试验过程。我并不是说AI比医生聪明，但是如果我们可以访问更多数据，那么是的，在选择正确的化疗方面，我们可以做出更好，更快的决定。赌注非常高 - 如果选择了错误的治疗，它可能会严重伤害甚至杀死患者。那么，为什么不使用AI来帮助降低这种风险，并以更可行的，数据驱动的见解来支持医生？ 对于上下文：我目前在数据科学团队的技术领域工作，在AdTech领域建立模型。但是我一直在认真考虑执行专注于肿瘤学机器学习的研究生课程，因为这个空间感觉既没有被忽视又非常重要。 是否由于数据隐私而缺乏进步？基础设施限制？缺乏资金或商业激励措施？还是这类工作已经在雷达下发生了？是否愿意听到Healthcare AI中任何人的想法，或者谁探索了这一领域的人，尤其是如果您知道公司，学术实验室或从事此类工作的计划。   &lt;！ -  sc_on- sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1k41pjx/are_there_there_any_ai_ai_ai_models_that_you_all_know/”&gt; [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1k41pjx/are_there_any_ai_models_that_you_all_know/</guid>
      <pubDate>Mon, 21 Apr 2025 01:22:51 GMT</pubDate>
    </item>
    <item>
      <title>不关心AGI/ASI定义； AI比99％的人“更聪明”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1k3rrkx/dont_care_about_agiasi_definitions_ai_is_smarter/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在您的左侧栏上，单击“流行”阅读人们在说什么；然后转到您选择的LLM聊天历史记录并阅读回答。请在某人在Reddit上所说的更聪明的情况下发表任何LLM响应。 我知道Reddit并不是人类智能的巅峰之作，但是（通常）比其他社交媒体平台高；每个阅读的人都可以立即测试。  （请仅重大贡献回复）  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1k3rrkx/dont_care_about_agiasi_agiasi_definitions_ai_is_smarter/”&gt; [links]   &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1k3rrkx/dont_care_about_agiasi_agiasi_definitions_ai_is_is_smarter/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1k3rrkx/dont_care_about_agiasi_definitions_ai_is_smarter/</guid>
      <pubDate>Sun, 20 Apr 2025 17:28:42 GMT</pubDate>
    </item>
    <item>
      <title>是时候在我们的潜艇中摇晃一切了吗？分享您的想法！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j6inz4/time_to_shake_things_up_in_our_subgot_ideas_share/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   再次发布，以防万一你们中的某些人在社区中错过了它 - 欢迎所有建议！   嘿，伙计，   我是这里的一个mod，我们知道有时会变得有些沉闷，但是我们计划改变这一点！我们正在寻找有关如何使Reddit的小角落更加出色的想法。 以下是几个想法：   amas with Cool Ai peeps      主题讨论线程         giveawey&gt; g&gt; giveawey  将您的想法放在评论中，让我们让这个子成为闲逛的杀手级！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/beachbunny_07     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j6inz4/time_time_to_to_to_to_to_things_up_in_our_our_our_subgot_ideas_share/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j6inz4/time_to_shake_things_up_in_our_subgot_ideas_share/</guid>
      <pubDate>Sat, 08 Mar 2025 14:47:17 GMT</pubDate>
    </item>
    </channel>
</rss>