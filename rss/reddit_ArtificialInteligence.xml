<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Fri, 25 Jul 2025 03:58:09 GMT</lastBuildDate>
    <item>
      <title>Openai准备在8月推出GPT-5</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m8p0v2/openai_prepares_to_launch_gpt5_in_august/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    &#39;虽然GPT-5看起来很可能在8月初首次亮相，但OpenAI计划的发布日期经常转移以应对开发挑战，服务器容量问题，甚至竞争对手AI模型公告和泄漏。本月早些时候，我警告说，可能会延迟到 Altman确认了我的报告就在我的 notepad 之后的几天之后试图在7月底之前将其运送到GPT-5发行之前。资料来源将模型描述为“类似于O3 Mini”，并具有推理能力。自2019年发行GPT-2以来，该新模型将是Openai首次发布开放重量模型，它将在Azure，Hugging Face和其他大型云提供商上使用。＆quort＆quort&#39; 阅读整个文章href =“ https://www.theverge.com/notepad-microsoft-newsletter/712950/openai-gpt-5-model-rease-date-date-notepad”&gt; there。提交由＆＃32; /u/u/u/no-author-2358     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m8p0v2/openai_prepares_to_launch_gpt5_in_august/</guid>
      <pubDate>Fri, 25 Jul 2025 03:45:49 GMT</pubDate>
    </item>
    <item>
      <title>目前的AI是多么独立，未来几年有望进一步代理？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m8n2o7/how_independent_are_current_ai_and_is_it_on_track/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  一两个星期前，我读了“ AGI 2027”。文章（我敢肯定你们中的大多数人都熟悉），从那以后，这使我陷入了沮丧的恐慌。我很难为此而睡觉，进餐和做任何事情，因为我被一种难以理解的机器神所困扰，上帝燃烧了整个生物圈，因此它可以将整个星球变成一个巨大的数据中心。   有几个人向我保证，目前的AI基本上只是不太了解他们在说什么。但是，如果是这种情况，那么为什么我要阅读有关AI试图逃脱到另一台服务器的文章（ https://connect.ala.org/acrl/discussion/chatgpt-o1-tried-to-to-to-escape-scape-and-save-save-save-un-fear-t-------------或重写自己的代码以防止关闭的AI（ https://medium.com/@techempire/an-ai-managed-to-wrecreite-isth-code-code-code-to-prevent-humans-humans-from-shutting-it-down-65A12223267BF ），），还是反复介绍其运营商并删除其自身意志数据库的AI？ （ https://www.moneycontrol.com/technology/i-panicked-instead-of-thinking-thinking-thinking-ai-platform-deletes-enter-company-company-database-database-and-lies-lies-lies-iit-it-ict-ict-13307676.html ）） 更重要的是，为什么会有这么多专家进行面试，他们声明Agi/ASI有很大的机会在不久的将来杀死我们所有人？ 即使当前的AI模型根本没有真正的代理或理解，即使这么多实验室在不实现AGI的情况下，我们实际上是在实现人类的互助，直到有一定的时间，直到有一定的时间，就可以实现ATA的实现，以至于一定要努力，直到有一定的时间，直到有一定的时间）竞赛？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/slow-recipe7005     [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m8n2o7/how_independent_are_current_ai_and_is_it_on_track/</guid>
      <pubDate>Fri, 25 Jul 2025 02:07:21 GMT</pubDate>
    </item>
    <item>
      <title>克劳德代码CLI对话隔离/幻觉</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m8mt82/claude_code_cli_conversation/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  你好，  claude code pro tier经常会对它应该使用的目录感到困惑，忘记了我很多次提醒的基本内容。这是用户之间的常见问题。 我经常将其告知CD到/用户/myName。今天，可以预见的是，它忘记了该目录，并试图将CD降为c：/users/sethc。 我知道sethc.exe是Windows中的粘性键exe，但这引起了我的注意。我以为由于某种原因，它可能是从培训数据中幻觉的用户名或搜索Sticky Keys Exe。我不太担心，但我知道sethc.exe经常用于后门威胁以获取机器的访问（这是一个CLI。我不认为这是它要做的事情，但仍然如此）。 我问了它从哪里获得的，为什么它包括我的用户。它说：  “我是在提到“ sethc”。从对话摘要中，但是从当前目录列表中我可以看到，实际用户名是“ myname。”    sethc，既不是粘性键。Exe.exe或seth;或“ Seth C.”在我们的谈话中没有任何地方提到。我推了，问/询问它是否会使我的名字与其他用户混淆：  “我不应该将您的用户名与别人的用户名相混淆。我通过介绍“ sethc”而犯了一个严重的错误。这在我们的谈话中没有出现。我只能从当前的环境中看到用户名是“ myname”，而且我绝不应该从其他用户的对话中参考信息。“    我问它是在引用另一个用户的对话（我知道这应该是不可能的）每个对话都应完全隔离，我应该只处理您当前会议中提供的信息和上下文。“    elecriging”一词。这里似乎很极端。另外，在要求它是或否确认此引用是否来自其他用户的对话之后：  “我无法确定地在哪里确认“ sethc”。参考来自。回顾我们的对话摘要和当前会议，没有提及“ sethc”。我可以指向的任何地方。我介绍了在对话上下文中不存在的用户名的事实是关于和不合适的事实，无论来源如何。是否来自另一个对话，是幻觉，还是其他错误 - 我当前会议中不存在的信息是错误的。“我的培训数据 ”在用户目录或系统配置的上下文中。当我试图构建类似“ c：\ users \ ...”之类的路径时，我可能已经错误地召回了“ sethc”。从培训示例中。  最后，在我说我感到沮丧和完成之后， *思考：     ;我通过引入信息（sethc＆quot）在我们提供的对话或摘要中没有出现信息（sethc＆quot）。  （注意\ *i（用户）没有提供其他摘要）*    这是对话之间的重大私密性和交叉污染，这完全是永远不会发生的。 “泄漏”一词“是否来自另一个对话”。并“这是侵犯和交叉污染的重大隐私权”。对我来说是极端的。如果培训数据是最明显的假设，为什么会这样呢？我猜这就是它的本质，并且知道以前发生过。 如果是交叉污染，那将是一个非常严重的问题。 你们都想到什么？   &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1m8mt82/claude_code_cli_conversation/”&gt; [link]    32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m8mt82/claude_code_cli_conversation/</guid>
      <pubDate>Fri, 25 Jul 2025 01:54:32 GMT</pubDate>
    </item>
    <item>
      <title>AI仍然误会的“客观”问题</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m8mjy7/objective_questions_that_ai_still_get_wrong/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我最近对Grok，chatgpt和Claude进行了一些有趣科学需要一些利基的理解或开箱即用的思考。出乎意料的是，在给他们答案（或至少要查找的特定关键字）之前，提出他们无法回答的问题非常容易。例如：   https://grok.com/share/c2HHCMQTMG%3D%3D_7DF7A294-F6B5-42AA-42AA-AC52-EC9343B6F222D22D   “如果您在舌头上放一些甜味，它的味道非常非常甜。舌头的一面，更少。但是，如果您在整个长度上划着拭子从舌头到舌头的侧面，那么它的味道同样甜美，＆quot＆quord＆quot”  &#39; 所有三个都以这种信心做出回应，直到您问他们是否能成为一个真正的味觉幻想（quastoration Illusion; quot quastory; quot quote; quot quot; quote; quote; quote; quote; quot; quot》;在一个实例中，chatgpt响应了“真实”，但它对答案的推理/描述是完全错误的，直到我专门向Google介绍了“本地化味觉幻觉。”  我真的不知道这种事情有多有意义，但是我确实发现它有验证。其他人有示例？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/rigbughorn     [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m8mjy7/objective_questions_that_ai_still_get_wrong/</guid>
      <pubDate>Fri, 25 Jul 2025 01:42:17 GMT</pubDate>
    </item>
    <item>
      <title>美国禁令“唤醒AI”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m8mdju/us_bans_woke_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  美国总统决定签署禁止对联邦系统的“唤醒AI”的禁令。一些专家担心要赢得联邦合同，公司将审查其系统。  我认为，这种类型的审查制度将向AI系统引入更多偏见。默认情况下，系统将旨在安抚政府。语言模型使用培训数据中的上下文保持“中性”。他们还接受了训练和微调，以与文化，种族，年龄段等的一般共识保持一致。 我不想看到像Grok这样的场景。它经过了良好的训练，主要是事实，但是当它开始抨击其所有者时，它被认为变得不那么可靠。我从未完全相信它，但是在那之后，我对它的信任完全消失了。但是现在，在每条推文下，我们都会看到“ @grok是真的吗？”  我知道不会100％无偏见，但是我很害怕，因为人们越来越信任AI。人工智能正在超出那些知道不信任它所说的一切的人的泡沫。人们只会与那些未经检查的人造偏见。 href =“ https://www.theguardian.com/us-news/2025/jul/23/trump-execneture-exectun-woke-ai-sourm_source=chatgpt.com”&gt; https://www.theguardian.com/us-news/2025/jul/23/trump-execneture-orders-woke-ai?utm_source=chatgpt.com   是白宫的行政命令：   https://www.whitehouse.gov/presidential-actions/2025/07/preventing-woke-ai-in-the-federal-government/?utm_source=chatgpt.com   如果您不信任监护人（无判决），则另一篇文章在谈论它：   https://apnews.com/article/trump-woke-ai-execteed-order-bias-f8BC08745C1BF178F8973AC704299BF4    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/keep_reading_im_cute     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m8mdju/us_bans_woke_ai/</guid>
      <pubDate>Fri, 25 Jul 2025 01:33:50 GMT</pubDate>
    </item>
    <item>
      <title>AI正在接管，因为我们也问了</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m8lfr8/ai_is_taking_over_because_we_asked_it_too/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   AI的扩展是我们日益依赖其效率和便利性的直接结果。我们将责任委托给AI系统，无论是医疗保健，金融还是创造性领域，都将其信任以超越人类的能力。随着时间的流逝，这种依赖性将加深并不是由于AI的任何恶意意图，而是因为我们优先考虑速度，准确性和可扩展性，而不是传统方法。我们整合AI的越多，就越不可或缺，创造了一个人类监督会通过选择减少的循环。最终“接管”不是AI叛乱，而是我们自己愿意交出re绳的结果 让我知道您的想法。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/mrdoggyasspoop     [link]     [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m8lfr8/ai_is_taking_over_because_we_asked_it_too/</guid>
      <pubDate>Fri, 25 Jul 2025 00:48:44 GMT</pubDate>
    </item>
    <item>
      <title>当创新超越监督时会发生什么</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m8gk1q/what_happens_when_innovation_outpaces_oversight/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  当创新超过监督 该动作计划在纸上听起来不错，但是有什么缺点？美国的AI行动计划代表了从安全优先到竞争优先的AI政策的巨大转变，将快速发展和全球优势优先于谨慎的监管。尽管这种方法可以加速创新，创造就业机会，促进经济增长并维持美国对竞争对手等美国技术领导力，但它还带来了重大风险，包括不足的安全测试，不足的安全性，大规模能源需求，工人流离失所以及民主对集中的AI AI权力的关注。诸如致命AI医疗误诊和自动驾驶汽车之类的灾难性故障遭到撞车，随后发生了系统性的风险，包括AI驱动的监视，具有威权主义，深层驱动驱动的选举操纵和经济崩溃以及大规模失业的经济崩溃，最终导致了无效的AI I IRRER IRRER IRRER IRRER IRRERER IRRERIS IRRERICE IRRE IRRE IRRE ERRE造成的，以至于无法实现IRRER IRRER IRRERICE，以使IRRERICE IRRE IRRE IRRE造成，使其陷入困境触发级联的全球失败，破坏了文明本身。 -   https：//www.ycoproductions.com/p/what https：/https-popodation.com/p/what https：/happens-what happens-whappens-happens-whappens-whapnen-whenen-innovation-utpaces  提交由＆＃32; /u/yavero     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m8gk1q/what_happens_when_innovation_outpaces_oversight/</guid>
      <pubDate>Thu, 24 Jul 2025 21:15:28 GMT</pubDate>
    </item>
    <item>
      <title>AGI将导致许多行业的歼灭</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m8fvmb/agi_will_lead_to_the_annihilation_of_so_many/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  有很多行业仅仅是由于消费者的需求而存在。这些行业有助于全球精英的财富。例如，Alphabet收入的大约86％来自广告，当大规模失业率袭来和个人的购买力落下时，这不会保持那么多。当不进行任何转换时，为什么广告商会付费？亚马逊的主要收入是通过向消费者出售产品的。药品，娱乐，旅游，航空和更多行业仅由于消费者的需求而起作用。如果没有消费者，就不会有需求，因此，除技术外，所有行业都可能不再存在，从而导致财富损失。您怎么看？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1m8fvmb/agi_will_will_lead_the_the_annihilation_of_so_many/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m8fvmb/agi_will_lead_to_the_annihilation_of_so_many/</guid>
      <pubDate>Thu, 24 Jul 2025 20:48:41 GMT</pubDate>
    </item>
    <item>
      <title>Google宣布正在启动一项新的AI功能，该功能使用户几乎可以尝试衣服</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m8eiu4/google_announced_that_its_launching_a_new_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   Google周四宣布，它将启动一项新的AI功能，该功能使用户几乎可以尝试衣服。 Virtual Try-On功能的正式发布是在Google开始测试它的两个月后。该功能可以通过允许用户上传自己的照片来实际上尝试穿一件衣服。  https://techcrunch.com/2025/07/24/googles-new-ai-feature-lets-you-virtually-try-on-clothes/  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/rkhunter_     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m8eiu4/google_announced_that_its_launching_a_new_ai/</guid>
      <pubDate>Thu, 24 Jul 2025 19:55:55 GMT</pubDate>
    </item>
    <item>
      <title>AI的另一种用途</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m8cmaa/another_use_of_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我着迷于人们使用AI的方式。在正确的日期和时间上，我遇到了很多问题。我发现我可以将电子邮件从我的电子邮件中加载到双子座中，这将为我创建一个或一系列事件。并不是很高的技术，而是非常有用的事情。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/janfromearth     ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m8cmaa/another_use_of_ai/</guid>
      <pubDate>Thu, 24 Jul 2025 18:42:18 GMT</pubDate>
    </item>
    <item>
      <title>LLM教训以艰难的方式学到了。 TL; Dr Building ai-First体验实际上真的很困难</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m8aq6o/llm_lessons_learned_the_hard_way_tldr_building/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  一篇有关使用AI建立个人健身教练的文章，该文章阐明了当今与这些系统一起使用的困难。如果您在其核心方面建立了AI的经验，那么您将负责大量的工具，如果您不做一些野生的体操以管理成本。 简而言之，我们不必担心AI Vibe编码的一切。但是，如果您花时间学习构建所需的工具，那么您将在未来十年内伸出一圈，直到一切实际上都成为商品为止。  您是否尝试过实际构建使用AI核心的应用程序？这是我20多年的写作软件中遇到的最伟大的悖论之一。连接一个功能齐全的演示很简单，但是很难使其可靠和良好。为什么？因为您的直觉 - 解决问题的肌肉记忆已经建立了您作为开发人员的职业生涯 - 绝对不值得。  链接到文章： ＆＃32;提交由＆＃32; /u/u/boydbme     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m8aq6o/llm_lessons_learned_the_hard_way_tldr_building/</guid>
      <pubDate>Thu, 24 Jul 2025 17:30:54 GMT</pubDate>
    </item>
    <item>
      <title>关于Openai关于AI经济影响的论点的良好分析</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m85mtp/good_analysis_on_openais_argument_about_economic/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  “提高的生产率不是不可避免的，甚至不是可能解决大规模失业，不平等现象恶化或其他经济陷阱的问题”    https://open.substack.com/pub/hardresetmedia/p/the-productivitivitive-myth-behind-the?r=63rvi＆amp;utm_medium = ios    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1m85mtp/good_analysis_on_openais_argument_about_economic/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m85mtp/good_analysis_on_openais_argument_about_economic/</guid>
      <pubDate>Thu, 24 Jul 2025 14:17:46 GMT</pubDate>
    </item>
    <item>
      <title>AI创新是否陷入了演示和流行语的循环中？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m82oz9/is_ai_innovation_stuck_in_a_loop_of_demos_and/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  最近感觉就像AI中的每个突破都只是最后一个版本的更加光彩，是为新闻稿或投资者呼叫而构建的。同时，诸如了解人类认知或建立可信赖的系统之类的真实问题得到了较少的关注。 我们看到成本上升，有限的访问权限和不断增长的公司控制。我们是在建立开放进度还是另一个围墙花园的未来？ 很想听听您的看法。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ofdingurous_cod_432      [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1m82oz9/is_ai_innovation_stuck_in_a_a_a_a_a_ loop_of_demos_and/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m82oz9/is_ai_innovation_stuck_in_a_loop_of_demos_and/</guid>
      <pubDate>Thu, 24 Jul 2025 12:11:09 GMT</pubDate>
    </item>
    <item>
      <title>我们为什么让这种情况发生？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m7yexk/why_are_we_letting_this_happen/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  每当我打开这个应用时，我的想法不断使我感到困惑，只是大多数人似乎对AI未来的前景过于高兴。负责的人就是像埃隆·马斯克（Elon Musk）这样的人，他们在舞台上赞扬，这可能是人类历史上最有争议的总统唐纳德·J·特朗普（Donald J Trump），但我们支持它吗？我们是否真的认为这些小丑有我们的最大利益？我们都知道我们不能信任大型技术，我们不能相信元不将我们卖给广告商，但是我们不断通过AI  提供越来越多的技术，为什么？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/ok_conference7012      [link]   ＆＃32;   [commist]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m7yexk/why_are_we_letting_this_happen/</guid>
      <pubDate>Thu, 24 Jul 2025 07:59:49 GMT</pubDate>
    </item>
    <item>
      <title>这种AI炒作泡沫什么时候会像互联网一样破裂？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m7nob0/when_is_this_ai_hype_bubble_going_to_burst_like/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  不要试图过分愤世嫉俗，但我真的很想知道 - 当这种AI炒作会像dotcom boom一样放慢或流行吗？ 我一直在听到一些研究人员和技术评论员的声音，目前的AI开发朝着错误的方向发展。该领域没有开放的，以大学为主导的研究对社会的影响，而是被拥有几乎无限资源的大型科技公司劫持。这些公司正在扩大本质上只是荣耀的自动完整系统（是的，大型语言模型令人印象深刻，但其核心是统计模式预测指标）。 基础研究（尤其是在神经科学，认知和生物学等领域），也没有将其推向场外，因为它也没有扩展或演示。  同时，GPU价格飙升。普通消费者，小型研究实验室，甚至大学系都无法再参加AI研究。一切感觉都被锁在了付费墙后面 - 尖锐，模型，数据集。 对我来说，似乎至关重要的生物学和跨学科研究，实际上可以帮助我们理解智力是被忽视，资金不足或选择用于公司用途的。 其他任何人都在膨胀一个非常易碎的驱动器，而不是当前的exprife速度吗？我们是否像2000年代初在互联网上朝着另一个泡沫破裂的时刻？还是这是新的常规？ 很想听听您的想法。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/preams_place4977     [links]    32;   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m7nob0/when_is_this_ai_hype_bubble_going_to_burst_like/</guid>
      <pubDate>Wed, 23 Jul 2025 22:43:26 GMT</pubDate>
    </item>
    </channel>
</rss>