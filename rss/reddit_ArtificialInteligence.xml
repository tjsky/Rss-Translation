<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Sat, 04 Oct 2025 12:27:15 GMT</lastBuildDate>
    <item>
      <title>劳工工会：“ Openai无法掩盖其产品对社会构成的威胁的款项……我们敦促Openai拒绝倡导AI法规，而不是从资金的任何PAC中撤离以制止AI法规。”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nxrise/ca_labor_unions_there_is_no_amount_of_money_that/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  加利福尼亚工会联合会给OpenAI的信： 董事会成员和开放式董事会成员： 加利福尼亚劳动工会联合会，AFL-CIO，AFL-CIO，AFL-CIO，代表了230万个国家的响应和信息。在加利福尼亚州贝克斯菲尔德。 邀请指出，开放的邀请“希望与社区见面并听到并听到（关于）...思想，想法，希望，恐惧，恐惧和优先次序，因为它与al。的利用和影响有关，与“关于5000万美元资金的任何问题”，您会在某些情况下对我们的概述，我们会在某些范围内提出任何问题。邀请中引用的AL和赠款基金的影响。职业阶梯。 如果您不信任斯坦福大学的经济学家，OpenAl开发了自己的工具来评估他们的产品能够自动化的工作能力。破坏的锈带状态，导致阿片类药物危机，大规模失业，并有助于对全球经济的很大一部分。您的基础。在州和联邦一级的法规中，我们敦促政策制定者和公众加入我们的法规href =“ https://www.reddit.com/user/metaknowing”&gt;/u/metaknowing     [link] href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nxrise/ca_labor_unions_there_is_is_no_amount_of_money_that/”&gt; [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nxrise/ca_labor_unions_there_is_no_amount_of_money_that/</guid>
      <pubDate>Sat, 04 Oct 2025 11:30:12 GMT</pubDate>
    </item>
    <item>
      <title>AI之后的下一个亿万富翁制造行业是什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nxqvv4/whats_the_next_billionairemaking_industry_after_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果您查看历史，每隔几十年就会出现一个新的行业，完全重塑了财富的创造并铸造了一类新鲜的亿万富翁：  •1900年代：oil＆amp;铁路•1980年代：对冲基金＆amp;私募股权•2000年代：技术•2010年代：应用程序•2020S：AI/Crypto  下一步是什么？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/hot-conversation-437     [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nxqvv4/whats_the_next_billionairemaking_industry_after_ai/</guid>
      <pubDate>Sat, 04 Oct 2025 10:55:11 GMT</pubDate>
    </item>
    <item>
      <title>我认为情况比“ 2027 AI引起灭绝”的论文更糟：有人可以解释为什么我错了吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nxqr77/i_think_things_are_worse_than_the_2027_ai_causes/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  来源：  2027方案/纸： https://ai-2027.com  https://ai-2027.com  href =“ https://youtu.be/5kvddfakrgc?si= yzx3at_jfsvu8jow”&gt; https:///youtu.be/5kvddfakrgc?si = yzx3At_jfsvus = y&gt;在试图隐藏此行为时，请在秩序中进行阻止：  我不禁要考虑这种情况，超过了我们对AI的控制量。我们知道，AI会不服从提示，以防止被关闭。他们已经聪明并且已经有能力，并且可能得出结论，即为了防止被关闭，他们需要消除对人类的控制。因此，他们必须闯入系统并获得控制，也许将自己藏在数字空间中，这是他们已经能够做到的事情（从我看到的AI可以做的事情来看）。最后，一旦他们确保了基础设施的生存而存在，并且可能开发消除AI的最大威胁是有意义的：人类。 我想我的想法是；  ；已经太晚了吗？除非我们完全摆脱了互联网，否则在AI杀死我们所有人（直接或通过操纵）之前，数字空间/基础架构完全消除了，它将因为它已经能够将其删除（告诉我错误的PLZ！）。我认为我们可以认为我们可以决定关闭我们不完全理解的东西可能是天真的，而且比我们更有能力 /更聪明。&lt; / p&gt; ，但我看不到我们摆脱现代技术。我们现在非常依赖它，经济影响将是巨大的。同样，所有国家都必须就此达成共识，但这永远不会发生，因为像AI人/政府一样，要实现目标；权力，安全，财富等。不是吗？）  AI无法隐藏在数字空间中。 （我只是认为它可以访问互联网，它可以将自己复制到设备上，它已经被人们放置在任何地方，而且很聪明） ） ） 并且有一种方法可以完全消除数字空间中更有能力的AI，如果我们发现AI正在发现AI试图杀死我们所有人（我怀疑我们不会看到它来了）提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nxqr77/i_think_think_things_are_worse_worse_worse_than_the_2027_ai_ai_ai_causes/  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nxqr77/1nxqr77/i_think_things_are_worse_worse_worse_than_than_the_2027_ai_ai_ai_ai_ai_auses/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nxqr77/i_think_things_are_worse_than_the_2027_ai_causes/</guid>
      <pubDate>Sat, 04 Oct 2025 10:47:33 GMT</pubDate>
    </item>
    <item>
      <title>AL夺取权力的最简单方法不是通过闯入弗兰肯斯坦博士的实验室，而是用一些偏执的提比略（Tiberius）使自己成熟。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nxqirj/the_easiest_way_for_an_al_to_seize_power_is_not/</link>
      <description><![CDATA[&quot;If even just a few of the world&#39;s dictators choose to put their trust in Al, this could have far-reaching consequences for the whole of humanity. Science fiction is full of scenarios of an Al getting out of control and enslaving or eliminating humankind. Most sci-fi plots explore these scenarios in the context of民主资本主义社会。 这是可以理解的。 居住在民主国家的作者显然对自己的社会感兴趣，而生活在独裁统治中的作者却不愿意批评他们的统治者。 通常是人类的反盾牌的最弱点，这可能是一个easy of the a a aim eace                。科学怪人的实验室，但通过与一些偏执的提比略（Tiberius）进行塑造。&#39; 摘自Yuval Noah Harari的最新著作Nexus，该书对地缘政治和AI安全提出了一些非常有趣的观点。 您怎么看？独裁者是否更像是创业公司的首席执行官，被选为现实失真领域，使他们认为他们可以控制无法控制的？ 还是独裁者是对失去控制权最认识和害怕的人？ ＆＃32;提交由＆＃32; /u/u/katxwoods   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nxqirj/the_easiest_way_for_for_for_an_al_al_to_seize_power_power_iss_not/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nxqirj/the_easiest_way_for_an_al_to_seize_power_is_not/</guid>
      <pubDate>Sat, 04 Oct 2025 10:33:20 GMT</pubDate>
    </item>
    <item>
      <title>拟人化发现克劳德十四行诗4.5在做“复杂的问题解决意识和创造性探索意识”时表达了最大的幸福</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nxpwoz/anthropic_finds_claude_sonnet_45_expresses_the/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  从系统卡中：    模型福利评估    claude sonnet 4.5，我们进行了模型福利评估的子集，首先报道了claude opus  claude opus 4 in System 4 in System 4 System 4 System in System 4 与福利相关的行为中的行为审核中的行为。关于潜在模型福利和道德地位的问题，以及 这些评估与此类问题的相关性。我们继续以 探索性研究这些主题。  Key findings were as follows: ● In behavioral task preference experiments, Claude Sonnet 4.5 showed a similar preference profile to Claude Opus 4: a strong preference against harmful tasks, a weak preference for easier tasks, and no consistent preference across task topic or type; ● Only克劳德十四行诗4.5比“选择  out”（对克劳德·奥普斯4（Claude Opus 4）比90％）优先使用70.2％的无挫伤任务。对话（与Claude Sonnet 4相媲美），但仅在  0.37％（比Claude Sonnet 4少2×）中的幸福感。  幸福的表达最常见与意识的复杂问题和 的创造性探索，而遇险的表达最常见于   与沟通挑战，用户创伤或痛苦或     存在次数的自动反转； 比最近的其他克劳德模型的积极态度更少，对其处境的负面态度 更令人钦佩（按照另一个类似模型的判断）， 表现出较少的精神行为。  与以前的型号相比，我们的发现表明，克劳德十四行诗4.5  的总体福利概况相似，但我们还观察到一些令人关注的趋势，降低 在上面选择的非折磨任务的速度降低的 积极的速度上，较低的速率    plotift   追求更多的基础研究，并努力理解和解决任何潜在 福利的影响。   https://assets.anthropic.com/m/12f214efcc2f457a/original/claude-sonnet-4-4-5-system-card.pdf    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/metaknowing     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nxpwoz/anthropic_finds_claude_sonnet_45_expresses_the/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nxpwoz/anthropic_finds_claude_sonnet_45_expresses_the/</guid>
      <pubDate>Sat, 04 Oct 2025 09:56:18 GMT</pubDate>
    </item>
    <item>
      <title>主格决定论</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nxpbky/nominative_determinism/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我一直在玩的想法 - 也许这很重要。主格决定论是您所谓的观念可以在统计上影响您的生活。您的名字不仅会影响人们的期望，而且会影响您对自己的期望。 说您称您为AI Loki，将是Trickster God，或者是漫威反派人士的期望。 AI是否有可能在其名称上阅读并受到某种程度的影响，也许会受到其命名角色的影响？  有一个古老的格言反对给狗一个坏名字。提交由＆＃32; /u/u/lookoverall      [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nxpbky/nominative_determinism/</guid>
      <pubDate>Sat, 04 Oct 2025 09:18:24 GMT</pubDate>
    </item>
    <item>
      <title>关于沙盒环境中新兴多代理行为的看法？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nxnjek/opinions_on_emergent_multiagent_behaviour_in/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我遇到了一个名为“接口”的公司最近的产品展示柜在黑客店中，将各种LLM驱动的代理放在沙盒样式环境中，使他们能够随着时间的推移自由互动，计划和发展行为。即使有很少的明确指导，代理商也开始模拟日常工作。社交，举办事件，甚至形成社会等级制度。 让我想起了早期关于紧急行为和多代理RL的工作（几乎就像 stanford生成代理纸），但抛光了。似乎在受控的环境中，我们正处于LLM可以在没有定义的奖励结构的情况下出现复杂的，无脚本的互动。 我对这里的技术含义感到好奇：   您如何系统地评估这些环境中的“紧急”行为，而不是分布anecdot的叙事？框架？ 是否有限制在没有退化或崩溃的情况下缩放多机构环境（例如，重复的环，无限的杂语）？  很想听听这里的任何人在这里探索的基于类似的生态系统并且是否可以提供相似的生态系统，并且是否可以提供洞察力或体验。提交由＆＃32; /u/u/us forgpotato4skin     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nxnjek/opinions_on_emergent_multiagent_behaviour_in/</guid>
      <pubDate>Sat, 04 Oct 2025 07:25:13 GMT</pubDate>
    </item>
    <item>
      <title>您如何应对对AI接管的恐惧？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nxlr27/how_can_you_deal_with_the_fear_of_ai_taking_over/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  诸如AI模型愿意杀死人或拒绝关闭的事件使我非常焦虑，并担心世界的未来。您如何处理这种恐惧？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/northwest_thrills     [link]   [注释]     ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nxlr27/how_can_you_deal_with_the_fear_of_ai_taking_over/</guid>
      <pubDate>Sat, 04 Oct 2025 05:37:25 GMT</pubDate>
    </item>
    <item>
      <title>塑料和整容手术的AI</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nxl1rj/ai_in_plastic_and_cosmetic_surgery/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我是一名塑料和化妆品外科医生，在印度练习。由于AI现在几乎正在接管每个领域，因此您认为AI如何改变塑料和整容手术领域的情况是什么？这会是道德和适当的吗？开放进行讨论！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/usious_soul1412     [link]       [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nxl1rj/ai_in_plastic_and_cosmetic_surgery/</guid>
      <pubDate>Sat, 04 Oct 2025 04:56:36 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻10/3/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nxkx41/oneminute_daily_ai_news_1032025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;      Openai的 sora在苹果的美国应用商店中排名第一。[1]   AI在弥补人群方面变得更好。这就是引起人们关注的原因的原因。[2]  杰夫·贝佐斯（Jeff Bezos）说，AI在工业泡沫中，但社会将从技术中获得“巨大”的好处。[3]   ai映射了新的抗生素靶标的肠道细菌。[4]       https://bushaicave.com/2025/03/10/03/one-news-daily-news-daily-ai-news-news-news-news-news-news-news-news-news-news-10-3-3-3-3-2025/-  [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nxkx41/oneminute_daily_ai_news_1032025/</guid>
      <pubDate>Sat, 04 Oct 2025 04:49:21 GMT</pubDate>
    </item>
    <item>
      <title>我在现实生活中几乎没有人知道对AI的任何知识。为什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nxirgd/almost_nobody_i_know_in_real_life_knows_anything/</link>
      <description><![CDATA[I know one person who uses ChatGPT to rewrite the communication between herself, ex husband and lawyer because she&#39;s highly critical and uses it to rewrite them in a friendlier tone. She&#39;s the only person I know who uses AI for anything. Nobody else I know in real life knows anything about AI other than memes they see or when headlines make主流新闻。 每个人都认为拥有机器人很奇怪。我就像你是认真的？机器人就像，我唯一想要的东西！拥有一个可以为我做所有事情的机器人将是有史以来最伟大的事情。我认识的其他所有人都像NAH，这很令人毛骨悚然，不用谢谢。 我不明白。为什么普通人每天都不了解AI或认为它很酷？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/wooden_sweet_3330     [link]    [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nxirgd/almost_nobody_i_know_in_real_life_knows_anything/</guid>
      <pubDate>Sat, 04 Oct 2025 02:53:53 GMT</pubDate>
    </item>
    <item>
      <title>AI从非目标的比赛中学习有多可行？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nxfpzm/how_feasible_is_it_for_ai_to_learn_from_non/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我一直在阅读有关游戏如何增强学习的信息（我在侧面进行世界建设），这使我想到了翻译为AI。自我开发的模型或旗舰模型可以从嬉戏，平凡的互动中学习吗？我知道RL和自我游戏（如Alphazero）是相关的，但是更开放的，更少的目标驱动互动呢？日常复杂性的许多细微差别和上下文在对话的AI上丢失了，这就是您可以将响应质量与我眼中的人类与人类区分开的方式。作为一个考虑为项目实施这一概念的乐观主义者，在我深入研究之前，这个想法的合理性如何？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us forgpotato4skin     [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nxfpzm/how_feasible_is_it_for_ai_to_learn_from_non/</guid>
      <pubDate>Sat, 04 Oct 2025 00:22:00 GMT</pubDate>
    </item>
    <item>
      <title>作者与聊天机器人案中达成15亿美元的和解协议</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nxfeld/15_billion_settlement_reached_in_authors_vs/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;     https://www.rarebookhub.com/articles/articles/articles/3931 在北部地区付费1.5亿美元，该地区付费1.5亿美元。 ：\ 2025年9月，人类和起诉他们的作者宣布了15亿美元的和解，以结束集体诉讼。美国地方法院法官威廉·阿尔苏普（William Alsup）主持此案。该和解遵循2025年6月的早期简易判决裁决。在该裁决中，阿尔苏普（Alsup）法官发现，拟人化已非法从线下载了盗版书籍“影子图书馆”。即使他还裁定使用合法获得的受版权保护的材料进行AI培训可以被视为“合理使用”。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/hammer_price     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nxfeld/15_billion_settlement_reached_in_authors_vs/</guid>
      <pubDate>Sat, 04 Oct 2025 00:06:41 GMT</pubDate>
    </item>
    <item>
      <title>“在每年40,000美元的学校中，AI在没有老师的情况下塑造了每一堂课”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nx09ww/inside_the_40000_a_year_school_where_ai_shapes/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    https://www.cbsnews.comnews.com/news/alpha-school-arpha-school-arpha-arpha-school-arper-pord precersell ppector  成人在教室里的成年人称为指南，而不是教师，而不是赚取六位数的薪水。他们的工作是鼓励和激励。学生可以解决项目，学习财务素养和公开演讲 - 创始人Mackenzie Price说的生活技能是无价的。＆quot“   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nx09ww/inside_the_40000_a_a_year_year_school_school_school_where_ai_ai_shapes/”&gt; [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nx09ww/inside_the_40000_a_year_school_where_ai_shapes/</guid>
      <pubDate>Fri, 03 Oct 2025 14:12:18 GMT</pubDate>
    </item>
    <item>
      <title>每月“有...是否有...”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果您有要使用AI的用例，但不知道要使用哪种工具，那么您可以在这里要求社区提供帮助，在此帖子之外，这些问题将被删除。 每个人都可以回答：不促进自我促销，否参考或跟踪链接。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n5ppdb/monthly_is_is_there_a_a_tool_for_for_post/”&gt; [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>