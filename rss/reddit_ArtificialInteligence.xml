<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Tue, 04 Nov 2025 15:17:06 GMT</lastBuildDate>
    <item>
      <title>人工智能内容现在真的可以通过工具绕过检测器吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oo9q1v/can_ai_content_really_bypass_detectors_now_with/</link>
      <description><![CDATA[我一直在使用 AI 生成一些内容，然后通过 Rephrasy 运行它来完善它。让我惊讶的是它之后通过人工智能探测器的效果如何。例如，Turnitin 和 GPTZero 在每次尝试时几乎都以 0% 的速度被绕过。 起初，我认为这只是一个小小的清理，但现在我想知道：这就是我们正在努力的方向吗？这是一件好事吗？我们现在是否应该担心人工智能生成的内容很容易逃脱检测？很想听听其他人的想法。   由   提交 /u/Dazzling_Occasion102   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oo9q1v/can_ai_content_really_bypass_detectors_now_with/</guid>
      <pubDate>Tue, 04 Nov 2025 15:12:55 GMT</pubDate>
    </item>
    <item>
      <title>为什么 Sam Altman 对 OpenAI 承诺的相关问题反应如此激烈？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oo9lxm/why_sam_altman_reacts_with_so_much_heat_to_very/</link>
      <description><![CDATA[昨天，我在 youtube 上收听了 All things AI 播客，其中 Sam Altman 被问到，当他们的收入相当低时，他们计划如何为所有达到 1 万亿美元以上的交易提供融资，而不是说他们的利润不存在。 我认为这是一个非常相关的问题，特别是当未能履行这些承诺可能导致重大经济后果时。他的回答非常令人不安 - 至少对我来说 - 没有解决问题本身，而是非常防御和讽刺。 对我来说，他并不是一个体现自信的人。充其量感觉很粗略。他甚至强调，这是一个非常激进的赌注。  是否有可能所有技术人员和高管都在效仿，因为他们真的没有其他选择（FOMO？），或者 Altman 和 Open AI 真的是人类创立的最成功、发展最快的企业吗？   由   提交 /u/MattieuOdd   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oo9lxm/why_sam_altman_reacts_with_so_much_heat_to_very/</guid>
      <pubDate>Tue, 04 Nov 2025 15:08:32 GMT</pubDate>
    </item>
    <item>
      <title>适应或落后：人工智能人性化的一面</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oo7ld3/adapt_or_get_left_behind_the_human_side_of_ai/</link>
      <description><![CDATA[人工智能的崛起不仅仅是一个技术故事，也是一个人类故事。虽然大多数人将人工智能与自动驾驶汽车和未来机器人联系在一起，但事实更为直接：人工智能已经渗透到我们从未想过它会触及的工作领域。专家警告说，到 2030 年，我们认为理所当然的一些职业可能会完全消失。 以客户服务为例。由人工智能驱动的聊天机器人现在可以以与人类工人相媲美的同理心来处理复杂的投诉。在金融领域，算法不仅能比人类更快地处理数字，而且还能以惊人的准确度预测市场趋势。即使是创意领域也不安全：人工智能现在可以在几分钟内写文章、创作音乐并生成艺术品。 这对普通工人意味着什么？经济学家警告说，未来数百万人可能需要接受再培训才能找到尚不存在的工作。挑战不仅仅是失去工作，而是变化的速度。与之前的技术变革不同，这次技术变革是实时发生的。 然而，在恐惧之中，也存在着机遇。新的行业和角色不断涌现，需要人类的创造力、同理心和复杂的判断力，而人工智能仍然难以复制这些技能。专家表示，关键是适应性。那些愿意学习、转向和拥抱变革的人可能会以我们无法想象的方式蓬勃发展。 问题不在于人工智能是否会改变劳动力，而在于社会是否会为此做好准备。   由   提交 /u/somehomelessman   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oo7ld3/adapt_or_get_left_behind_the_human_side_of_ai/</guid>
      <pubDate>Tue, 04 Nov 2025 13:48:41 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]人工智能中的原始感知：机器情感框架以及优化与体验阈值</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oo5o60/discussion_protosentience_in_ai_a_framework_for/</link>
      <description><![CDATA[嘿 r/artificial， 我是一名前端工程师，正在苦苦思考为什么《战锤 40K》的帝国禁止人工智能。这促使我写了一篇论文，探讨机器意识实际上是如何运作的——具体来说，是什么将真正的原始情感学习与简单的优化区分开来。  核心理念：并非所有基于反馈的学习都是情绪化的。恒温器可以优化温度，但不会承受压力。原始情感需要通过具有记忆连续性和具体后果的自我模型来解释反馈。  该框架包括： - 优化和原始情感学习之间的区别 - 用于体现反馈的硬件架构（传感器、执行器、能量管理） - “绝望场景” - 当长期的负面反馈削弱坚持意愿时会发生什么 - 为什么试错+体现+自我模型可能会创造功能性知觉 **不声称解决了意识的难题** - 只是提出系统何时从机械反应跨越到像动机一样起作用的可测试标准。  这里是关于情感上的原始感知人工智能的 theisi 链接 https://docs.google.com/document/d/1SU6M-38l8dsX9756Zba7bRWFm45DRDG6/edit?usp=sharing&amp;ouid=110229732793887781065&amp;rtpof=true&amp;sd=true  寻找反馈、批评和我错过的研究方向。对这个框架最强烈的反驳是什么？   由   提交/u/deruniam  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oo5o60/discussion_protosentience_in_ai_a_framework_for/</guid>
      <pubDate>Tue, 04 Nov 2025 12:07:24 GMT</pubDate>
    </item>
    <item>
      <title>如果大多数公司全面采用人工智能，大规模失业是否会导致需求崩溃和利润下降？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oo5ib6/if_ai_adoption_is_at_full_scale_for_most/</link>
      <description><![CDATA[我对经济学的专业知识了解不多，所以请原谅我理解上的任何错误。我非常愿意学习。 我随处可见新闻，大公司正在用人工智能取代大部分员工。这种情况在全世界范围内都在发生，而不仅仅是在美国。如果我们假设人工智能的全面采用会导致大规模失业，那么如果许多人买不起公司销售的相同服务，是否会出现需求崩溃？这也会导致公司利润下降？ 举个例子：如果苹果或谷歌的许多程序员被解雇，许多人将失业，如果许多人不再负担得起他们的服务，苹果或谷歌是否也会遭受损失？ 我确信还有其他不受人工智能威胁的工作可以继续工作，但是，是的，我只是不敢相信人工智能的指数级发展，它如何改变社会，以及我们的社会如何做好准备是为了这种改变。 产品价格是否会降低，作为公司主要由人工智能驱动的补偿？会有更便宜的商品和服务吗？人工智能应用的快速转变会带来新的就业机会和行业吗？目前人工智能采用的状况实际上对全球经济有利吗？   由   提交 /u/Ok_Owl_891   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oo5ib6/if_ai_adoption_is_at_full_scale_for_most/</guid>
      <pubDate>Tue, 04 Nov 2025 11:58:06 GMT</pubDate>
    </item>
    <item>
      <title>零计算机科学背景的医生寻求从头开始构建专业的人工智能知识——从哪里开始？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oo533j/physician_with_zero_cs_background_seeking_to/</link>
      <description><![CDATA[我是一名医生，希望深入研究人工智能并从零开始建立扎实的专业水平的理解。就背景而言，我从高中直接进入医学院，并将我的整个职业生涯都花在医学上——没有任何计算机科学、编码、软件工程或人工智能经验。我基本上是从一个完全的初学者开始的，但我有动力并且愿意投入时间进行自学。我应该从哪里开始？您会推荐哪些基础书籍来帮助我快速入门？哪些在线课程或资源最适合像我这样的人有效地自学？任何关于构建我的学习路径的建议也将非常感激！预先感谢您的建议！   由   提交 /u/PleasantLettuce3282   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oo533j/physician_with_zero_cs_background_seeking_to/</guid>
      <pubDate>Tue, 04 Nov 2025 11:34:53 GMT</pubDate>
    </item>
    <item>
      <title>人工智能不会造成失业，人类会。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oo4bx7/ai_wont_create_unemployment_humans_will/</link>
      <description><![CDATA[如果没有工作可做，那是不是意味着每个人都已经得到了一切。如果没有工作可做，人们仍然悲伤，那是因为当权者没有给予悲伤的人平等的权利。 如果人们真的悲伤，就必须有工作要做，如果他们认为自己没有得到 PS5，那么人工智能就无法生产足够的 PS5。如果他们得不到食物，人工智能就无法生产足够的食物。 所以我的观点是经典的全民基本收入。    由   提交 /u/ResponsibleBanana522   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oo4bx7/ai_wont_create_unemployment_humans_will/</guid>
      <pubDate>Tue, 04 Nov 2025 10:51:25 GMT</pubDate>
    </item>
    <item>
      <title>默认情况下，谷歌会根据你提供给任何人工智能的所有数据来训练其模型，所以要小心，而且他们也不会让你像其他人一样选择退出</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oo49mq/google_by_default_trains_its_models_on_all_data/</link>
      <description><![CDATA[如果你在 Colab、Gemini 应用程序或 Web 应用程序或任何与 Gemini 相关的东西中使用 Gemini，Google 会告诉你要保护自己，因为它们不会.. 至少一点都不好 虽然其他模型提供商允许你选择不接受数据训练，但 Google 不会，除非你放弃任何获得体面体验的机会，否则你基本上会处于隐身状态，无法使用任何工具，如果你不希望你的数据被训练。 真正令人难以置信的是，标准已经制定，并且正在进行一些用户保护，而谷歌根本没有遵循它......但我猜它是谷歌 来自谷歌： &gt; Google Gemini 默认使用聊天记录进行模型训练，但您可以关闭“Gemini Apps Activity”设置以防止将来的聊天记录用于训练；但是，此操作还会禁用保存持久聊天历史记录，因为这两个功能是链接的。未来的聊天记录将保存至少 72 小时以供提供服务，但如果设置关闭，则不会出现在您的活动中或用于培训。对于敏感数据，请使用临时聊天功能或避免使用 Gemini 获取机密信息。  来自 Gemini Apps 隐私中心： &gt;人工审核员（包括我们服务提供商训练有素的审核员）审核我们为此目的收集的一些数据。请不要输入您不希望审核者看到或 Google 用来改进我们的服务（包括机器学习技术）的机密信息。 Google 不会保护您   由   提交/u/NeuralAA   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oo49mq/google_by_default_trains_its_models_on_all_data/</guid>
      <pubDate>Tue, 04 Nov 2025 10:47:32 GMT</pubDate>
    </item>
    <item>
      <title>过度依赖人工智能会带来什么后果？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oo3qoh/what_are_the_consequences_of_relying_too_much_on/</link>
      <description><![CDATA[过度依赖人工智能会带来什么后果，不仅是自动化和所有事情，而且更多的是使用 ChatGPT 来完成所有事情。 ?   由   提交 /u/Money_Inside6519   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oo3qoh/what_are_the_consequences_of_relying_too_much_on/</guid>
      <pubDate>Tue, 04 Nov 2025 10:15:22 GMT</pubDate>
    </item>
    <item>
      <title>人工智能正在悄然取代创造性工作，只是看着它发生。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oo3o30/ai_is_quietly_replacing_creative_work_just/</link>
      <description><![CDATA[wdyt：我的几个朋友正在建立一家数字钱包初创公司。他们已经进行了数周的原型设计，让产品运行起来，找到了供应商，对后端进行了排序等等。 本周他们坐下来制作网站。通常情况下，这会是：聘请设计师，争论颜色，与 Figma 斗争两周。 相反？他们使用了 3 种人工智能工具，一种用于复制，一种用于布局，一种用于视觉效果。他们大概花了3个小时。网站于当晚上线。它看起来……合法。就像一个合适的机构会收取 1000 美元的费用。就在那时，我突然意识到，“人工智能消除创造性劳动”不是什么未来的理论。这已经在创始人层面悄然发生。人们只是不再雇用这些角色了。 wdyt，这只是智能建筑还是对创意人士来说有点悲伤？   由   提交 /u/0xSatyajit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oo3o30/ai_is_quietly_replacing_creative_work_just/</guid>
      <pubDate>Tue, 04 Nov 2025 10:10:56 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士现在可以无需使用语言即可相互交谈</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oo3lv5/llms_can_now_talk_to_each_other_without_using/</link>
      <description><![CDATA[论文摘要：多 LLM 系统利用不同大型语言模型的互补优势，实现单一模型无法实现的性能和效率提升。在现有设计中，LLM 通过文本进行通信，迫使内部表示转换为输出标记序列。这个过程既丢失了丰富的语义信息，又导致了逐个令牌的生成延迟。出于这些限制，我们不禁要问：法学硕士能否进行超越文本的交流？ Oracle实验表明，丰富KV-Cache语义可以在不增加缓存大小的情况下提高响应质量，支持KV-Cache作为模型间通信的有效媒介。因此，我们提出了缓存到缓存（C2C），这是 LLM 之间直接语义通信的新范例。 C2C 使用神经网络将源模型的 KV 缓存与目标模型的 KV 缓存进行投影和融合，以实现直接语义传输。可学习的门控机制选择从缓存通信中受益的目标层。与文本通信相比，C2C 利用了两种模型的深层、专业语义，同时避免了显式的中间文本生成。实验表明，C2C 的平均准确率比单个模型高 8.5-10.5%。它的性能进一步优于文本通信范例约 3.0-5.0%，同时延迟时间平均提高 2.0 倍  https://arxiv.org/pdf/2510.03215   由   提交 /u/MetaKnowing   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oo3lv5/llms_can_now_talk_to_each_other_without_using/</guid>
      <pubDate>Tue, 04 Nov 2025 10:06:55 GMT</pubDate>
    </item>
    <item>
      <title>Mercor AI - 到底发生了什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1onvdcp/mercor_ai_what_the_actual_hell_is_going_on/</link>
      <description><![CDATA[好吧，我在福布斯上看到了这条新闻，Mercor AI 孩子们成为了纸上亿万富翁（https://www.forbes.com/sites/richardnieva/2025/10/30/mercor-youngest-self-made-billionaires/)。 到目前为止，一切都很好，尽管有点难认为三个在湾区长大、技术工人的孩子真的是白手起家。 但是有两个问题我无法理解：  他们的商业模式本质上是为求职者运营一个平台并从中获取分成。为什么他们需要在 C 轮融资中筹集 3.5 亿美元？它不是一个资本密集型业务，它并没有真正开发自己的技术，它只是一个招聘网站！是的，有一些警告，但本质上就是这样。我无法想象这样一个企业（顺便说一句，已经带来了收入）在现阶段需要这么多钱 - 除非他们对招聘进行补贴（例如，需要数据标签机的 A 公司提出支付 50 美元/小时，他们将其提高到 100 美元/小时以吸引更多人）。所以我很想对此有一些见解，因为我真的不明白为什么工作中间人在现阶段需要那么多荒谬的现金注入。 四轮融资后，他们说三位创始人仍各拥有公司 22% 的股份（这意味着创始人总共拥有 66% 的股份）。在四轮不同的融资中筹集了近 5 亿美元后，稀释度仅为 34%，这不是很奇怪吗？至少是很不常见？    由   提交 /u/SpaceCaptain4068   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1onvdcp/mercor_ai_what_the_actual_hell_is_going_on/</guid>
      <pubDate>Tue, 04 Nov 2025 02:11:48 GMT</pubDate>
    </item>
    <item>
      <title>人工智能到底发生了什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ontnb6/whats_actually_going_on_with_ai/</link>
      <description><![CDATA[我真的很困惑，我希望有人能启发我。 公司花费了数千亿美元，所以这一切都必须是真实的，对吧？这不能只是“炒作”而已。公司试图留住投资者的资金，可以吗？他们肯定有一个目标，因为如果回报本身不是史无前例的，那么花费史无前例的金钱是不合理的？ 但我很难理解这一切的去向。我就是不明白。据说一切都进展得非常快，但我并没有真正看到它。很多人似乎认为 5 年后世界将会发生很大的变化，但是具体情况会怎样呢？  说实话，所有这一切让我想象出一个科幻般的不久的将来，人形机器人无处不在，可以治愈所有可以想象到的疾病，还有飞行汽车，而我几乎过着最简单的生活 - 所以这可能是在我身上。  世界正在进入一个新时代，人工智能比工业革命更具变革性，还是大家都在夸大其词？    由   提交/u/oeilgauchedefectueux  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ontnb6/whats_actually_going_on_with_ai/</guid>
      <pubDate>Tue, 04 Nov 2025 00:53:40 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT 并不聪明。这是更奇怪的事情</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1onmxmq/chatgpt_isnt_smart_its_something_much_weirder/</link>
      <description><![CDATA[我最近听了这个采访：https://youtu.be/5CKuiuc5cJM?si=uGUNFTJowEnUrrPC 这个讨论提出了一些我没有听到太多讨论的观点：1)法学硕士无法承认他们不知道或错误，因为在书面训练数据中承认错误是非常罕见的，而人类大多只以非正式和口头的方式谈论不确定性，在写下来之前试图更正确，2) 幻觉是创造性的输出，当问题确实与 1 相关时，它会抑制创造力，因为人类总是在编造一些东西。 它显然要长得多，并且讨论其他问题，但这些都是围绕15 分钟标记以及该主题应该讨论的内容。 如果这些讨论更常见，我深表歉意，但我在这里找不到太多相关信息。   由   提交/u/Procrastin8_Ball   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1onmxmq/chatgpt_isnt_smart_its_something_much_weirder/</guid>
      <pubDate>Mon, 03 Nov 2025 20:25:52 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>