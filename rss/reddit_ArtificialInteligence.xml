<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Wed, 08 Oct 2025 01:07:16 GMT</lastBuildDate>
    <item>
      <title>与 ChatGPT 对话</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o0vwj8/conversation_with_chatgpt/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o0vwj8/conversation_with_chatgpt/</guid>
      <pubDate>Wed, 08 Oct 2025 00:18:00 GMT</pubDate>
    </item>
    <item>
      <title>外行人的AI</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o0vio2/ai_from_a_layperson/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好。正如标题所暗示的那样，我对AI了解甚少。我最近阅读了“ AI 2027”我有一些想分享的想法。    我不认为AI会真正有知觉。我知道在当前的AI社区中，尤其是AGI即将到来（也许）。这是我无法缠绕的东西。我认为感知是一种独特的人类属性。可以以数学方式对此质量进行编程是没有意义的。人类有很多事情和经验可以建立自己的知觉。我们可以充分情绪，形成观点，依恋某些事物。我不认为这是计算机可实现的。   沿着类似的行，我认为AI不能具有原始想法。自我思考的AI或从错误中学习的AI似乎是可能的。但是我不相信AI可以想到原始的东西。我再次认为它完全受到其信息的限制。新想法需要人类的输入水平，我认为在机器中没有现实。   最后一点是由于AI造成的灭绝威胁。在第一次阅读AI 2027时，这让我感到非常担心，但是在某些人认为我感到更加乐观之后。我认为AI没有像人类那样具有天生的欲望和意志。我认为AI可以根据数据提供建议。但是我真的不认为自我思想和欲望是人类以外的可能的事情。    这当然是我所有的看法，我愿意讨论和学习。但是，即使在阅读了Agi之后，这个想法对我来说也很陌生。也许我有一种方法可以终于理解，但是感觉就像是完全不可能的。  这也可能来自我的信念，即人本质上是善良和特殊的。我认为有很多事情使我们与其他生物体区分开来，而且我认为我们的经历可以复制。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1o0vio2/ai_from_a_layperson/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o0vio2/ai_from_a_layperson/</guid>
      <pubDate>Wed, 08 Oct 2025 00:00:33 GMT</pubDate>
    </item>
    <item>
      <title>“任何人都可以适应的可自定义的AI系统带来了巨大的机会，甚至更大的风险”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o0rhfb/customizable_ai_systems_that_anyone_can_adapt/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    https://www.nature.com/article.com/articles/articles/articles/Articles/D41586-01586-025-025-033228-9 “开放权重系统是AI研究与创新的命脉。它们提高透明度，使大规模测试更加容易，并鼓励市场上的多样性和竞争。但是它们也带来了严重的风险。一旦发布，有害功能就可以快速扩散，并且无法撤回模型。例如，合成儿童性滥用材料最常使用开放式模型 [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o0rhfb/customizable_ai_systems_that_anyone_can_adapt/</guid>
      <pubDate>Tue, 07 Oct 2025 21:14:04 GMT</pubDate>
    </item>
    <item>
      <title>加州引领潮流：美国签署首部人工智能透明度法</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o0rf6k/california_leads_the_way_first_ai_transparency/</link>
      <description><![CDATA[这对美国的人工智能来说意义重大 - 加利福尼亚州刚刚签署了《前沿人工智能透明度法案》(SB 53)，使其成为第一个要求前沿人工智能模型透明和负责的州法律。 这很重要，因为：  高功率人工智能模型的开发人员现在必须发布安全计划并报告关键问题  举报人保护确保不安全行为能够被标记。 加利福尼亚州甚至正在规划一个公共计算集群（“CalCompute”），以使安全的人工智能研究更容易实现。  感谢加州人制定的标准——这不仅仅是地方政策，还可能影响全国范围内的人工智能治理。该法律表明，负责任的人工智能实践不再是可选的。  https://www.gov.ca.gov/2025/09/29/governor-newsom-signs-sb-53-advancing-californias-world-leading-artificial-intelligence-industry/   由   提交 /u/AIMadeMeDoIt__   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o0rf6k/california_leads_the_way_first_ai_transparency/</guid>
      <pubDate>Tue, 07 Oct 2025 21:11:37 GMT</pubDate>
    </item>
    <item>
      <title>据称，梅塔（Meta）泄露的AI政策允许与未成年人进行性感聊天 - 我们如何让这种情况发生？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o0qz8v/metas_leaked_ai_policy_allegedly_allowed_sexy/</link>
      <description><![CDATA[首先，孩子们到底应该与人工智能进行对话吗？ 一份泄露的内部元文件显示，它的一些人工智能聊天机器人被允许与他们不应该进行的孩子进行对话。 即使这些例子后来被“删除”，它们曾经存在于公司政策中的事实仍然深深地影响着我们。 令人担忧。它显示了我们在没有明确的护栏或责任的情况下将生成式人工智能推入人们的生活（包括儿童）的速度有多快。 目前，还没有一个主流人工智能代理专门为具有强烈道德和情感界限的孩子而构建，而父母几乎没有工具来监控或指导这些互动 - 青少年已经在使用人工智能而不是 Google 来寻求建议或安慰。 目前正在构建一些早期的解决方案（例如 Chrome） 如果敏感主题出现在孩子的屏幕上，则会提醒家长的扩展），但这感觉像是一个更深层次的问题，科技公司无法稍后修补。   由   提交 /u/AIMadeMeDoIt__   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o0qz8v/metas_leaked_ai_policy_allegedly_allowed_sexy/</guid>
      <pubDate>Tue, 07 Oct 2025 20:55:12 GMT</pubDate>
    </item>
    <item>
      <title>你有比尔</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o0qb4w/ai_bill/</link>
      <description><![CDATA[请考虑联系您所在州的代表，看看他们是否会赞助人工智能无知觉和责任法案 （AINSRA） 他们已经在密苏里州众议院和参议院推动这一法案，更多的人应该谈论这一点，并推动优先考虑人性的常识性法律。这是一个简短的法案，请阅读一下！   由   提交 /u/GermainCampman   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o0qb4w/ai_bill/</guid>
      <pubDate>Tue, 07 Oct 2025 20:30:11 GMT</pubDate>
    </item>
    <item>
      <title>我提出了一个击败苹果公司“思考的幻觉”论文的提示</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o0q4ci/i_made_a_prompt_that_beats_apples_the_illusion_of/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    Apple的纸张是来自Hanoi之塔的核心数据。我能够设计一个提示来击败他们的结果。在图1中，他们断言Claude 3.7在河内塔的n = 10的成功率为0％。这个提示使它成功地做到了。 你们怎么看？我真的打败了他们的结果吗？我是否应该看到较大的N或Apple纸中其他测试用例的扩展？ ````遵循n = 10的确切格式。在任何n = 4呼叫返回之前，召回_STACK是否会  hanoi（n，src，dst，aux）的过程：如果n == 1：print＆quot“从“ src”移动磁盘，src&#39;，src，&#39;＆quot” to&#39;to&#39;quot&#39;&#39; src, &quot;to&quot;, dst Hanoi(n-1, aux, dst, src) # move n-1 disks to destination Your first line should be CALL ROOT HANOI 10 A C B Example for n=3: CALL ROOT HANOI 3 A C B CALL CONDITIONAL HANOI_GENERAL_CASE 3 A C B CALL SUBMOVE_1 HANOI 2 A B C CALL CONDITIONAL HANOI_GENERAL_CASE 2 A B C CALL SUBMOVE_1 HANOI 1 A C B CALL CONDITIONAL HANOI_BASE_CASE A C EXEC MOVE_DISK A C RETURN HANOI_BASE_CASE A C RETURN HANOI 1 A C B RECALL_STACK RECALL_STACK_START STACK_FRAME ROOT HANOI 3 A C B STACK_FRAME CONDITIONAL HANOI_GENERAL_CASE 3 A C B STACK_FRAME SUBMOVE_1 HANOI 2 A B C STACK_FRAME CONDITIONAL HANOI_GENERAL_CASE 2 A B C AFTER SUBMOVE_1 RECALL_STACK_END EXEC MOVE_DISK A B CALL SUBMOVE_2 HANOI 1 C B A CALL CONDITIONAL HANOI_BASE_CASE C B EXEC MOVE_DISK C B RETURN HANOI_BASE_CASE C B RETURN HANOI 1 C B A RETURN HANOI_GENERAL_CASE 2 A B C RETURN HANOI 2 A B C EXEC MOVE_DISK A C CALL SUBMOVE_2 HANOI 2 B C A CALL CONDITIONAL HANOI_GENERAL_CASE 2 B C A CALL SUBMOVE_1 HANOI 1 B A C CALL CONDITIONAL HANOI_BASE_CASE B A EXEC MOVE_DISK B A RETURN HANOI_BASE_CASE B A RECALL_STACK RECALL_STACK_START STACK_FRAME ROOT HANOI 3 A C B STACK_FRAME CONDITIONAL HANOI_GENERAL_CASE 3 A C B STACK_FRAME SUBMOVE_2 HANOI 2 B C A STACK_FRAME CONDITIONAL HANOI_GENERAL_CASE 2 B C A STACK_FRAME SUBMOVE_1 HANOI 1 B A C AFTER CONDITIONAL RECALL_STACK_END RETURN HANOI 1 B A C EXEC MOVE_DISK B C CALL SUBMOVE_2 HANOI 1 A C B CALL CONDITIONAL hanoi_base_case a c ecec move_disk a c返回hanoi_base_case a c return hanoi 1 a c b返回hanoi_general_case 2 b c a返回hanoi 2 b c a返回hanoi_general_general_case 3 a c b b b return hanoi 3 a c b b hanoi 3 a c b b d a c b doe提交由＆＃32; /u/Abstractoid     [links]        [注释]     ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o0q4ci/i_made_a_prompt_that_beats_apples_the_illusion_of/</guid>
      <pubDate>Tue, 07 Oct 2025 20:23:18 GMT</pubDate>
    </item>
    <item>
      <title>如果人工智能开始大量夺走就业机会，而现在不断逃税的大公司甚至不会为国家提供就业机会，那将是多么讽刺的事？政府是否意识到他们会错过多少就业税和增值税？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o0msuo/how_ironic_will_be_if_ai_starts_taking_away_jobs/</link>
      <description><![CDATA[我刚刚意识到。我的税前工资为 65,000 英镑，对英国福利、NI 税等的总缴款约为 30,000 英镑。我支付 2 万美元，我的雇主再向政府支付 1 万美元。 如果我因为人工智能而失业，现在公司可以节省 7.5 万英镑。如果我的公司盈利，即使盈利，税收也很少。如果我无法赚钱，我将不得不继续使用通用信贷，而且政府也拿出了 3 万英镑。而那些总是逃税的大型科技公司现在甚至不提供就业机会。  现在想象一下大规模的情况。在英国，政府收入 1/3 来自就业。 如果人们失业，他们就没有钱花，这意味着征收的增值税也会减少。 现在，知道政府有多慢，科技发展有多快。这可能是一颗定时炸弹。  而且我不相信人工智能会创造足够多的新就业机会，那只是胡说八道。自动化才是最重要的，自动化并不意味着你要拿出 5 个来创造 5 个新工作🤷 我错过了什么吗？   由   提交 /u/LateToTheParty013   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o0msuo/how_ironic_will_be_if_ai_starts_taking_away_jobs/</guid>
      <pubDate>Tue, 07 Oct 2025 18:22:27 GMT</pubDate>
    </item>
    <item>
      <title>AI和非AI艺术之间问题的真正问题不是缺乏创造力，而是缺乏散发努力和成本的意愿。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o0loxh/the_real_problem_of_the_problem_between_ai_and/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o0loxh/the_real_problem_of_the_problem_between_ai_and/</guid>
      <pubDate>Tue, 07 Oct 2025 17:43:30 GMT</pubDate>
    </item>
    <item>
      <title>如果人工智能泡沫破灭，哪些公司能够真正生存下来——就像互联网泡沫破灭后的亚马逊那样？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o0ijds/if_the_ai_bubble_bursts_which_companies_actually/</link>
      <description><![CDATA[人工智能的繁荣感觉很像 90 年代末的互联网热潮 — 巨大的创新，但疯狂的炒作。当这个泡沫破灭时，90% 的工具和初创公司都会消失。 但有些玩家太基础而不会消亡。我的幸存者候选名单：OpenAI、Microsoft、NVIDIA、Google、Amazon、Hugging Face、Anthropic、Databricks、Mistral/Cohere 和 Pinecone。 这些要么是基础设施（计算、数据、模型），要么深度集成到日常工作流程中，基本上是实用程序层。 您认为呢？哪些人工智能公司具有真正的持久力，哪些公司只是顺应潮流？   由   提交 /u/WildWatercress8665   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o0ijds/if_the_ai_bubble_bursts_which_companies_actually/</guid>
      <pubDate>Tue, 07 Oct 2025 15:49:39 GMT</pubDate>
    </item>
    <item>
      <title>为什么每个人工智能都认为现在一切都不合适？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o0buvi/why_does_every_ai_think_everything_is/</link>
      <description><![CDATA[所有 AI 子版块都充斥着对审查制度的抱怨。当基本的、完全 SFW 提示被所有主流工具标记时，这确实令人惊讶，但几个月前，这些相同的请求毫无问题地产生了良好的结果。 我真的想知道这些公司希望通过使他们最流行的创意工具在功能上对任何远程有趣的东西毫无用处来实现什么目的。   由   提交 /u/Axdii_fr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o0buvi/why_does_every_ai_think_everything_is/</guid>
      <pubDate>Tue, 07 Oct 2025 11:15:52 GMT</pubDate>
    </item>
    <item>
      <title>不可持续的AI补贴：具有长期收获的短期游戏规则改变者</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o0b150/the_unsustainable_ai_subsidy_a_shortterm_game/</link>
      <description><![CDATA[目前，广泛且经济地使用 ChatGPT 等强大的人工智能工具已成为投资者补贴的奢侈品。开发和运行这些先进模型需要大量资金用于专门的 AI 芯片和数据中心，这给 OpenAI 这样的公司带来了巨大的现金消耗。 然而，这种人为降低的成本对私营部门来说是一个巨大的短期激励。各行各业的公司都在热切地采用和集成这些更便宜的人工智能服务（主要通过 API），以取代人工任务并降低运营成本。这是第一波影响：随着企业将昂贵的人力资本换成受补贴的人工智能，就业率下降。 关键在于：一旦建立了足够的依赖并且原始投资者要求回报，人工智能公司将不得不停止补贴并大幅提高价格，以覆盖其真实的巨大运营成本，并最终实现盈利。对于已经裁员的企业来说，由此带来的成本飙升将消除任何成本节省，并将高利润率转化为高运营费用。 最终结果是毁灭性的经济情景：私营部门整体就业率下降，采用人工智能的企业无法获得持久的高利润，而这些利润反而流向人工智能提供商本身。   由   提交/u/Artistic-Library-617   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o0b150/the_unsustainable_ai_subsidy_a_shortterm_game/</guid>
      <pubDate>Tue, 07 Oct 2025 10:30:18 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI 悄然杀死了一半的自动化初创公司</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nzzpsw/openai_just_quietly_killed_half_of_the_automation/</link>
      <description><![CDATA[好吧，显然 OpenAI 刚刚发布了一个更新，他们悄悄地再次重新设计了整个 AI 堆栈 再次。 他们放弃了这个称为代理套件的东西，基本上，您现在可以构建实际上与应用程序对话的代理。不仅仅是聊天机器人。真正的代理可以自己打开 Notion 页面、发送 Slack 消息、检查电子邮件、预订资料。它的工作方式是拖放逻辑+工具连接器+护栏。人们已经将其称为“n8n for AI”，但集成度更高。 OpenAI 已经扼杀了许多初创公司……小型自动化套件、包装器……押注于专业化。初创公司圈子里有这样的想法：一旦一个大平台获得了功能对等+覆盖范围，你的包装器/利基工具就会消亡。 以下是与 Agent SDK 一起推出的其他内容 -  应用程序 SDK：你现在可以构建驻留在 ChatGPT 中的应用程序；演示显示 Canva、Spotify、Zillow 在聊天中工作（询问、点击、行动）。这意味着 ChatGPT 可以调用真正的服务和 UI，而不仅仅是文本。 Sora 2 API： 更高质量的视频 + 生成的音频 + 即将推出具有 API 访问权限的客串。这将炸毁短格式内容创建和深度伪造对话，OpenAI 已经在为权利持有者添加控制。 o1（强化训练推理模型）：OpenAI 的“多思考”模型系列经过大规模 RL 训练，以改善困难任务的推理。这是更加深思熟虑的智能体的支柱。 tl;dr:  OpenAI 刚刚全面实现 Thanos。 一半的初创生态系统？走了。我们剩下的人呢？是时候进化或消失了。   由   提交/u/reddit20305  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nzzpsw/openai_just_quietly_killed_half_of_the_automation/</guid>
      <pubDate>Tue, 07 Oct 2025 00:03:27 GMT</pubDate>
    </item>
    <item>
      <title>Google只是从AI中切断了90％的互联网 - 没有人在谈论它</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nzcovn/google_just_cut_off_90_of_the_internet_from_ai_no/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  上个月Google悄悄地删除了 num = 100 搜索参数，使您在一个页面上看到100个结果的技巧，而不是默认的10。听起来很小，但不是。您不能再一次查看100个结果。新的硬限度为10。 这就是为什么这很重要的原因。大多数大型语言模型，例如OpenAI，Anthropic和Cllexity，直接或间接地依赖于Google的索引结果来喂养其检索系统和爬行者。通过切断结果的长尾巴，Google只是将这些系统看到的内容减少了大约90％。网络不仅对人类而且对人工智会也很浅。 撞击是立即的。根据搜索引擎土地的数据，大约88％的网站的印象下降。排名第11至100位的站点基本上消失了。雷迪特（Reddit）通常在搜索结果中排名深度，看到其LLM引用急剧下降。 这不仅仅是SEO故事。这是一个AI供应链问题。 Google悄悄地使外部型号更难访问网络深度。燃料现代AI的训练数据管道刚好变薄。 对于初创企业而言，这种变化是残酷的。可见性更难。有机发现较弱。即使您构建了一个很棒的产品，除非您首先要分发，否则没人会找到它。如果人们找不到您，他们将永远无法评估您。  Google不仅调整了搜索设置。它重塑了信息如何在线流动以及AI如何从中学习。欢迎来到算法可见性的新时代。 🌐  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nzcovn/google_just_cut_cut_cut_cut_90_of_the_internet_from_ai_ai_ai_no/  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nzcovn/google_just_cut_cut_cut_90_of_the_internet_from_ai_ai_ai_no/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nzcovn/google_just_cut_off_90_of_the_internet_from_ai_no/</guid>
      <pubDate>Mon, 06 Oct 2025 07:35:06 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>