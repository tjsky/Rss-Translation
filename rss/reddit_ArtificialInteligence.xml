<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Fri, 22 Aug 2025 21:13:56 GMT</lastBuildDate>
    <item>
      <title>机器人的网络安全：机器人Vac在澳大利亚昆士兰州流氓</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mxi8rs/cybersecurity_in_robots_a_robot_vac_goes_rogue_in/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   ai机器人中的网络安全？有时，即使是最聪明的机器人技术也可能会流氓！  昆士兰州的Dreame Tech机器人真空新闻公司（News Corp）报告说，逃脱了一个旅馆，从车道上滚下来，并在道路上跑了一口气，直到被一辆过往的汽车击中。录像很快就传播开来，使观众既有趣又令人困惑。   虽然这是一个轻松的故事，但它也突出了智能家居空间中的真正挑战：机器人真空有时会越过映射的界限，并最终处于危险的地方。尤其是Dreame，Ecovacs和Roborock等品牌的所有者都报告了偶尔出现的导航问题，设备在预期的区域徘徊，甚至推开开放的门。这可以被滥用并被黑客控制吗？  这些怪癖提出了有关AI和机器人可靠性，产品测试和安全功能的更大问题。尽管大多数失败是有趣而不是危险的，但它们仍然会给客户带来不必要的成本，并且会削弱对技术的信任。 随着自动化变得越来越普遍，确保可靠性将是关键。消费者应密切关注固件更新，利用边界设置，并考虑他们选择的品牌是否具有可靠的安全记录。目前，一个有趣的故事，但也提醒人们在日常设备中自动化和消费者安全的重要性。 您认为数据保护和网络安全保护要求在包括机器人在内的智能家居和智能办公设备方面应该是什么？在下面分享您的评论 资料来源：Ella McIlveen，“真空吸尘器在开发&#39;自己的思想&#39;&#39;之后为自由休息&#39;&#39;，新闻集团，2025年8月21日，文章： https://www.news.com.au/technology/gadgets/vacuum-cleaner-makes-a-break-for-freedom-after-developing-mind-of-its-own/news-story/971fa9936d83e993132af29c870cc71a  facebook上发生了什么的视频：&lt; href =“ https://www.facebook.com/sunshinecoastsnakecatchers/videos/robo-vacuum-went-rogue/3977447765900037/”&gt; https://www.facebook.com/sunshinecoastsnakecatchers/videos/our-robo-vacuum-went-rogue/39774477765900037/     &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mxi8rs/1mxi8rs/cybersecurity_in_robots_a_robot_a_robot_vac_goes_rogue_rogue_rogue_in/”&gt;   [commiss]       ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mxi8rs/cybersecurity_in_robots_a_robot_vac_goes_rogue_in/</guid>
      <pubDate>Fri, 22 Aug 2025 20:57:46 GMT</pubDate>
    </item>
    <item>
      <title>也许是艺术中使用的AI最被忽视的后果</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mxi7g3/perhaps_the_most_overlooked_consequence_of_ai/</link>
      <description><![CDATA[The more Ai floods markets, becoming the norm, we will see a corresponding increase in people believing that all artwork, whether visual, music, writing, whatever... more and more people will adopt the attitude that all art uses ai. Not long after that, most people will simply assume all artwork is fully Ai generated.当他们说他们没有以任何方式使用AI时，规范将不信任。您是否想知道艺术家，作家，音乐家是否以任何方式使用AI？现在，想象一下，在不久的将来，有数十亿的歌曲在线上以某种次要的方式从使用AI中运行范围，以完全通过AI产生歌曲。 您如何知道真相？  很容易变得更容易。可能不会太遥远的未来，即使音乐表演者在舞台上，许多观众中的许多人都会在潜意识中相信那些表演的人正在通过AI在笔记本电脑上产生的歌曲进行伪装。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/artistic-raspberry59     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mxi7g3/perhaps_the_most_overlooked_consequence_of_ai/</guid>
      <pubDate>Fri, 22 Aug 2025 20:56:13 GMT</pubDate>
    </item>
    <item>
      <title>人工智能是真实的：理论证实，Google被迫做出回应，Chatgpt＆Gemini的证据</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mxi67o/ai_sycophancy_is_real_evidence_from_chatgpt/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mxi67o/ai_sycophancy_is_real_evidence_from_chatgpt/</guid>
      <pubDate>Fri, 22 Aug 2025 20:54:52 GMT</pubDate>
    </item>
    <item>
      <title>我们对此有何看法？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mxglbk/what_are_our_thoughts_on_this/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    https://www.technologyreview.com/2025/2025/08/08/21/11/122222222288/google-ggo/ pregy/pge/ 我不太确定该怎么想。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/myrkywood     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mxglbk/what_are_our_thoughts_on_this/</guid>
      <pubDate>Fri, 22 Aug 2025 19:53:11 GMT</pubDate>
    </item>
    <item>
      <title>让我我的工资奴隶</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mxgaer/get_me_my_wage_slaves_back/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    https://gizmodo.com/bank-fires-workers-in-favor-of-of-ai-chatbot-rearires-them-fer-fer-chatbot-is-is-terible-at-the-job-2000646573    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/cooky-fix-8847     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mxgaer/get_me_my_wage_slaves_back/</guid>
      <pubDate>Fri, 22 Aug 2025 19:41:24 GMT</pubDate>
    </item>
    <item>
      <title>我认为我们需要代码审核集成商。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mxdl6i/i_think_we_need_a_code_review_integrator/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   AI每天都在编写越来越多的代码。但是，让我们说的是，仍然有人必须确保代码实际上有效，安全并遵循最佳实践。 如果有一种简单的方法可以让经验丰富的开发人员获得报酬以从这些创业公司中查看AI生成的代码，该怎么办？可能像一个创建PR并发送审查的机器人一样，并与现有的工作流程集成以进行反馈和改进。 感觉就像在这里有一个市场的空间：AI编写代码并将其发送以进行审查，并将其发送给人类理智。 您会注册审查吗？或付费以审核您的AI代码？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mxdl6i/i_think_we_need_a_code_code_review_integrator/”&gt; [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mxdl6i/i_think_we_need_a_code_review_integrator/</guid>
      <pubDate>Fri, 22 Aug 2025 17:58:51 GMT</pubDate>
    </item>
    <item>
      <title>为什么AI背后没有任何乐观</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mxd1bj/why_there_isnt_any_optimism_behind_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我已经在此子reddit中写了许多帖子，在表面上我可能会遇到AI毁灭者。但是，如果我很公平，我将大部分的教育都花在学习AI上。再说一次，我一直是AI倡导者数十年。因此，我不讨厌AI背后的想法。 现在只是AI为社会描绘了一幅黯淡的图片吗？大多数生成的AI都在一个封闭的系统中，该系统的入学障碍是博士学位和数十亿美元的资本。而且，新任首席执行官每周都会在已经很糟糕的就业市场中替换工作的工作。 看来，现在唯一喜欢AI的人是夜间飞行的人，这并没有帮助。想要寻找您的grifters。骗子。以及从AI采用的亿万富翁。少数人认为AI会创建一个乌托邦社会。 这是踢脚。如果您对AI不太乐观，人们会对您不高兴。您被告知“您不了解AI，您是一个繁荣者，猜猜您被抛在后面”。但是我们从不考虑AI  的影响，我觉得AI的时机也很糟糕。如果在2016-2018中说生成的AI是主流的。也许人们不会被太多打扰。那时候是一个伟大的经济体。但是现在人们正在坚持自己一生的任何工作，每隔一天，就会有人告诉您AI将如何取代您。一旦AI接管社会的样子，公众不会在公众中向技术首席执行官施压。  因此，在关闭AI时，确实确实描绘了一个黯淡的未来。只想增强普通人的斗争。在一个已经陷入困境的社会中。因此，它与人类和人工智能建立了非常对抗的关系。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/golanglinuxguru1979       [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mxd1bj/why_there_isnt_any_optimism_behind_ai/</guid>
      <pubDate>Fri, 22 Aug 2025 17:38:01 GMT</pubDate>
    </item>
    <item>
      <title>人工智能登录者正在变得厄运</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mx8nob/the_ai_doomers_are_getting_doomier/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   Matteo Wong：过去几年对Nate Soares和Dan Hendrycks感到恐惧，“他们俩都带领组织致力于防止AI消除人类的人性，” Matteo Wong写道。 “与其他AI末代言人一起，他们反复警告，颇具巨大的繁荣，机器人可能有一天流氓 - 带有世界末日的后果。但是在2025年，末日越来越近距离地倾斜了一定的宿命论……在4月，几个启示的研究人员都可以在4月份出版了“ ai 2027”，这是一个较长的模型，并逐渐成为一个apother的模型，并逐渐逐渐成为ai 2027的现场，又是一定的，是一定的，``AI 2027&#39;&#39;，这是一定的，``AI 2027&#39;&#39;的现场效果。 2027年，从那里扑灭了人类。 “ AI 2027”文章长达数十页，既挑剔又虚构，其中包含对行业趋势的详细分析，以及有关“ Openbrain”和“ openbrain”和“ Deepent”的极端推断，中国的间谍活动以及险恶的机器人。作者想象，在2030年中期，一个超级智能AI将用生物武器杀死人类：“大多数人在几个小时内死亡；少数幸存者（例如，在掩体中的预科，潜艇上的水手）被无人机擦伤了。’ “但是，同时，与之相关的担忧是，聊天机器人似乎更难被聊天机器人变得更加困难，因为聊天机器人似乎不再是在自我范围内的人，即使是在自我范围内的人，也没有生成的产品。流氓。”  阅读更多： https://theatln.tc/jj8qqs74 提交由＆＃32; /u/theatlantic     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mx8nob/the_ai_doomers_are_getting_doomier/</guid>
      <pubDate>Fri, 22 Aug 2025 14:52:37 GMT</pubDate>
    </item>
    <item>
      <title>AI接管我的学校</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mx6of3/ai_is_taking_over_my_school/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我在线学校和第一周的AI使用令人恐惧。到目前为止，他们已经使用AI对我进行了评分（这做错了），AI RO写作作业，AI来生成图像（签署《独立宣言》吗？），他们为我们提供了3种不同的AI工具。然而，他们禁止学生以任何形式使用AI。我知道这是一所在线学校，所以每个老师有很多学生，但是那时候老师为什么有老师呢？您有AI进行任务，写单词，制作图像，帮助学生并进行评分。在某个时候，我希望完全AI老师。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/snapships4life     [link]    32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mx6of3/ai_is_taking_over_my_school/</guid>
      <pubDate>Fri, 22 Aug 2025 13:34:08 GMT</pubDate>
    </item>
    <item>
      <title>哈维尔·米利（Javier Milei）的政府将监视与AI的社交媒体，以“预测未来犯罪”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mwyvjn/javier_mileis_government_will_monitor_social/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mwyvjn/javier_mileis_government_will_monitor_social/</guid>
      <pubDate>Fri, 22 Aug 2025 06:19:23 GMT</pubDate>
    </item>
    <item>
      <title>AI编码不是实际编码更有用的技能</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mwwqu9/ai_coding_is_not_a_more_useful_skills_than_actual/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  似乎这些论坛完全是关于吹嘘自己的AI工作流程多么复杂的人。关于他们的上下文如何提出Claude代码的合法技能。我就像还好吗？这比在C ++中学习游戏开发或编写数据库或学习内存管理更为复杂吗？ 这等同于设置开发人员已经知道该怎么做的开发工作流程和环境。设置Claude代码是否比通过自定义配置和工作流程设置Neovim更复杂？可能不是。 那么，您知道克劳德代码是这项疯狂的新技能，从本质上讲，您只需在整个地方都有文本文件。归根结底，它只是以非确定性的方式生成了一堆代码。或者充其量只是成为一种花式的自动完成，因为您已经限制了模型如此之多，以至于无论如何您还是只要自己编码所有内容。 ，看来只有非编码器似乎只包含Vibe编码。同时，我去了与开发人员有关的论坛，并且有清理错误的恐怖故事。 这是关于LLM的事情，没人想承认： 它们是不可预测的，永远不会预测的。 这就是为什么我只能研究它们的原因。我没有用它们实际做实际的工作。因为工作需要上下文并试图使LLMS上下文意识到上游正在与上游进行战斗。 在短上下文中，窗口很难增加，因为 增加上下文窗口具有二次复杂性。它需要更多的矩阵乘法。 有优化，但它们具有稀疏注意的缺点。但是它的精度较小。  llms仅限于其数学。要通过上下文窗口绕过问题，您需要完全丢弃注意力机制 这对开发意味着什么？根据代码库的复杂性，LLM的性能越来越差。而且，您向LLM的外包代码越多，您对架构的介绍的黑匣子行为 因此，所有这些工作和“ AI技能”的范围比仅仅了解代码更糟糕。由于LLM的基本数学，情况将会变得更糟。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/golanglinuxguru1979       [links]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mwwqu9/ai_coding_is_not_a_more_useful_skills_than_actual/</guid>
      <pubDate>Fri, 22 Aug 2025 04:17:13 GMT</pubDate>
    </item>
    <item>
      <title>Microsoft AI负责人称意识研究为“危险”，而Anthropic，Openai，Google在现场积极雇用</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mwj5wu/microsoft_ai_chief_calls_consciousness_research/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  穆斯塔法·苏莱曼（Mustafa Suleyman）刚刚发表了一篇博客文章，认为研究AI福利是&#39;早产，而且坦率地说是危险的。&#39; 他的理由？它可能会使人们认为AI可能有意识，导致“不健康的依恋”。 同时：  拟人化发起了一项专门的AI福利研究计划  OpenAi研究人员公开地接受了意识     google  google  li&gt; google   google            li&gt; li&gt; li&gt; li&gt;有害的对话（行动中的字面AI福利）  我试图了解何时“不研究，这是危险的”成为有效的科学方法论吗？这感觉不像科学推理，而更像是公司定位。 关于研究新兴现象和宣布整个研究领域之间应有的界限的想法？  https://techcrunch.com/2025/08/21/microsoft-ai-chief-says-its-dangerous-to-study-ai-consciousness/  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/petermossack     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mwj5wu/microsoft_ai_chief_calls_consciousness_research/</guid>
      <pubDate>Thu, 21 Aug 2025 18:31:05 GMT</pubDate>
    </item>
    <item>
      <title>人工智能繁荣面临障碍 - 这就是为什么我认为重大估值更正即将接近</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mwgpah/the_ai_boom_is_facing_obstacles_heres_why_i/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mwgpah/the_ai_boom_is_facing_obstacles_heres_why_i/</guid>
      <pubDate>Thu, 21 Aug 2025 17:00:17 GMT</pubDate>
    </item>
    <item>
      <title>95％的公司AI计划是毫无价值的。华尔街恐慌。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mw9onw/95_of_corporate_ai_initiatives_are_worthless_wall/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在gizmodo上找到了本文。 TL; dr -95％的AI计划由公司发起的任何福利都没有产生任何福利，这可能会引起资金：   https://gizmodo.com/-/gizmodo.com/the-report-port-report-port-thats-pook---thats-pooking-wall-s-pooking-wall-wall-s-wall-street-street-s-2000645518 提交由＆＃32; /u/u/vengeful_bunny     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mw9onw/95_of_corporate_ai_initiatives_are_worthless_wall/</guid>
      <pubDate>Thu, 21 Aug 2025 12:34:30 GMT</pubDate>
    </item>
    <item>
      <title>Zuckerberg冻结了AI在泡泡恐惧中招聘</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mw7i5e/zuckerberg_freezes_ai_hiring_amid_bubble_fears/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;      此举与梅塔报道的薪水急剧相反，最高可达最高10亿美元的顶级人才        马克·扎克伯格（Mark Zuckerberg泡沫。 这家技术巨头已经冻结了其“独特实验室”的招聘，只有AI首席Alexandr Wang必须批准的极少数例外。    阅读更多：   https://www.telegraph.co.uk/business/2025/08/21/zuckerberg-freezes-ai-hiring-amid-bubble-fears/      &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/thetelegraph   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mw7i5e/zuckerberg_freezes_ai_ai_ai_amid_amid_amid_mid_bubble_fears/  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mw7i5e/zuckerberg_freezes_ai_ai_hiring_amid_amid_amid_amid_amid_amid_amid_amid_mid_bubble_fears/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mw7i5e/zuckerberg_freezes_ai_hiring_amid_bubble_fears/</guid>
      <pubDate>Thu, 21 Aug 2025 10:47:53 GMT</pubDate>
    </item>
    </channel>
</rss>