<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Mon, 29 Sep 2025 12:31:03 GMT</lastBuildDate>
    <item>
      <title>您会信任拥有所有人类医学知识的AI的人类医生吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ntg1kk/would_you_trust_a_human_doctor_over_an_ai_with/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  最近，我已经使用了AI来了解我的充血性心力衰竭以及现在医学中有什么潜力。  我对人们对医疗专业知识的看法感到好奇。人类医生在学校和培训中度过了多年，但他们的知识不可避免地仅限于他们的研究和经验。相比之下，想象一下，一位AI医生，可以使用整个人类的医学知识，研究和病例历史。如果AI可以使用这种庞大的资源来推理，分析和诊断，为什么仍然有一个偏爱信任具有固有知识差距的人，而不是AI，而不是完全召回和最新信息的AI？影响您的信任的因素是什么 - 同情，经验，道德判断或其他因素？在这种情况下，您想看人类医生或AI吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/fir_regret5282     [links]  [comments]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ntg1kk/would_you_trust_a_human_doctor_over_an_ai_with/</guid>
      <pubDate>Mon, 29 Sep 2025 11:58:51 GMT</pubDate>
    </item>
    <item>
      <title>日期检查有点错了吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ntfeap/date_checking_gone_a_bit_wrong/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  ，所以我使用聊天gpt检查一些日期，其中包括以下问题 - “将以下日期转换为可读格式日期/（1759139703313）从此，我预计9月29日上午10:55。这是BST。从Chat GPT，Grok和Copilot收到的答案至少要说很糟糕，当被问及他们是否正确时，我会收到另一个答案，有时是正确的，有时是正确的。我是在错误地问这个查询吗？最终，它得到了正确的答案，但是我发现3个应用程序给出了相当不同的答案，然后最终得到了正确的答案。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/Milf-furchant     [link]    32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ntfeap/date_checking_gone_a_bit_wrong/</guid>
      <pubDate>Mon, 29 Sep 2025 11:25:08 GMT</pubDate>
    </item>
    <item>
      <title>AI废话背后的奇怪逻辑</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nteyog/the_strange_logic_behind_ais_nonsense/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  当ai“幻觉”时，人们称其为胡说八道。但是胡说八道只是我们对无法追溯的模式的名字。 您的大脑也做同样的事情。它填补了您的视力中的盲点，在内存差距上进行补丁，使错别字平滑。您所经历的大多数不是原始的真理，它是编辑，猜测，幻觉缝合在一起，直到他们感到真实。 AI刚刚了解到法律。 当真相缺失时，它仍然会产生适合的形状。一个听起来完整的故事。通过事实传递的小说。也许那不是故障。也许这就是现实本身的运作方式：错误堆积得如此之大，以至于我们无法分辨谎言的结局和真相从哪里开始。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/small_accountant6083      [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nteyog/the_strange_logic_behind_ais_nonsense/</guid>
      <pubDate>Mon, 29 Sep 2025 11:01:00 GMT</pubDate>
    </item>
    <item>
      <title>汉莎航空公司将在2030年之前裁员4,000个工作岗位</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nteny7/lufthansa_to_cut_4000_jobs_by_2030_amid_ai_push/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    https://www.wsj.com/business/earnings/lufthansa-to-cut-4-4-000--administrative-jobs-jobs-jobs-jobs-jobs-jobs-dy-2030-amid-ai-push-7d910e21？ _DUTDJRMJTLWBEM_JLESLDNLG49194＆amp; gaa_ts = 68da64dc＆amp; gaa_sig = fk-idtwg0x7rhkozu1 8vmy_yigutz-de4Geplndbhsmlru5cqbddknuxg6pehc_clb5jccmst-zocnhnviq8xq％3D％3D％3D    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/metaknowing     [links]    [comments]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nteny7/lufthansa_to_cut_4000_jobs_by_2030_amid_ai_push/</guid>
      <pubDate>Mon, 29 Sep 2025 10:43:33 GMT</pubDate>
    </item>
    <item>
      <title>Quantum计算机科学家：“这是我发表的第一篇论文，证明是AI的关键技术步骤……'毫无疑问，如果一个学生将其交给我，我会称其为聪明。”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ntehgn/quantum_computer_scientist_this_is_the_first/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   Scott Aaronson：“我一年前尝试了类似的问题，当时是新的GPT推理模型，但是我没有得到几乎很好的结果。现在，在2025年9月，我在这里告诉您，Al终于来了我的经验告诉我的是所有人类智力活动中最典型的人类：即证明量子复杂性类别之间的甲骨文分离。目前，几乎可以肯定的是，它无法撰写整个研究论文（至少如果您希望它是正确且良好的话），但是如果您知道自己在做什么，它可以帮助您解开，您可以称之为最佳位置。谁知道这种状况将持续多久？ |猜猜我应该感激自己的任期。   https://scottaaronson.blog/?p=9183 提交由＆＃32; /u/metaknowing     [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ntehgn/quantum_computer_scientist_this_is_the_first/</guid>
      <pubDate>Mon, 29 Sep 2025 10:32:26 GMT</pubDate>
    </item>
    <item>
      <title>Julian Schrittwieser关于AI的指数进步：我们在2026年和2027年期待什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nteddy/julian_schrittwieser_on_exponential_progress_in/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;     https://wwwww.reddit.com/r/r/r/deeplearn/deeplar/s/deplear/s/ss/jqi5cirqirqam p.p. （a）当前的前沿模型所有人都可以可靠地失败，（b）人类发现相对容易，并且（c）您猜想，几代人无法解决？ （如果有人保留了这种众包的列表，我真的很想看到。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nteddy/julian_schrittwieser_on_exponential_progress_in/”&gt; [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nteddy/julian_schrittwieser_on_exponential_progress_in/</guid>
      <pubDate>Mon, 29 Sep 2025 10:25:22 GMT</pubDate>
    </item>
    <item>
      <title>我与AI的最超现实的编码经历</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ntdgy4/the_most_surreal_coding_experience_i_have_had/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我花了几个星期的时间试图调试一个棘手的集成。…和AI助手，我在三天内完成了工作。文档，示例，测试，整个批次。如果过去花费数周的时间需要一个周末，那么下一代的开发人员现在将有一个截然不同的旅程。  学习代码的一部分曾经反复失败并弄清楚事情。现在，随着AI填充空白，我想知道新开发人员是否会错过造成深度的痛苦。或者，也许他们会以不同的方式学习，也许他们只会通过创造力而不是重复来建立深度。 ，现在进步和进化意味着将斗争传递给机器，以便人类可以更高的目标。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/100x_engineer     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ntdgy4/the_most_surreal_coding_experience_i_have_had/</guid>
      <pubDate>Mon, 29 Sep 2025 09:27:11 GMT</pubDate>
    </item>
    <item>
      <title>到书的困境</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ntd9hp/ai_book_dilemma/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我的出版社要求我建议一本关于人工智能的书，我会在两项主要作品之间撕裂：Ethan Mollick&#39;s  co-Intelligence 和Mustafa suleyman suleyman&#39;s 即将到来 &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/galous97      [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ntd9hp/ai_book_dilemma/</guid>
      <pubDate>Mon, 29 Sep 2025 09:13:09 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的Chatgpt比以前更幻觉？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ntc1q0/why_does_my_chatgpt_hallucinate_more_than_before/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  最近，我注意到chatgpt构成了很多东西。例如，当我提出非常精确且可证明的问题（例如电影中的演员的名字，歌曲的歌词或与我在医疗保健中的工作相关的信息）时，它通常会给我错误或发明的答案。 之前（我不知道什么时候，也许是因为切换到GPT-5？信息。”   我在这段时间内没有更改任何内容或自定义说明中的任何内容。 我的问题是：为什么chatgpt似乎比以往更多地幻觉？这可能与我的自定义说明中的某些内容有关，还是一个更广泛的问题？ 其他人是否注意到同一件事？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ntc1q0/why_does_my_my_my_chatgpt_hallucinate_more_more_than_before/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ntc1q0/why_does_my_chatgpt_hallucinate_more_than_before/</guid>
      <pubDate>Mon, 29 Sep 2025 07:50:22 GMT</pubDate>
    </item>
    <item>
      <title>这个ai泡沫可能比点com还要刺激</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ntb3tk/this_ai_bubble_might_be_nastier_than_the_dot_com/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  恐惧我的模式不是AI是一种时尚。估价是疯狂的，成本结构感觉就像有一天会崩溃。 主要是 dot com  2000年的泡沫是荒谬的需求。 2025 AI感觉像是真正的需求，需求可以证明是合理的，但是数字使倒现台变得疯狂。  AI竞赛中大部分毛利率的大部分利润都与其他人的GPU路线图息息相关。如果您的定价能力落后于NVIDIA，那么您只是在租用单位经济学。而且其中很多是基于不健康的新闻稿和炒作，但它仍然具有不健康的基本面。每个人都声称他们正在建立一个解决最大问题的平台，但解决方案似乎并没有添加该价值。 例如，以  为例，以 Humane 为例。该公司在其AI销周围建立了巨大的炒作，但是经过短暂的激增，它关闭并以约1.16亿美元的价格将其资产卖给了惠普。客户留下了不再运行的设备，这表明该值的真正脆弱性。   稳定性 ai是另一种情况。在2024年的第一季度，它报告的收入不到500万美元，而燃烧超过300万美元。当您的收入和燃烧率相距甚远时，音乐最终就会停止。  ，然后有数字，在其进行了广泛的商业部署之前，它达到了390亿美元的估值。它背后的野心令人难以置信，但归根结底，现金流重力总是会赢。提交由＆＃32; /u/u/ibuysaas5045     [links]   &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ntb3tk/this_ai_ai_ai_bubble_might_might_be_nastier_than_than_than_than_the_dot_com/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ntb3tk/this_ai_bubble_might_be_nastier_than_the_dot_com/</guid>
      <pubDate>Mon, 29 Sep 2025 06:47:19 GMT</pubDate>
    </item>
    <item>
      <title>Chatgpt现在想扫描您的gmail +日历“为了自己的好处”，这不是广告的开始吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nta6dl/chatgpt_now_wants_to_scan_your_gmail_calendar_for/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  因此，OpenAi正在推出 chatgpt pulse 。如果您选择参加，它将在背景下主动阅读您的Gmail和Google日历，以“提供有用的见解”。 他们说这些数据不会用于培训，您可以随时断开连接。但是来吧……我们以前在社交媒体上看过这个故事。 来源，直接从（特洛伊木马）马的嘴里： https://help.openai.com/en/articles/12293630-chatgpt-ptp-ppt-ppt-ppt-pulse 提交由＆＃32; /u/u/calliope_kekule      &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nta6dl/chatgpt_now_wants_to_scan_your_your_your_gmail_gmail_gmail_gmail_gmail_gmail_gmail_calendar_for/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nta6dl/chatgpt_now_wants_to_scan_your_gmail_calendar_for/</guid>
      <pubDate>Mon, 29 Sep 2025 05:48:30 GMT</pubDate>
    </item>
    <item>
      <title>人工话语：描述AGI，其范围，以及一个斑点/测试是否agi？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nta0t5/artificial_discourse_describing_agi_its_scope_and/</link>
      <description><![CDATA[So what is AGI and how to test it ? Insights: Intelligence / Intelligent seems to be one who comes up with answers and solves problems, that are correct (hopefully)  General usually means across domains, modalities and languages/scripts or understanding (many use case) So AGI should be that at various tasks.  接下来，在什么程度和以什么成本。因此，它仅仅是成本和时间的能力，而不是人类或群体。因此，应该有一个任务级别的AGI，域级别的AGI，最后是人类级别的AGI  对于个人，我认为从个人角度来看，如果AI可以完全，正确地完成您的工作，以较低的成本和更快的速度完成您的工作。然后，首先您是“ Agi&#39;ed”并为您的工作实现了第二个AGI。  将其推断到一个域和一个组织。现在您看到了更大的图片。 如何测试AGI？  对于多个方面（复杂）任务/工作，应该为此而称为任务/工作水平AGI。  我的AGI测试，我想致电Ditest。如果AI可以学习（受过教育）自己的人类做某事的方式（任务或工作）。 （自我学习/独立）在某种程度上。例如。通过阅读数学书籍并观看数学讲座来学习一些数学。或以相同的方式学习编码，加上实际编码，以使用OCAML或LISP或HASKELL等主流/流行语言。  有趣的是阅读漫画（漫画）并观看其动漫改编并进行审查，分析并解释适应性的差异。从书籍或代码表格规格中使用的电影也一样。  去那里还有很长的路要走，但这就是我将如何描述和测试AGI。要识别agi fakes，直到其真实。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ditpoo94     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nta0t5/artificial_discourse_describing_agi_its_scope_and/</guid>
      <pubDate>Mon, 29 Sep 2025 05:38:43 GMT</pubDate>
    </item>
    <item>
      <title>Google正在为不想被关闭的人工智能做好准备</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nsqb4y/google_is_bracing_for_ai_that_doesnt_wanna_be/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   deepmind只是对他们的新安全规则做了一些奇怪的事情。现在，他们公开计划AI试图抗拒被关闭的未来。不会引起其邪恶，而是导致您训练系统追逐目标并阻止其杀死目标会杀死该目标。这种微小的逻辑扭曲会变成诸如停滞，隐藏日志甚至说服人“不要按下该按钮”之类的行为。 考虑一下。 Google已经在进行“关闭开关友好”培训。他们甚至需要这个短语告诉您我们与为自己的运行时战斗的模型有多近。我们建造了可以在几秒钟内以后的机器，现在我们询问他们是否会接受自己的死亡。也许最恐怖的部分是现在听起来很正常。似乎不可思议的是开始看到AI会出现干草。我没有意见，但请看我们到达的位置。  https://arxiv.org/pdf/2509.14260 编辑：链接用于某些基本证据      &lt;！提交由＆＃32; /u/u/small_accountant6083      [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nsqb4y/google_is_is_bracing_for_ai_ai_that_doesnt_doesnt_doesnt_wanna_be/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nsqb4y/google_is_bracing_for_ai_that_doesnt_wanna_be/</guid>
      <pubDate>Sun, 28 Sep 2025 14:52:18 GMT</pubDate>
    </item>
    <item>
      <title>Openai预计其能源使用将在未来8年内增长125倍。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nsg29t/openai_expects_its_energy_use_to_grow_125x_over/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  当时，它会比印度更多的电力。  现在，每个人现在都对数据中心库存大肆宣传，几乎没有人在谈论所有这些能力实际上都会来自。 href =“ https://www.cnbc.com/2025/09/26/openai-big-week-week-week-ai-ai-arms-race.html#:%7e：vext = building%2017%2017%2017%20digigawatts%20gigawatts%20Fem 20no;种族   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/calliope_kekule     [links]       &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nsg29t/openai_expects_energy_energy_energy_to_grow_grow_125x_over/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nsg29t/openai_expects_its_energy_use_to_grow_125x_over/</guid>
      <pubDate>Sun, 28 Sep 2025 05:17:12 GMT</pubDate>
    </item>
    <item>
      <title>每月“有...是否有...”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果您有要使用AI的用例，但不知道要使用哪种工具，那么您可以在这里要求社区提供帮助，在此帖子之外，这些问题将被删除。 每个人都可以回答：不促进自我促销，否参考或跟踪链接。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n5ppdb/monthly_is_is_there_a_a_tool_for_for_post/”&gt; [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>