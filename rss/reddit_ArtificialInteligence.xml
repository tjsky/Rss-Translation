<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Wed, 09 Jul 2025 06:24:04 GMT</lastBuildDate>
    <item>
      <title>如果LLM只是自动完成的，为什么它们有时看起来比大多数人更体贴？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lva5u0/if_llms_are_just_fancy_autocomplete_why_do_they/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我通过基于培训数据来预测下一个令牌，从而使大型语言模型起作用 - 它的统计模式匹配，而不是真正的理解。但是，当我与他们互动时，反应通常比我从实际人那里听到的感觉更加清晰，情感聪明和反思。如果他们只是在大规模进行自动完成，为什么他们会如此体贴？这只是他们的培训数据所产生的幻想，还是我们低估了实际能够真正能够？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/thebipolarironman     [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lva5u0/if_llms_are_just_fancy_autocomplete_why_do_they/</guid>
      <pubDate>Wed, 09 Jul 2025 04:53:34 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻7/6/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lv8gtr/oneminute_daily_ai_news_762025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   冒名顶替者使用人工智能与外国和美国官员联系。[1]  教师联盟与人类，Microsoft和OpenAi合作，Microsoft和Openai与Openai合作，开设AI-Training Academy。推理模型。[3]   苹果的最高AI行政人员的pang pang s s叶。[4]   来源包括： https://bushaicave.com/2025/07/07/07/08/one-minute-minute-news-news-news-news-news-7-7-8-8--8--2025/--  [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lv8gtr/oneminute_daily_ai_news_762025/</guid>
      <pubDate>Wed, 09 Jul 2025 03:19:26 GMT</pubDate>
    </item>
    <item>
      <title>人类语言压缩：用更少的单词编程AI</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lv7eb3/humanai_linguistic_compression_programming_ai/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lv7eb3/humanai_linguistic_compression_programming_ai/</guid>
      <pubDate>Wed, 09 Jul 2025 02:25:04 GMT</pubDate>
    </item>
    <item>
      <title>我应该主修人工智能吗？我刚完成高中</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lv7e1o/should_i_major_in_artificial_intelligence_i_just/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿，正如标题所说，我几天前毕业了，AI已经开始来到我所在地区的大学 我想知道的，这是一个更可靠的选择吗？我不认为太多的人会尝试在我居住的地方进行主修，因为它仍然很尚不清楚，但我害怕它成为计算机科学2.0，每个人和他们的狗都完成了计算机科学 有关该主题的任何信息都非常感谢！   &lt;！ -  sc_on- sc_on-&gt;＆＃32;提交由＆＃32; /u/u/yaboiishornyaf     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lv7e1o/should_i_major_in_artificial_intelligence_i_just/</guid>
      <pubDate>Wed, 09 Jul 2025 02:24:44 GMT</pubDate>
    </item>
    <item>
      <title>镜子与黑镜</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lv6pr0/mirror_vs_black_mirror/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  对我来说很奇怪，最近有太多的镜子/螺旋围绕不同的subreddits，而没有谈论黑镜会使您螺旋……（ツ）/em&gt;/       sc_on-&gt; &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/elipsisinc     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lv6pr0/mirror_vs_black_mirror/</guid>
      <pubDate>Wed, 09 Jul 2025 01:51:40 GMT</pubDate>
    </item>
    <item>
      <title>“仅正面评论”：研究人员隐藏了AI提示在论文中</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lv61ri/positive_review_only_researchers_hide_ai_prompts/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  该技术非常简单 - 通过使用与背景相同或使用非常小的字体大小的文本来隐藏AI提示。 AI扫描仪不关心文本颜色或字体尺寸。如果学者正在这样做，那么公众也会。  &#39;Positive review only&#39;: Researchers hide AI prompts in papers  TOKYO -- Research papers from包括日本，韩国和中国在内的八个国家的14个学术机构包含隐藏的提示，指导人工智能工具给他们良好的评论，     &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lv61ri/posistil_review_review_review_only_researchers_hide_ai_ai_prompts/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lv61ri/positive_review_only_researchers_hide_ai_prompts/</guid>
      <pubDate>Wed, 09 Jul 2025 01:18:34 GMT</pubDate>
    </item>
    <item>
      <title>我为综合情感和认知而建立的想法会喜欢反馈或想法</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lv4zkj/an_idea_i_built_to_synthesize_emotion_and/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿，大家， 我一直想共享一段时间。我通常比海报更像是潜伏者，所以如果这感觉有些蓝色。 几个月前，我想出了将情感和认知综合为结构化系统的想法。在一个为期三天的假期周末中，我深入探讨了它，最终创建了一个完整的图表以及一篇简短的论文来解释该概念。 这是我完全从头开始构建的，没有AI，神经科学或认知科学的学术背景。我实际上是一名最终的机械工程专业的学生，​​因此，尽管这是一项严肃的努力，但它比我有时间完全发展的热情项目更像是一个激情的项目。我什至涉足Rust尝试原型的某些方面，但我远非任何具体的东西（我不是程序员）。 这仍然是一项正在进行的工作。肯定有孔和粗糙的边缘，每当我发现值得改进的东西时，我一直在慢慢修改事情。 这就是为什么我把它放在那里的原因。我希望有真正的反馈，建设性的批评，或者可能会在一个想进一步进行的人中引发一个想法。 最终是有用，鼓舞人心还是只是一个有趣的思想实验，我很想听听您的想法。 我建议您从纸上开始，然后在简介之后查看图表。这是一段漫长的阅读，很多东西都包含了很多内容，但是该论文包括有关结论和一些虚构的应用程序场景的重要部分，而图表则介入了所提出的系统的内部工作。 这是指向图的链接：   https://drive.google.com/file/d/178xjveatiwvia7ksvxux1umnvkv68jg_/view?usp = sharing   和纸：   https://drive.google.com/file/d/1jncjt9kr7_qkipvjor3ju1bqlqlljmqgpd/view?usp = sharing    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/thassiogs   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lv4zkj/an_idea_i_i_built_to_synthesize_emotion_and/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lv4zkj/an_idea_i_i_i_built_synto_synthesize_emotion_and//]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lv4zkj/an_idea_i_built_to_synthesize_emotion_and/</guid>
      <pubDate>Wed, 09 Jul 2025 00:27:21 GMT</pubDate>
    </item>
    <item>
      <title>我如何发展我的AI工程师职业？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lv4crc/how_can_i_grow_my_ai_engineer_career/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我最近在AI获得了学士学位，但它来自一所鲜为人知的大学。我找到了我唯一的AI工程师的工作，但我觉得我的价值在这里没有得到认可。我被认为是一个聪明的人，可以做别人做不到的事情，但我没有进步。我想进步我的职业生涯，而不是停滞不前，所以我已经参加了Coursera IBM AI工程师专业证书以改善我的简历。之后，我不确定该怎么办。我正在考虑将自己的节省用于麻省理工学院的机器学习＆amp; AI专业证书，但非常昂贵。感谢您的建议。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ppaaul_     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lv4crc/how_can_i_grow_my_ai_engineer_career/</guid>
      <pubDate>Tue, 08 Jul 2025 23:57:28 GMT</pubDate>
    </item>
    <item>
      <title>停止假装大型语言模型理解语言</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1luxj7j/stop_pretending_large_language_models_understand/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1luxj7j/stop_pretending_large_language_models_understand/</guid>
      <pubDate>Tue, 08 Jul 2025 19:16:07 GMT</pubDate>
    </item>
    <item>
      <title>使用AI来加强民主而不是破坏民主的想法。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1luxegc/idea_to_use_ai_to_reinforce_democracy_instead_of/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  前几天只是考虑一下，并想分享它以查看反馈。  llms可以用作探讨人群对政治的真实意图的工具。民主国家的问题之一，尤其是当今，是在政客及其选民之间进行有用的对话仍然很难。人们和文化变得越来越多样化，政客充其量可以尝试汇总并出售他们认为想要的愿景。  我们喜欢生活在民主国家中，但是即使人们有好主意，也很难分享好主意，并真正尝试达成人们对人们想要的东西的共识。  为此做的聊天机器人可能在那里很有用。它与选民聊天以探究他们真正想要的东西。重要的是，AI不会以一种或另一种方式塑造问题，而是建设性的反馈，以真正了解选民想要什么。然后，他们可以恢复趋势，并对公众真正想要的更好。对于公司进行AI的公司来说，这也是一个很好的卖点。 “我们将与您一起推动政治家真正做您想做的事”如果证明AI是可靠的，则可能是一个很好的卖点。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/dartharchon     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1luxegc/idea_to_use_ai_to_reinforce_democracy_instead_of/</guid>
      <pubDate>Tue, 08 Jul 2025 19:11:00 GMT</pubDate>
    </item>
    <item>
      <title>唯一的AI专家（在工作中学习） -  3个月，没有切实的胜利，老板要求“快速获胜”  - 我是敬酒吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1luv5of/sole_ai_specialist_learning_on_the_job_3_months/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  你好， 我处在一个艰难的位置，并在目前的角色上寻找一些客观的观点。 3个月前，我被聘为该公司的第一位和唯一的AI专家。我正在学习这项工作，从以前的数据专家职位过渡到这个角色。我最初的愿景（以及我被雇用的）是实施大型，战略性的AI解决方案。 现实是……与众不同的。 •没有明显的结果：3个整个月（现在开始我的第4个），我没有产生任何高影响力，有形，有形的结果。我的首席财务官现在明确要求“快速获胜”。和“低悬一起的水果。”我同意他们的反馈意见，结果尚未出现。 •data＆amp; ORG成熟度：这家公司非常精通DATA。我正在从头开始建立数据理解，基础架构和文化。同事通常是不合作/不响应的，管理层提供了关键的反馈，但对技术障碍的明确方向或了解很少。 •技术瓶颈：最初，我什至无法从我们的ERP系统访问数据。我正在使用N8N只是为了从ERP中提取数据，我现在可以。我们还遇到了一个浪费时间的供应商问题。 •内部冲突：我觉得我被雇用了AI，但我被迫从事基本的BI工作。感觉“不性别”并与我获得深厚AI体验的长期目标脱节，尤其是当我积极试图提高自己在这个领域的熟练程度时。这引起了重大的个人幻灭和认知过载。 我的问题： ••专注于一个“ nosexy”。 BI报告确实是这里最好的战略举动，即使我的角色是“ AI专家”我正在学习这项工作吗？ •鉴于高压和“没有结果”。历史，我的本能是在多个方面展示活动的本能（即使有较小的项目）只是持续失败的秘诀吗？ •当管理层不了解技术障碍但需要立即结果时，对向上进行管理的任何建议？       &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/International_pace66     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1luv5of/sole_ai_specialist_learning_on_the_job_3_months/</guid>
      <pubDate>Tue, 08 Jul 2025 17:45:41 GMT</pubDate>
    </item>
    <item>
      <title>雷·库兹韦尔（Ray Kurzweil）有没有人读过《奇点即将来临》？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lut9bq/has_anyone_read_the_singularity_is_near_by_ray/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  刚刚完成了第一章，在其中作者基本上列出了AI的未来，我必须承认我完全感到震惊。  我认为其中许多想法主要是科幻。我没有意识到我们在技术上走了多远。  我都着迷，但也很害怕，因为似乎我们确实正在走向一个增强人类，半机械人，ASI和最终奇异性的世界。我认为我们的人类在精神上进化不足以了解所有这一切的后果。  库兹韦尔的许多预测已经发生。他的准确率约为85％。  看来，许多其他人也会比他预测的要晚10-15年。  您想什么？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/cagninosis-possysosis     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lut9bq/has_anyone_read_the_singularity_is_near_by_ray/</guid>
      <pubDate>Tue, 08 Jul 2025 16:33:41 GMT</pubDate>
    </item>
    <item>
      <title>华盛顿邮报：AI即将获得入门级工作。每个人都需要做好准备</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lupud6/washington_post_ai_is_coming_for_entrylevel_jobs/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    AI即将用于入门级作业。每个人都需要做好准备。   “当然，首席执行官说，AI即将获得很多工作，而且很快 - 也许是所有白领工人中的一半。这很可能首先出现在入门级工作中，其中所需的基本技能是最容易复制的，而在技术中，快速适应最新软件工具的能力本身就是入门级工作要求。果然，近年来，在新的大学毕业生中失业率上升最快，这刺激了LinkedIn高管Aneesh Raman写道，白领职业阶梯的最低点是“破坏”。提交由＆＃32; /u/u/u/no-author-2358     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lupud6/washington_post_ai_is_coming_for_entrylevel_jobs/</guid>
      <pubDate>Tue, 08 Jul 2025 14:21:38 GMT</pubDate>
    </item>
    <item>
      <title>在2020年之前从事该领域的人：您如何跟上ML/AI中不断变化和不断变化的技术？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lukgrn/people_who_have_been_in_the_field_before_2020_how/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  作为一个真正喜欢学习新技术的学生，我有时会发现要跟上快速变化的速度。感觉就像昨天我已经熟悉了抹布，然后是代理商，现在MCP服务器是下一个大事。 在技术和学者之外的生活变得越来越困难，我开始感到沮丧，而我开始尝试保持所有事情的佼佼者。这不仅是AI的核心进步 - 在MLFlow，Kubernetes和其他我认为I 应该学习的基础架构工具等相关领域也发生了很多事情。   我询问2020年前的时间是因为从我的角度来看，AI似乎并没有快速移动。确实感觉就像在Chatgpt发行后加速了一切一样，AI Engineering现在感觉与我曾经做过的更传统的机器学习工作截然不同。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artco.  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lukgrn/people_have_have_have_have_have_in_in_the_field_field_before_2020_how/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lukgrn/people_who_have_been_in_the_field_before_2020_how/</guid>
      <pubDate>Tue, 08 Jul 2025 09:49:21 GMT</pubDate>
    </item>
    <item>
      <title>如果AI会取代工作，而不是，那么所谓的公司“胡说八道的工作”应该先消失吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1luk6by/if_ai_will_replace_jobs_arent_the_so_called/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果像项目经理或咨询公司这样的工作是“胡说八道”，因为它们围绕制作PowerPoint，回答电子邮件和参加无用的会议，难道不是这些类型的公司（或行政）工作应该先消失，而不是在管家或工厂工作者或工厂工人之前消失？  为什么某些程度（例如人文，语言，设计，计算机科学）比经济学，金融或管理/笨蛋更具风险？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/shift Interesting3346     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1luk6by/if_ai_will_replace_jobs_arent_the_so_called/</guid>
      <pubDate>Tue, 08 Jul 2025 09:30:00 GMT</pubDate>
    </item>
    </channel>
</rss>