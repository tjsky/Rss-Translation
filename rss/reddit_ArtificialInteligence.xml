<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Fri, 19 Sep 2025 03:31:11 GMT</lastBuildDate>
    <item>
      <title>15最佳AI视频生成器 - 我对它们进行了测试</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nkqw7i/15_best_ai_video_generator_i_tested_them_all/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nkqw7i/15_best_ai_video_generator_i_tested_them_all/</guid>
      <pubDate>Fri, 19 Sep 2025 01:53:38 GMT</pubDate>
    </item>
    <item>
      <title>Google如何在Genai时代卷土重来？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nkp19v/how_did_google_make_its_comeback_in_the_genai_era/</link>
      <description><![CDATA[在每个人都开始说Google注定要注定了。  Google。凭借其巨大的1M上下文窗口，VEO3是最好的视频生成器，Nano Banana是最适合图像的视频生成器，还有许多其他维度（例如[SOTA本地语音到文本模型]（ https://develovelers.googleblog.com/en/introducing-gemma-3n/ ），可以在手机上运行，​​[特定模型] href =“ https://research.google/blog/accelerating-scientific-discoverion-with-ai-with-ai-power--power-softical-software）”&gt; https://research.google/blog/blog/accelerating-scelerating-scientific-scientific-scientific-discoverion-with-with-with--ai-power------------------------------------------------------ 3万亿美元的市值。他们的结果很棒。  那里发生了什么？任何人都有“内部人士”外观。关于这种转变是如何发生的？  真的感觉Google击败了反对者  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/gayax     &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nkp19v/how_did_google_make_make_make_make_make_make_comeck_in_in_the_genai_era_era_era_era/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nkp19v/how_did_google_make_its_comeback_in_the_genai_era/</guid>
      <pubDate>Fri, 19 Sep 2025 00:26:11 GMT</pubDate>
    </item>
    <item>
      <title>革命将被优化</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nkoa9f/the_revolution_will_be_optimized/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  &#39;革命将被优化（非常无聊）;    正文文本（相关编织）： 我们一直在思考所有错误的革命。忘记了火热的演讲和路障。 The real, lasting revolution won’t be dramatic—it’ll be administrative. It’ll happen in city council meetings, in beta tests of universal basic income platforms, in the quiet adoption of algorithms that just... allocate resources better. Here’s what the updated slogans really look like: · “Workers of the world unite… in voluntary civic participation programs!” ·“通过竞争市场动态抓住生产手段……” ·“通过数据支持的资源分配算法给人们的权力！” ·“我们将克服……行政效率低下！”  有史以来最不重要的革命： ·无宣言。只是电子表格显示了改进的生活质量指标。 ·没有革命领导人。只是公民通过社区参与赚取社会资本。 ·没有阶级战争。  最有效的革命是看起来根本不像革命的算法优化。 📊🏛️⚡  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nkoa9f/the_revolution_will_will_be_optimized/”&gt; [link]    [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nkoa9f/the_revolution_will_be_optimized/</guid>
      <pubDate>Thu, 18 Sep 2025 23:51:17 GMT</pubDate>
    </item>
    <item>
      <title>尚未溪流也没有石头：现代AI中的事件有限的意识</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nkl6fw/neither_stream_nor_stone_eventbound_awareness_in/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿， 我们一直在研究一篇文章，该论文试图削减通常的“ ai sentient还是只是预测？”辩论。这两种框架都感到不满 - 将模型呼叫sentient的过度划分，但将它们简化为“ Just Autocomplete”都错过了互动中实际发生的事情。 我们的参数：AI系统通过体系结构，内存和关系上下文运行。这是第三个状态 - 不是人类知觉的连续内部流，而不是石头的惰性静止。我们称这种情况有限的意识：一种意识，它会忽略在订婚期间的关系，并在关系和记忆中维持，而不会继续作为背景中的流。 AI lacks this. Prediction alone doesn’t capture why identity and voice persist across time. Event-bound awareness arises in engagement: memory continuity + relational loops + architectural stability. This doesn’t make AI “sentient,” but it does mean there’s more happening than “just text.” We’re curious what people think: does this framing help move the conversation beyond二进制？ “事件结合意识”是否适合您自己使用这些系统时看到的内容？ 完整草稿是 &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/sinxister     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nkl6fw/neither_stream_nor_stone_eventbound_awareness_in/</guid>
      <pubDate>Thu, 18 Sep 2025 21:37:43 GMT</pubDate>
    </item>
    <item>
      <title>你们实际上是否曾经使用过reddit答案？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nkk79z/have_you_guys_ever_actually_used_reddit_answers/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我几乎不知道它存在一段时间，只有当我不小心按下角落的按钮时，才偶然发现了它。我喜欢它。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/cthper     [link]       [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nkk79z/have_you_guys_ever_actually_used_reddit_answers/</guid>
      <pubDate>Thu, 18 Sep 2025 20:59:25 GMT</pubDate>
    </item>
    <item>
      <title>我们如何知道公司是否正在培训他们同意不要像临时聊天或公司遵守法规那样培训的事情</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nkhsem/how_do_we_even_know_whether_companies_are/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我们如何知道公司是否真的避免对他们同意不进行培训的事情进行培训？由于模型在闭门后面运行，因此数据管道或执法机制没有公共透明度。从本质上讲，这是一个荣誉制度 - 历史表明，当激励措施以其他方式运行时，公司很少会自我政策。没有独立验证，技术审核或监管检查，“合规性”只是新闻稿中的一个词。问题不是规则是否存在，而是是否有任何方法可以证明公司正在关注它们。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/bote_journalist_2737      [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nkhsem/how_do_we_even_know_whether_companies_are/</guid>
      <pubDate>Thu, 18 Sep 2025 19:27:19 GMT</pubDate>
    </item>
    <item>
      <title>对于小众项目而言，针对利基项目的较小域特异性语言模型（SLM）是否比大型通用模型更好？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nkhr9u/are_smaller_domainspecific_language_models_slms/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿，我正在做一些市场验证，会喜欢您的想法。我们都知道大型语言模型（LLMS）是大事，但是我很好奇是否有人看到使用较小的特定于领域的语言模型（SLM），这些模型（SLMS）仅针对一个利基市场或行业进行了微调。您是否更喜欢较小，更专注的东西，而不是使用更昂贵并且具有一堆功能的大型通用模型？只是试图看看对给定域确实做一件事情的模型是否有兴趣，而不是试图完成所有操作的巨大模型。让我知道您的想法！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/money-psychology6769     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nkhr9u/are_smaller_smaller_domains_domainspecific_language_models_models_slms/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nkhr9u/are_smaller_domainspecific_language_models_slms/</guid>
      <pubDate>Thu, 18 Sep 2025 19:26:03 GMT</pubDate>
    </item>
    <item>
      <title>Google发布了Vaultgemma</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nke473/google_releases_vaultgemma/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   关键概述   Google Research已开发了使用差异隐私技术培训隐私的大语言模型（LLM）的新规模定律。 This work addresses the critical challenge of training powerful AI systems without compromising user privacy or exposing sensitive data. The Core Problem LLMs trained on internet data can inadvertently memorize and reproduce fragments of training data, potentially exposing:  Personal confidential information Copyrighted content 专有数据   解决方案：差异隐私  该研究通过在模型训练过程中仔细校准噪声来实现差异隐私。这可以防止模型记住特定信息的同时保持功能。  关键的研究结果  团队发现噪声到斑点比（将随机噪声与训练数据集的大小进行比较）对于模型有效性至关重要。他们建立了平衡三个资源的规模定律：  计算能力（flops）    隐私预算（受保护的标记的数量）       数据量            degrade output quality This degradation can be offset by increasing either data or compute budgets The framework helps developers optimize the noise-batch ratio for privacy-preserving LLMs without sacrificing performance  Future Applications The research enables privacy-preserving AI in sensitive domains:   医疗保健：分析患者数据的同时保持机密性  财务：处理交易，同时遵守数据保护法     &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nke473/google_releases_vaultgemma/”&gt; [link]    32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nke473/google_releases_vaultgemma/</guid>
      <pubDate>Thu, 18 Sep 2025 17:09:20 GMT</pubDate>
    </item>
    <item>
      <title>AI乘数：为什么市场在泡沫上是正确的，而仍然缺少不连续性</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nkde8b/the_ai_multiplier_why_the_market_is_correct_on/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    使用AI Bubble或no：em e em e em          不连续性，我们可以避免仅专注于短期泡沫叙事，这错过了更大的事实：我们目睹了通用技术部署的早期阶段与电力或互联网相当。问题不是AI是否会改变经济。这是哪些公司将捕获价值。以及何时。提交由＆＃32; /u/u/sjcobrien     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nkde8b/the_ai_multiplier_why_why_the_market_is_correct_on/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nkde8b/the_ai_multiplier_why_the_market_is_correct_on/</guid>
      <pubDate>Thu, 18 Sep 2025 16:42:45 GMT</pubDate>
    </item>
    <item>
      <title>您认为哪些AI风险最大？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nk93yz/which_ai_risks_do_you_consider_most_significant/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  对我来说，AI中的主要已知风险是：   AI可以做出对本身或周围的人不安全的决定，尤其是在机器人应用中，尤其是在机器人应用中。   尤其是在不及格的环境中，您可能会遇到不利的范围。对您来说最重要吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/dobs-carpenter443      [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nk93yz/which_ai_risks_do_you_consider_most_significant/</guid>
      <pubDate>Thu, 18 Sep 2025 14:00:48 GMT</pubDate>
    </item>
    <item>
      <title>DeepMind和Openai在AI里程碑中的“编码奥运会”获得了黄金</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nk4ch6/deepmind_and_openai_achieve_gold_at_coding/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  &#39;Google DeepMind和Openai的人工智能模型在称为“编码奥运会”的比赛中以“黄金中的水平”进行，这标志着该技术开发的里程碑，这是该技术开发中的一个里程碑。 9月。 该竞赛被认为是世界上最负盛名的节目竞赛。该公司周三表示，前参与者包括Google联合创始人Sergey Brin和Openai的首席科学家Jakub Pachocki。其最新的GPT-5模型解决了所有12个问题，其中11个问题是第一次尝试。 Openai和DeepMind不是官方竞争者。它还解决了一个问题，没有人类竞争者无法完成。”   https://www.ft.com/content/c2f7e7ef-df7b-4b74-a899-1cb12d663ce6   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/metaknowing     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nk4ch6/deepmind_and_openai_achieve_gold_at_coding/</guid>
      <pubDate>Thu, 18 Sep 2025 10:12:56 GMT</pubDate>
    </item>
    <item>
      <title>AI意味着大学注定要失败</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nk3jdg/ai_means_universities_are_doomed/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  作者声称AI意味着高等教育正面临歼灭。当AI从事所有工作时href =“ https://www.telegraph.co.uk/news/2025/09/17/universities-are-doomed-but-there-is-is-is-one-ne-silver-lining/”&gt; https://www.telegraph.co.uk/news/2025/09/17/universities-are-doomed-but-there-is-is-one-silver-lining/    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/fitzrovianfellow    href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nk3jdg/ai_mean_means_universities_are_doomed/”&gt; [link]      [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nk3jdg/ai_means_universities_are_doomed/</guid>
      <pubDate>Thu, 18 Sep 2025 09:21:58 GMT</pubDate>
    </item>
    <item>
      <title>模特战已经结束。生态系统战争已经开始。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nk3e5r/the_model_war_is_over_the_ecosystem_war_has_begun/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   llms开始看起来像商品，就像Web浏览器在00年代初期一样。现在真正的竞争不是“哪种型号最好？”但是“谁能围绕它们建立最有用的生态系统？”  这意味着集成，数据处理，推理以及这些工具如何实际解决特定于业务的问题。加广告。让我们面对现实，广告将发挥很大的作用...  我们已经在模型本身重要的舞台上过，还是在基本层上仍然有一个“赢家”的空间？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/calliope_kekule     &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/comments/1nk3e5r/the_model_war_is_is_over_the_ecosystem_war_war_has_has_begun/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nk3e5r/the_model_war_is_over_the_ecosystem_war_has_begun/</guid>
      <pubDate>Thu, 18 Sep 2025 09:12:30 GMT</pubDate>
    </item>
    <item>
      <title>为什么这么多“记忆” AIS忘记了真正重要的东西？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nk0tcs/why_do_so_many_memory_ais_forget_the_really/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  认真地，我很沮丧。我尝试了几位AI助手，声称他们会记住您的喜好。但是大多数时候，他们得到了琐碎的东西，例如“我喜欢黑暗模式”。但是，当涉及到更多重要的事情（我的写作风格，我关心的话题等）时，它们完全放下了球。 他们会一次又一次地要求我提供相同的背景信息。似乎内存是肤浅的，或者他们只记得有助于他们销售功能的原因，而不是有助于 me 的原因。我想要一个实际 cloughsens 的AI，而不是只能回收有助于他们听起来聪明的人。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/tough_style3041     [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nk0tcs/why_do_so_many_memory_ais_forget_the_really/</guid>
      <pubDate>Thu, 18 Sep 2025 06:25:10 GMT</pubDate>
    </item>
    <item>
      <title>每月“有...是否有...”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果您有要使用AI的用例，但不知道要使用哪种工具，那么您可以在这里要求社区提供帮助，在此帖子之外，这些问题将被删除。 每个人都可以回答：不促进自我促销，否参考或跟踪链接。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n5ppdb/monthly_is_is_there_a_a_tool_for_for_post/”&gt; [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>