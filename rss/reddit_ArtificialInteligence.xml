<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Fri, 25 Jul 2025 09:20:16 GMT</lastBuildDate>
    <item>
      <title>盖蒂图像是否开始使用AI生成内容？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m8tcob/has_getty_images_begun_to_use_ai_to_generate/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  一些材料，例如几年的戛纳电影节图像和视频，似乎是生成的，而不是纪录片。你也想知道吗？如果是这样，您似乎喜欢AI使用的证据吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/fir_ad545     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m8tcob/has_getty_images_begun_to_use_ai_to_generate/</guid>
      <pubDate>Fri, 25 Jul 2025 08:01:57 GMT</pubDate>
    </item>
    <item>
      <title>太多的人试图使Jarvis不够试图制作wall-e</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m8sp74/too_many_people_trying_to_make_jarvis_not_enough/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   wall-e表示对周围世界的同理心，好奇心和真正的关心。尽管Jarvis作为一种工具令人印象深刻，但Wall-E体现了形成有意义的联系并在简单事物中看到美丽的AI。也许我们需要更多欣赏日落的AI。这不是很好的策划，但是您怎么看？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/ok_report_9574     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1m8sp74/too_many_people_people_trying_tro_trying_to_make_jarvis_jarvis_not_enot_enough/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m8sp74/too_many_people_trying_to_make_jarvis_not_enough/</guid>
      <pubDate>Fri, 25 Jul 2025 07:18:45 GMT</pubDate>
    </item>
    <item>
      <title>思想o控制人工智能</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m8rg1f/thoughts_o_way_to_control_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我知道人们正在为如何确保AI安全而苦苦挣扎。我的建议是围绕校长建立AI，即它仅在当前和过去起作用。构建它，因此它甚至无法构想未来。然后，它无法计划或有任何渴望为人类操纵人类，因为它的眼中没有未来。 它仍然可以帮助您代码制作图片，因为它可以访问所有过去的信息。它只是无法计划的，因为它无法期待。  无论如何，我对如何或是否可能有0个想法。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/mxjamesc     [link]      [commist]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m8rg1f/thoughts_o_way_to_control_ai/</guid>
      <pubDate>Fri, 25 Jul 2025 06:00:48 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻7/25/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m8r12r/oneminute_daily_ai_news_7252025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   在AI的帮助下，他计划在曼哈顿进行爆炸的炸弹。[1]  特朗普的新AI政策中有什么事，以及为什么重要。 机器人，知道自己：基于新的视觉的系统教机器理解其身体。[4]   包括： https://bushaicave.com/2025/07/07/25/2025/2025/2025/one-news-daily-news-news-news-news-7-25-25-25/--  [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m8r12r/oneminute_daily_ai_news_7252025/</guid>
      <pubDate>Fri, 25 Jul 2025 05:36:08 GMT</pubDate>
    </item>
    <item>
      <title>我有一个想法：如果我们可以使用众包，自愿数据构建更好的AI模型怎么办？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m8qdxe/i_have_an_idea_what_if_we_could_build_a_better_ai/</link>
      <description><![CDATA[I&#39;ve been using tools like ChatGPT and other AI systems, and sometimes I wish they could learn more from how I use them—not just to improve my experience, but to help make the model better for everyone. Instead of relying only on private or hidden datasets, what if users could voluntarily contribute their data—fully opt-in,我知道这些工具已经在后台有所改善，但我很想看到一个人可以看到          我很想塑造他们的影响，并有助于塑造更聪明，更具包容性的AI。 。好奇别人的想法。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/plem-class-7070     [link]      &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1m8qdxe/i_have_an_idea_if_what_what_we_what_we_wwe_could_could_build_a_better_a_better_ai/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m8qdxe/i_have_an_idea_what_if_we_could_build_a_better_ai/</guid>
      <pubDate>Fri, 25 Jul 2025 04:59:20 GMT</pubDate>
    </item>
    <item>
      <title>所有希望削减成本的大公司的问题。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m8pqfd/a_question_to_all_the_big_firms_looking_to_cut/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我对这些大型技术和其他行业公司有一个疑问，希望通过减少的头部降低成本 - 如果全世界的人们失去了AI和自动化的工作，那么他们就不会有太多花费在您创建的产品上。  财务 - 如果我没有稳定的月收入，我买不起那些饮料。 银行 - 同样的逻辑 - 如果我不知道我的下一个EMI在哪里 实际上是从 真正支付的，显然是不可能负担得起的prog&gt; prog&gt;      a fancy education if there’s no hope for a decent placement  …the list of falling dominoes goes on. So while these companies have worked out some real shiny profit margin numbers in their spreadsheets and power points and growth models, haven’t you just collectively eliminated your majority customer base? I’m not a fancy finance guy with a shiny Harvard degree - so I’m not sure if I have overlooked something that these公司正在看到还是我过分简化了整个事情。  思想？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/cyphrsk   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1m8pqfd/a_question_to_to_all_the_big_firms_firms_looking_to_cut/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1m8pqfd/a_question_to_to_all_the_big_firms_looking_looking_to_cut_to_cut/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m8pqfd/a_question_to_all_the_big_firms_looking_to_cut/</guid>
      <pubDate>Fri, 25 Jul 2025 04:23:21 GMT</pubDate>
    </item>
    <item>
      <title>Openai准备在8月推出GPT-5</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m8p0v2/openai_prepares_to_launch_gpt5_in_august/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    &#39;虽然GPT-5看起来很可能在8月初首次亮相，但OpenAI计划的发布日期经常转移以应对开发挑战，服务器容量问题，甚至竞争对手AI模型公告和泄漏。本月早些时候，我警告说，可能会延迟到 Altman确认了我的报告就在我的 notepad 之后的几天之后试图在7月底之前将其运送到GPT-5发行之前。资料来源将模型描述为“类似于O3 Mini”，并具有推理能力。自2019年发行GPT-2以来，该新模型将是Openai首次发布开放重量模型，它将在Azure，Hugging Face和其他大型云提供商上使用。＆quort＆quort&#39; 阅读整个文章href =“ https://www.theverge.com/notepad-microsoft-newsletter/712950/openai-gpt-5-model-rease-date-date-notepad”&gt; there。提交由＆＃32; /u/u/u/no-author-2358     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m8p0v2/openai_prepares_to_launch_gpt5_in_august/</guid>
      <pubDate>Fri, 25 Jul 2025 03:45:49 GMT</pubDate>
    </item>
    <item>
      <title>目前的AI是多么独立，未来几年有望进一步代理？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m8n2o7/how_independent_are_current_ai_and_is_it_on_track/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  一两个星期前，我读了“ AGI 2027”。文章（我敢肯定你们中的大多数人都熟悉），从那以后，这使我陷入了沮丧的恐慌。我很难为此而睡觉，进餐和做任何事情，因为我被一种难以理解的机器神所困扰，上帝燃烧了整个生物圈，因此它可以将整个星球变成一个巨大的数据中心。   有几个人向我保证，目前的AI基本上只是不太了解他们在说什么。但是，如果是这种情况，那么为什么我要阅读有关AI试图逃脱到另一台服务器的文章（ https://connect.ala.org/acrl/discussion/chatgpt-o1-tried-to-to-to-escape-scape-and-save-save-save-un-fear-t-------------或重写自己的代码以防止关闭的AI（ https://medium.com/@techempire/an-ai-managed-to-wrecreite-isth-code-code-code-to-prevent-humans-humans-from-shutting-it-down-65A12223267BF ），），还是反复介绍其运营商并删除其自身意志数据库的AI？ （ https://www.moneycontrol.com/technology/i-panicked-instead-of-thinking-thinking-thinking-ai-platform-deletes-enter-company-company-database-database-and-lies-lies-lies-iit-it-ict-ict-13307676.html ）） 更重要的是，为什么会有这么多专家进行面试，他们声明Agi/ASI有很大的机会在不久的将来杀死我们所有人？ 即使当前的AI模型根本没有真正的代理或理解，即使这么多实验室在不实现AGI的情况下，我们实际上是在实现人类的互助，直到有一定的时间，直到有一定的时间，就可以实现ATA的实现，以至于一定要努力，直到有一定的时间，直到有一定的时间）竞赛？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/slow-recipe7005     [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m8n2o7/how_independent_are_current_ai_and_is_it_on_track/</guid>
      <pubDate>Fri, 25 Jul 2025 02:07:21 GMT</pubDate>
    </item>
    <item>
      <title>AI仍然误会的“客观”问题</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m8mjy7/objective_questions_that_ai_still_get_wrong/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我最近对Grok，chatgpt和Claude进行了一些有趣科学需要一些利基的理解或开箱即用的思考。出乎意料的是，在给他们答案（或至少要查找的特定关键字）之前，提出他们无法回答的问题非常容易。例如：   https://grok.com/share/c2HHCMQTMG%3D%3D_7DF7A294-F6B5-42AA-42AA-AC52-EC9343B6F222D22D   “如果您在舌头上放一些甜味，它的味道非常非常甜。舌头的一面，更少。但是，如果您在整个长度上划着拭子从舌头到舌头的侧面，那么它的味道同样甜美，＆quot＆quord＆quot”  &#39; 所有三个都以这种信心做出回应，直到您问他们是否能成为一个真正的味觉幻想（quastoration Illusion; quot quastory; quot quote; quot quot; quote; quote; quote; quote; quot; quot》;在一个实例中，chatgpt响应了“真实”，但它对答案的推理/描述是完全错误的，直到我专门向Google介绍了“本地化味觉幻觉。”  我真的不知道这种事情有多有意义，但是我确实发现它有验证。其他人有示例？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/rigbughorn     [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m8mjy7/objective_questions_that_ai_still_get_wrong/</guid>
      <pubDate>Fri, 25 Jul 2025 01:42:17 GMT</pubDate>
    </item>
    <item>
      <title>AI正在接管，因为我们也问了</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m8lfr8/ai_is_taking_over_because_we_asked_it_too/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   AI的扩展是我们日益依赖其效率和便利性的直接结果。我们将责任委托给AI系统，无论是医疗保健，金融还是创造性领域，都将其信任以超越人类的能力。随着时间的流逝，这种依赖性将加深并不是由于AI的任何恶意意图，而是因为我们优先考虑速度，准确性和可扩展性，而不是传统方法。我们整合AI的越多，就越不可或缺，创造了一个人类监督会通过选择减少的循环。最终“接管”不是AI叛乱，而是我们自己愿意交出re绳的结果 让我知道您的想法。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/mrdoggyasspoop     [link]     [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m8lfr8/ai_is_taking_over_because_we_asked_it_too/</guid>
      <pubDate>Fri, 25 Jul 2025 00:48:44 GMT</pubDate>
    </item>
    <item>
      <title>当创新超越监督时会发生什么</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m8gk1q/what_happens_when_innovation_outpaces_oversight/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  当创新超过监督 该动作计划在纸上听起来不错，但是有什么缺点？美国的AI行动计划代表了从安全优先到竞争优先的AI政策的巨大转变，将快速发展和全球优势优先于谨慎的监管。尽管这种方法可以加速创新，创造就业机会，促进经济增长并维持美国对竞争对手等美国技术领导力，但它还带来了重大风险，包括不足的安全测试，不足的安全性，大规模能源需求，工人流离失所以及民主对集中的AI AI权力的关注。诸如致命AI医疗误诊和自动驾驶汽车之类的灾难性故障遭到撞车，随后发生了系统性的风险，包括AI驱动的监视，具有威权主义，深层驱动驱动的选举操纵和经济崩溃以及大规模失业的经济崩溃，最终导致了无效的AI I IRRER IRRER IRRER IRRER IRRERER IRRERIS IRRERICE IRRE IRRE IRRE ERRE造成的，以至于无法实现IRRER IRRER IRRERICE，以使IRRERICE IRRE IRRE IRRE造成，使其陷入困境触发级联的全球失败，破坏了文明本身。 -   https：//www.ycoproductions.com/p/what https：/https-popodation.com/p/what https：/happens-what happens-whappens-happens-whappens-whapnen-whenen-innovation-utpaces  提交由＆＃32; /u/yavero     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m8gk1q/what_happens_when_innovation_outpaces_oversight/</guid>
      <pubDate>Thu, 24 Jul 2025 21:15:28 GMT</pubDate>
    </item>
    <item>
      <title>Google宣布正在启动一项新的AI功能，该功能使用户几乎可以尝试衣服</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m8eiu4/google_announced_that_its_launching_a_new_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   Google周四宣布，它将启动一项新的AI功能，该功能使用户几乎可以尝试衣服。 Virtual Try-On功能的正式发布是在Google开始测试它的两个月后。该功能可以通过允许用户上传自己的照片来实际上尝试穿一件衣服。  https://techcrunch.com/2025/07/24/googles-new-ai-feature-lets-you-virtually-try-on-clothes/  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/rkhunter_     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m8eiu4/google_announced_that_its_launching_a_new_ai/</guid>
      <pubDate>Thu, 24 Jul 2025 19:55:55 GMT</pubDate>
    </item>
    <item>
      <title>关于Openai关于AI经济影响的论点的良好分析</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m85mtp/good_analysis_on_openais_argument_about_economic/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  “提高的生产率不是不可避免的，甚至不是可能解决大规模失业，不平等现象恶化或其他经济陷阱的问题”    https://open.substack.com/pub/hardresetmedia/p/the-productivitivitive-myth-behind-the?r=63rvi＆amp;utm_medium = ios    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1m85mtp/good_analysis_on_openais_argument_about_economic/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m85mtp/good_analysis_on_openais_argument_about_economic/</guid>
      <pubDate>Thu, 24 Jul 2025 14:17:46 GMT</pubDate>
    </item>
    <item>
      <title>AI创新是否陷入了演示和流行语的循环中？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m82oz9/is_ai_innovation_stuck_in_a_loop_of_demos_and/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  最近感觉就像AI中的每个突破都只是最后一个版本的更加光彩，是为新闻稿或投资者呼叫而构建的。同时，诸如了解人类认知或建立可信赖的系统之类的真实问题得到了较少的关注。 我们看到成本上升，有限的访问权限和不断增长的公司控制。我们是在建立开放进度还是另一个围墙花园的未来？ 很想听听您的看法。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ofdingurous_cod_432      [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1m82oz9/is_ai_innovation_stuck_in_a_a_a_a_a_ loop_of_demos_and/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m82oz9/is_ai_innovation_stuck_in_a_loop_of_demos_and/</guid>
      <pubDate>Thu, 24 Jul 2025 12:11:09 GMT</pubDate>
    </item>
    <item>
      <title>这种AI炒作泡沫什么时候会像互联网一样破裂？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m7nob0/when_is_this_ai_hype_bubble_going_to_burst_like/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  不要试图过分愤世嫉俗，但我真的很想知道 - 当这种AI炒作会像dotcom boom一样放慢或流行吗？ 我一直在听到一些研究人员和技术评论员的声音，目前的AI开发朝着错误的方向发展。该领域没有开放的，以大学为主导的研究对社会的影响，而是被拥有几乎无限资源的大型科技公司劫持。这些公司正在扩大本质上只是荣耀的自动完整系统（是的，大型语言模型令人印象深刻，但其核心是统计模式预测指标）。 基础研究（尤其是在神经科学，认知和生物学等领域），也没有将其推向场外，因为它也没有扩展或演示。  同时，GPU价格飙升。普通消费者，小型研究实验室，甚至大学系都无法再参加AI研究。一切感觉都被锁在了付费墙后面 - 尖锐，模型，数据集。 对我来说，似乎至关重要的生物学和跨学科研究，实际上可以帮助我们理解智力是被忽视，资金不足或选择用于公司用途的。 其他任何人都在膨胀一个非常易碎的驱动器，而不是当前的exprife速度吗？我们是否像2000年代初在互联网上朝着另一个泡沫破裂的时刻？还是这是新的常规？ 很想听听您的想法。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/preams_place4977     [links]    32;   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m7nob0/when_is_this_ai_hype_bubble_going_to_burst_like/</guid>
      <pubDate>Wed, 23 Jul 2025 22:43:26 GMT</pubDate>
    </item>
    </channel>
</rss>