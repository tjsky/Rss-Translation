<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的方方面面提供一个门户，并促进有关我们所知的人工智能思想和概念的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、如何开发人工智能/机器学习项目、商业中的人工智能、人工智能如何影响我们的生活、未来可能的发展方向以及许多其他主题。欢迎。</description>
    <lastBuildDate>Sat, 18 Jan 2025 09:13:36 GMT</lastBuildDate>
    <item>
      <title>统计结果表明我们即将面临灭绝（源于人工智能？）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i43ru6/a_statistical_argument_that_were_about_to_face/</link>
      <description><![CDATA[抱歉，这篇帖子让人沮丧。我最近在《编程宇宙》一书中读到一位理论物理学家提出的一个论点。想象一下曾经有过或将要出现的每一个人类的诞生。你自己的诞生就是其中之一，是随机选择的。 假设历史上大约有 1000 亿人出生（不确定实际数字是多少，但这个数字已经足够了）。今天大约有 80 亿人活着。如果明天是我们灭绝前的最后一天，那么在人类历史上这个非常重要的时刻，也就是我们正在创造智慧的过程中，我们活着的几率大约是 8/100。 现在假设未来是光明的，人类注定要再繁荣一百万年，许多星球上的人口不断增长。假设在我们最终灭绝之前有 10 亿亿人出生。在这种情况下，我们在这个关键时刻活下来的机会微乎其微（8 / 1,000,000,000）。 如果人类注定繁荣，那么我们不太可能在此时此刻活在这里。我们不太可能处于历史的开端，也不太可能在恰当的时机活下来见证人类过去和未来最重要的时刻之一（如果你相信 AGI 正在路上）。 如果事情即将出错，那么我们此时此刻活在这里的事实似乎只是一个小巧合。 这个论点让我很不舒服。感觉不对劲，但我很难看出它有什么缺陷。你们怎么看？    提交人    /u/Helpful-Raisin-5782   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i43ru6/a_statistical_argument_that_were_about_to_face/</guid>
      <pubDate>Sat, 18 Jan 2025 09:13:14 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT 模型的糖尿病自我管理建议挑战和建议</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i43nl6/advice_for_diabetes_selfmanagement_by_chatgpt/</link>
      <description><![CDATA[标题：ChatGPT 模型对糖尿病自我管理的建议、挑战和建议 我每天都在寻找和总结有趣的 AI 研究论文，这样你就不必仔细阅读它们了。今天的论文题为“ChatGPT 模型对糖尿病自我管理的建议：挑战和建议”，作者是 Waqar Hussain 和 John Grundy。 本文评估了 ChatGPT 模型（版本 3.5 和 4）针对糖尿病相关查询提供的建议。它揭示了这些模型在提供准确和实用的糖尿病自我管理建议方面面临的重大挑战。该研究评估了这些模型的医学知识和个性化咨询能力，发现了准确性和偏见方面的差异，这些差异对有效的糖尿病管理构成了风险。 主要发现：  准确性和偏见问题：研究发现 ChatGPT 模型在准确性和根深蒂固的偏见方面存在显著差异，这凸显了它们在提供定制的糖尿病管理建议方面的局限性，除非它们受到高级提示的指导。 危险的建议风险：ChatGPT 通常在没有必要澄清的情况下提供建议，这可能导致潜在的危险建议，强调了在临床环境中需要人工监督。 建议的增强功能：为了应对已发现的挑战，作者建议实施一个常识性评估层以进行快速分析，并利用先进的检索增强生成 (RAG) 技术来整合特定于疾病的外部数据。这些增强功能旨在提高信息质量并降低错误信息风险。 持续的批评：对 ChatGPT 建议的批评源于其倾向于提供一般性建议、误解临床数据以及未能提供针对特定情况的响应，而这些响应在这些模型的当前迭代中保持了相关性。 人为监督：该研究强调了继续进行人为监督和改进 AI 模型的必要性，以有效满足医疗保健需求，特别是在糖尿病等慢性病管理方面。  您可以在此处查看完整的细分：这里 您可以在此处查看完整的原始研究论文：原始论文    提交人    /u/steves1189   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i43nl6/advice_for_diabetes_selfmanagement_by_chatgpt/</guid>
      <pubDate>Sat, 18 Jan 2025 09:04:15 GMT</pubDate>
    </item>
    <item>
      <title>有人知道 Chatous AI 聊天机器人发生了什么事吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i43nl3/does_anyone_know_what_happened_to_the_chatous_ai/</link>
      <description><![CDATA[我记得我使用过 Chatous AI 的聊天机器人，然后有一天，它突然关闭了。有人知道出了什么问题或者为什么会关闭吗？任何帮助都会有用.. 编辑 - 关闭而不是关闭。我的错。    提交人    /u/rutvik0911   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i43nl3/does_anyone_know_what_happened_to_the_chatous_ai/</guid>
      <pubDate>Sat, 18 Jan 2025 09:04:15 GMT</pubDate>
    </item>
    <item>
      <title>为什么 LLM 在代理系统中应该是可选的</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i43mgm/why_llms_should_be_optional_in_agent_systems/</link>
      <description><![CDATA[我们正在开发一个名为 Ceylon 的去中心化多代理框架。在这个框架中，我们决定将 LLM 与核心系统分离。我已经验证了我们的想法，如下所示。我希望听到您的意见，以便获得进一步发展的建议和想法。 最近几个月，我们观察到人工智能社区中出现了一种日益增长的趋势，即大型语言模型 (LLM) 越来越多地被视为代理系统的强制性组件。虽然 LLM 提供了强大的功能，但我们认为需要仔细检查这一假设。本文解释了我们将 LLM 支持与核心代理库分离的战略决策，以及为什么这种架构选择对基于代理的系统的未来很重要。 当前形势 在当今的人工智能领域，大型语言模型 (LLM) 已经变得如此占主导地位，以至于越来越多的人认为所有智能代理都必须由 LLM 驱动。虽然 LLM 是强大的工具，但盲目追随这一趋势违背了“简单胜于复杂”的基本原则。 历史视角 重要的是要记住，软件代理的概念早在 LLM 之前就存在了。虽然 LLM 驱动的代理在多代理系统中肯定有一席之地，但许多实际问题可以使用既定方法更有效地解决，例如：  用于处理不确定性的模糊逻辑系统 用于顺序决策的强化学习 用于分类和回归任务的随机森林模型 用于明确定义问题的传统基于规则的代理  现实世界的例子 考虑这个实际场景：想象一个智能制造系统，其中有多个代理监视和控制生产的不同方面。一个代理负责机器的预测性维护。虽然 LLM 可以处理传感器数据和维护日志来预测故障，但结合基本的基于规则的逻辑的更简单的随机森林模型可能更高效、更可靠：  随机森林模型处理实时传感器数据（温度、振动、功耗）来预测潜在故障 基于规则的逻辑处理维护任务的调度和优先级 简单的消息传递协议可实现维护和生产调度代理之间的通信  该解决方案将是：- 执行速度更快（LLM 推理以毫秒为单位，而不是以秒为单位）- 更可靠（不易出现幻觉或上下文混淆）- 更易于调试和维护- 更具成本效益（无需 API 调用或大型模型托管） 我们的架构决策 考虑到这些因素，我们采用模块化方法，将 LLM 功能实现为单独的可选库，而不是核心依赖项。这种架构决策具有以下几个优点：  当更简单的解决方案就足够时，复杂性会降低 降低计算开销和运营成本 在为特定问题选择合适工具时具有更大的灵活性 提高了核心代理框架的可维护性  这种方法确保开发人员可以构建高效的多代理系统，同时保留在 LLM 功能真正增加价值时集成它们的选项。例如，可以在以后将 LLM 功能添加到维护系统中，以处理非结构化维护说明或生成详细报告，同时保持核心预测功能的精简和高效。 展望未来 我们相信这种模块化方法代表了基于代理的系统更可持续、更实用的前进道路。它既承认 LLM 的强大功能，也承认传统方法的持续价值，使开发人员能够根据自己的特定需求做出明智的选择，而不是遵循一刀切的方法。    提交人    /u/dewmal   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i43mgm/why_llms_should_be_optional_in_agent_systems/</guid>
      <pubDate>Sat, 18 Jan 2025 09:01:54 GMT</pubDate>
    </item>
    <item>
      <title>人工智能的新名称。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i43dp2/new_name_for_artificial_intelligence/</link>
      <description><![CDATA[我认为人工智能及其衍生词（如通用人工智能或超级人工智能）太过拗口，并没有真正反映出这些现代神经网络的真正含义。 我建议用 仿生思维 代替人工智能，然后我们可以从中增加类别：I、II、III 等等。我们现在拥有的最佳人工智能将是 仿生思维 I。随后我们​​可以添加下一个罗马数字。您觉得呢？有什么不同的想法吗？    提交人    /u/JohnTo7   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i43dp2/new_name_for_artificial_intelligence/</guid>
      <pubDate>Sat, 18 Jan 2025 08:43:48 GMT</pubDate>
    </item>
    <item>
      <title>如何在 PyTorch 中制作音频模式应用模型？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i439gu/how_to_make_an_audio_pattern_applier_model_in/</link>
      <description><![CDATA[大家好！例如，我想执行以下操作：  男性 -&gt; 女性转换或反之亦然 RVC -&gt; RAW 人声 背景噪音添加器/消除器 以及任何其他修改  是否有或如何在 PyTorch 中编写单个 NN，您只需放置源和目标音频，它就会提取模式，然后您就可以应用添加或删除它！？  注意：必须处理 10-30 分钟这样的小数据！     提交人    /u/yukiarimo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i439gu/how_to_make_an_audio_pattern_applier_model_in/</guid>
      <pubDate>Sat, 18 Jan 2025 08:34:55 GMT</pubDate>
    </item>
    <item>
      <title>Google 的 UX 设计 AI 超级有用！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i411fa/googles_ai_for_ux_design_are_super_useful/</link>
      <description><![CDATA[Google 为设计师推出了一些出色的工具 - 可帮助您记录、研究甚至创作 - https://youtu.be/acWlbZmkwV0    提交人    /u/Punitweb   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i411fa/googles_ai_for_ux_design_are_super_useful/</guid>
      <pubDate>Sat, 18 Jan 2025 05:56:09 GMT</pubDate>
    </item>
    <item>
      <title>人工智能是“大过滤器”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i3zi8d/the_idea_that_artificial_intelligence_is_the/</link>
      <description><![CDATA[我知道这个问题之前已经讨论过了，但我对你的想法很好奇。 如果人工智能是我们从未遇到过先进文明的原因呢？ 无论任何物种的大脑容量如何，它很可能都需要创造人工智能来实现星际太空旅行等壮举。 我承认我们仍然不确定人工智能的发展将如何进行，但似乎如果它是一个不断改进的自我学习系统，它最终会超越它的创造者。 这并不一定意味着人工智能会变得有自我意识并摧毁它的创造者，但持续的进步可能会导致社会以其他方式崩溃。例如，过度依赖。在几代人使用人工智能之后，文明可能会达到“退化”的临界点，开始倒退。随着人工智能变得越来越强大和改变生活，它也可能导致战争和内乱。  这一切显然都依赖于大量的猜测。我绝不是人工智能的仇恨者。我只是认为这是一个有趣的想法。谢谢阅读！    提交人    /u/SeniorTechnician8222   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i3zi8d/the_idea_that_artificial_intelligence_is_the/</guid>
      <pubDate>Sat, 18 Jan 2025 04:20:32 GMT</pubDate>
    </item>
    <item>
      <title>Huggingface smolagents：以代码为中心的代理框架。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i3z9ni/huggingface_smolagents_code_centric_agent/</link>
      <description><![CDATA[Huggingface 最近发布了 smolagents，这是一个简单的 AI 代理框架，可以编写 Python 代码并执行分配的任何任务。它简单易用，适合构建 POC。它是最好的吗？我不这么认为。在此处查看更多详细信息和演示：https://youtu.be/_vNGG5BY9bA?si=NXLbkcu3vBVOn9vl    提交人    /u/mehul_gupta1997   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i3z9ni/huggingface_smolagents_code_centric_agent/</guid>
      <pubDate>Sat, 18 Jan 2025 04:06:36 GMT</pubDate>
    </item>
    <item>
      <title>优质免费 AI 治疗机器人</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i3rec7/good_free_ai_therapy_bots/</link>
      <description><![CDATA[有没有好的免费 AI 治疗机器人。我尝试过很多你可以在网上找到的机器人，但它们都不太管用，你最终不得不在谈话中途付费。任何我可以谈论分手的东西。 编辑：我很感谢大家的回复，我今晚会仔细查看它们，看看哪个 AI 最适合我。    提交人    /u/Wetmattress_125   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i3rec7/good_free_ai_therapy_bots/</guid>
      <pubDate>Fri, 17 Jan 2025 21:35:17 GMT</pubDate>
    </item>
    <item>
      <title>是否有人厌倦了与聊天机器人而不是真人交谈？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i3p79c/is_anyone_else_tired_of_talking_to_a_chatbot/</link>
      <description><![CDATA[在尝试处理某种支持或问题时，是否有其他人厌倦了与聊天机器人交谈或聆听聊天机器人而不是真人？ 它们并没有真正提供很多帮助，浪费了很多时间。 每当我遇到问题时，我通常都必须等待并采取某种解决方法才能联系到人来解决问题。    提交人    /u/SmartPercent177   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i3p79c/is_anyone_else_tired_of_talking_to_a_chatbot/</guid>
      <pubDate>Fri, 17 Jan 2025 19:58:09 GMT</pubDate>
    </item>
    <item>
      <title>Google Titans：具有更好长期记忆的新型 LLM 架构（更优质的视频）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i3p3fl/google_titans_new_llm_architecture_with_better/</link>
      <description><![CDATA[Google 最近发布了一篇介绍 Titans 的论文，他们试图在名为 Titans 的 LLM 新架构中模仿类似人类的记忆。在指标方面，该架构在论文中分享的许多基准测试中均优于 Transformers。在此处了解有关 Google Titans 的更多信息：https://www.youtube.com/watch?v=pU5Zmv4aq2U    提交人    /u/44th-Hokage   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i3p3fl/google_titans_new_llm_architecture_with_better/</guid>
      <pubDate>Fri, 17 Jan 2025 19:53:30 GMT</pubDate>
    </item>
    <item>
      <title>软件构建的未来</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i3k3zq/the_future_of_building_software/</link>
      <description><![CDATA[有点漫无目的。  对我来说，构建软件已经商品化，这一点非常清楚。我实际上在不到一天的时间内就推出了一个带有后端、身份验证、前端的全新应用程序，并进行了部署。  看看 OpenAI、Claude、Gemini 中的新功能，它们每天都在接管越来越多的用例。  我觉得公司将减少购买单个软件，并使用一些通用代理进行管理。在这种情况下，大型代理几乎将接管 90% 的工作流程。  新构建者将何去何从？您觉得呢？     提交人    /u/j_relentless   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i3k3zq/the_future_of_building_software/</guid>
      <pubDate>Fri, 17 Jan 2025 16:22:47 GMT</pubDate>
    </item>
    <item>
      <title>每月“是否有一个工具可以……”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用 AI 的用例，但不知道使用哪种工具，您可以在这里请求社区提供帮助，在此帖子之外，这些问题将被删除。 对于每个回答的人：没有自我宣传，没有参考或跟踪链接。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:09:07 GMT</pubDate>
    </item>
    <item>
      <title>每月自我推销贴</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4l16/monthly_self_promotion_post/</link>
      <description><![CDATA[如果您有产品要推广，可以在这里进行推广，本帖之外的内容将被删除。  禁止引用链接或带有 utms 的链接，请遵守我们的推广规则。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4l16/monthly_self_promotion_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:03:08 GMT</pubDate>
    </item>
    </channel>
</rss>