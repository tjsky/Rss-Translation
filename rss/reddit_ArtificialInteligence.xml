<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Thu, 11 Sep 2025 21:12:53 GMT</lastBuildDate>
    <item>
      <title>您最近从AI模型中看到的最出乎意料的功能是什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nek4ku/whats_the_most_unexpected_capability_youve_seen/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   ai使我们感到惊讶的是新的能力和创意输出。最近，我一直在探索一些深入的资源，这些资源确实扩大了我对AI潜力的看法。现代AI的一项功能或行为是什么使您措手不及？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/cute_dog_8410     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nek4ku/whats_the_most_unexpected_capability_youve_seen/</guid>
      <pubDate>Thu, 11 Sep 2025 20:46:45 GMT</pubDate>
    </item>
    <item>
      <title>遇到了这个疯狂的推文，显然是Vals AI基准的人类标准模型</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1neibee/came_across_this_crazy_tweet_apparently_vals_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  研究人员你们对此有何看法？有人熟悉这个实验室吗？  https://x./x.com./spencermateega/status/1966618000062295896295896284 提交由＆＃32; /u/u/cstiker05     [link]     [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1neibee/came_across_this_crazy_tweet_apparently_vals_ai/</guid>
      <pubDate>Thu, 11 Sep 2025 19:36:30 GMT</pubDate>
    </item>
    <item>
      <title>不受欢迎的意见：LLM提示必须视为资产</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1negsnn/unpopular_opinion_llm_prompts_must_be_considered/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;     tl; dr; dr：当提示可能变得不可思议，结构化和独特性时，它们可以成为跨模型的收据，水印和可移植性的资产。   听我说，我会听到我。但是现代提示可以选择工具，建立规则，跟踪状态和协调步骤。这比休闲请求更接近小型操作系统。 如果某种某种的行为像这种“ OS层”。这解释了命令，执行策略和策划工作，当然，这东西不应该被视为资产吗？ 当然不是每个提示。我说的是：   不太明显。 嘿，做一些聪明的事情，不仅是同义词，字形和丁字鸟。  结构化。它们具有可识别的部分，例如歌曲中的经文/合唱。  唯一。 t 人们可以针对相同的目标，并且仍然产生一个独特的“方法”。  我认为，如果提示具有这三个素质，它不再是任意的说明。   好的，但是，这是什么样的？它有五个部分（有目的很无聊）：   标题。这件事的作用。  目标。 他的结果是用户关心的。  原则。 g  uardrails（安全限制，速度/准确性权衡等） - “为什么”“   操作。 应该采取什么措施 - “什么”“什么”&#39; 逐步逐步细节（动作，参数和预期结果） - “如何“   ”，但您实际上可以拥有食谱吗？ 律师喜欢说“依赖”，而他们并不是错误的。软件是确定性的。 LLM是概率。版权喜欢固定的表达，但提示通常是短暂的。法院本身并不能保护“操作方法”，提示可以看上去是程序性的。 ，但我们会做一些实用的事情：修复事情。请使用“提示”并锁定它。     密码收据。 p 作者身份和许可条款的屋顶。  不可变的存储。 C  OnTent-Hash身份（如果更改逗号，则更改哈希）。  无形的水印。 P 跨模型的Rovenance。  模型可移植性，因此您可以在不同的LLM上运行它而不会进行微调。  现在您拥有一个稳定的可调式伪像。也许该模型的输出有所不同，但是配方，如其结构，选择和理由，保持固定。这就是您可以指出的部分，并说：“我做了。”   这不仅仅是幻想格式化的兄弟？   no。想想音乐。和弦很常见； 安排是艺术。食谱，工具和任务很常见。这是的选择和协调，您构建目标，原理，操作和步骤的方式。  “为什么现在要打扰？ llms继续获得“智能”。并且可能已经提出了“专利”文物。也许他们还没有发明新的物理学，但是如果 elon 可以相信，那是几个月/几个月/一些提示/几个提示。已经在练习。 ，但是这个想法需要进一步的辩论和讨论。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/benjaminskyy     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1negsnn/1negsnn/unpopular_opinion_llm_prompts_musts_must_be_considered/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1negsnn/unpopular_opinion_llm_prompts_must_be_considered/</guid>
      <pubDate>Thu, 11 Sep 2025 18:37:54 GMT</pubDate>
    </item>
    <item>
      <title>您有2027 = BS吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1neg2o5/ai_2027_bs/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  不确定你们是否已经看到了丹尼尔·科科塔·贾洛（Daniel Kokotajlo）和他的团队的高度投机AI 2027预测。 如果没有，只需搜索AI 2027，只需单击第一个地址（出于某种原因，Reddit就不会让我的Paste link link link link link link link lol lol lol lol） tl; dr：  最终AI变得如此先进，以至于它要么消灭人类，要么我们和中国决定合作创建一个加强和平的人工智能。 的假设是，这两个国家都在进一步发展和进一步发展AI，这是最终导致您成功的事情，因为谁经历了AI 2027：   AI固有地决定如果人类不在附近，它对自己最好？  ai本身并不知道最好或不知道什么是最好的，毕竟我们一直在不断地提供反馈。      &lt;  &lt;  &lt;  &lt;  &lt; 基于p的反馈和p&gt;   出去没有意义。这将如何有助于改进和进一步发展？ 不仅可以防止AI实现其目标，而且AI 2027也假设AI具有由蓝色创建的秘密议程，就好像它可以区分好的，就像是什么是不好的，或者是从本身做出的决定，也可以从中取代其秘密的预定。我们，除非认为我们构成威胁，否则这是有意义的。提交由＆＃32; /u/u/u/elytrunks       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1neg2o5/ai_2027_bs/</guid>
      <pubDate>Thu, 11 Sep 2025 18:10:22 GMT</pubDate>
    </item>
    <item>
      <title>缩放你有</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nefa24/scaling_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  对于那些将AI自动化解决方案从单个部门缩放到整个企业的人来说，您没有看到的最大瓶颈是什么？是技术债务，缺乏明确的所有权还是其他东西？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/just_violinist_5458       [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nefa24/scaling_ai/</guid>
      <pubDate>Thu, 11 Sep 2025 17:40:22 GMT</pubDate>
    </item>
    <item>
      <title>AI编码代理是下一个没有代码吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nef6m8/are_ai_coding_agents_the_next_no_code/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   5年前没有代码爆炸。现在，像blink.new这样的ai-优先平台在这里描述您的应用程序，它可以构建前端，后端，db，auth，托管。 当我对其进行测试时，blink.new的错误比螺栓或可爱的错误。感觉就像没有代码，AI正在融合。 您认为拖放构建者能够幸存下班吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/Psychologationarea992     [link]     [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nef6m8/are_ai_coding_agents_the_next_no_code/</guid>
      <pubDate>Thu, 11 Sep 2025 17:36:41 GMT</pubDate>
    </item>
    <item>
      <title>简而</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nedx86/trumpgpt_in_a_nutshell_saying_correct_things/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    cf与gpt 5： https://imgur.com/a/a/a/a/a/43kfpit  gpt说的是“正确的”的话吗？它介绍了民主党人的一方和特朗普的一面，对吗？绝对没有提及独立报告。只有民主党人和特朗普。   - 首先是“有争议的”，然后在“民主党释放”上给出了尽可能多的空间。就像特朗普的否认一样。这两个观点都被赋予了很多字符。这听起来像是在文件的真实性上存在严重，平衡的争议，跨政党分裂，这是公然的错误   - 忽略了特朗普过去否认过去整个文件的存在。根据独立报告，爱泼斯坦档案中提到了特朗普。省略了文件的出处（WSJ报告，Epstein Estate提供）。完全省略了字母的内容。 阅读本文时，听起来“我们不知道，它是有争议的。现实是，当然，当然，这没有争议，而王牌只是否认一切，并称其为“民主骗局”。因为他个人被灌输了。 “它说的东西是正确的”。是一个低的，低杠。   https://chatgpt.com/share/share/68c2fcae/68c2fcae-2 ed8-800b-800b-800b-8db-8db7-67E7E7E7E7E7E7E7E7E7E9624  r/aicensorship     &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/xdumbpuppyplyunax     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nedx86/trumpgpt_in_a_nutshell_saying_correct_things/</guid>
      <pubDate>Thu, 11 Sep 2025 16:49:23 GMT</pubDate>
    </item>
    <item>
      <title>有人解决了WAN模型的扩展问题吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ne9sxn/has_anyone_solved_the_scaling_problem_with_wan/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   wan一直是生成头像，视频，配音等的首选。但这是一个极端的计算密集应用。我正在尝试使用WAN构建产品，但面临缩放问题，尤其是在托管O​​SS版本时。 有人面临类似的问题吗？您如何解决/减轻几个客户的缩放问题？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ne9sxn/has_anyone_solved_the_scaling_problem_with_wan/&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ne9sxn/has_anyone_solved_the_scaling_problem_with_wan/</guid>
      <pubDate>Thu, 11 Sep 2025 14:09:14 GMT</pubDate>
    </item>
    <item>
      <title>使用AI（主要是LLM）的限制因素</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ne8pfp/the_limiting_factor_in_using_ai_mostly_llms/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    您无法自动化自己无法发音的东西。         eart e e e e e  p&gt; p&gt; p&gt; p&gt;原理：  在知识工作中，瓶颈不是信息的外部可用性。这是处理能力的内部带宽，这取决于您的先天能力和思想的训练状态。  source      我认为这已经发生了。但是，我主要在最了解的领域中受益。 This aligns with the hypothesis that AI is killing junior position in software engineering while senior positions remain untouched. AI should be used as a乘数，不是代孕。因此，总的来说，我们从训练我们的思想而不是AI-Improvements中总共受益。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/fastsascha   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ne8pfp/the_limiting_factor_in_ion_ai_ai_ai_aim_ables_llms/”&gt; [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ne8pfp/the_limiting_factor_in_using_ai_mostly_llms/</guid>
      <pubDate>Thu, 11 Sep 2025 13:23:02 GMT</pubDate>
    </item>
    <item>
      <title>在LLM中击败Horace He（Ex-Openai CTO）中的非确定性</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ne4mvi/defeating_nondeterminism_in_llm_inference_by/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   可重复性是科学进步的基础。但是，很难从大语言模型中获得可复制的结果。   aint是事实。取自在llm推理中击败非固定主义 horace he（ex-openai cto）。当发生这种情况时，很小的数字差异可能会蔓延。   他们设法通过[阅读本文解决了它，因为我的释义将是废话]，这意味着答案在温度零，测试和调试中可重复，并且在整个运行中都可以进行比较。  尽管这确实意味着您放弃了一些速度和巧妙的调度，因此在繁忙的服务器上，延迟和吞吐量可能会更糟。 历史上，我们已经能够选择一个模型，例如以速度进行一些智能进行贸易。我想知道最终在确定性和概率之间是否会有一个切换来调整速度/准确性平衡？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/paddy-makk     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ne4mvi/defeating_nondeterminism_in_llm_inference_by/</guid>
      <pubDate>Thu, 11 Sep 2025 09:53:45 GMT</pubDate>
    </item>
    <item>
      <title>Big AI推动了“我们需要击败中国”的叙事，因为他们想要胖政府合同和零民主监督。这是一个古老的把戏。恐惧卖出。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ne4e1h/big_ai_pushes_the_we_need_to_beat_china_narrative/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在整个冷战期间，军事工业综合体花费了一笔命运，推动了虚假的叙述，即苏联军队比实际上更先进。 为什么？为了确保国会的钱一直在流动。 他们撒谎了……撒谎……并再次撒谎，以获得更大的国防合同。 现在，显然，          Big&gt; Big Tech竭尽全力地使他们能够为他们提供了什么才能使他们陷入困境的境地，他们希望他们能够为他们提供任何争议    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/katxwoods   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ne4e1h/big_ai_ai_pushes_the_we_we_we_need_to_to_to_to_beat_china_narrative/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ne4e1h/big_ai_pushes_the_we_we_need_te_to_to_to_to_to_to_beat_china_china_narrative/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ne4e1h/big_ai_pushes_the_we_need_to_beat_china_narrative/</guid>
      <pubDate>Thu, 11 Sep 2025 09:37:55 GMT</pubDate>
    </item>
    <item>
      <title>数据科学家的日记🥼</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ndzv9k/diary_of_a_data_scientist/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在pseduoanonymous的在线参与时，请记住，代理AI bot网络在大规模规模上运行猖ramp。该行业并没有真正具有复杂的保护来防止这种情况，因为可以对这些代理进行编程以模仿真实的用户行为。 IP地址和硬件地址可能会被欺骗以避免黑名单，而在夏天，不好的演员比蟑螂更难摆脱。 这甚至不是理论上的，该工具已经取得了进步，以至于愚蠢地容易设置这些自动化，以帮助您一点点的知识知识，您可以从字面上帮助您实施一个llm。由于Openai和其他提供商在训练模型中为我们造成了困难的局面，因此这种架构确实并不是那么复杂。  tl; dr-不要相信在深层划分和炎症时期受到了社交媒体很可能被操纵的情况时，在深层划分和炎症的情况下，人们不相信流行的，更新的Reddit/facebook/insta/x意见。我建议采用一个零信任模型的未来，未经验证的社交媒体意见，因为我真正相信这些社交媒体平台现在已经妥协了，攻击向量是...我们所有人。提交由＆＃32; /u/orygregs     [link]    32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ndzv9k/diary_of_a_data_scientist/</guid>
      <pubDate>Thu, 11 Sep 2025 04:47:14 GMT</pubDate>
    </item>
    <item>
      <title>我们几乎没有理解智力，不介意制作Agi</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ndmo8i/we_are_nowhere_near_understanding_intelligence/</link>
      <description><![CDATA[Hey folks, I&#39;m hoping that I&#39;ll find people who&#39;ve thought about this. Today, in 2025, the scientific community still has no understanding of how intelligence works. It&#39;s essentially still a mystery. And yet the AGI and ASI enthusiasts have the arrogance to suggest that we&#39;ll build ASI和Agi。 即使我们不操知道智能是如何工作的。 他们甚至听到他们在说什么？ 为什么人们不推迟谈论AGI或ASI的任何人并问一个简单的问题：                   ＆quot“您要建造一台机器来聪明。真的很快，告诉我智能是如何工作的？＆quort  已经制造了一些很棒的工具并将制造。但是我们不是在这里建立智能。 它是2025年皇帝的新衣服的版本。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/lazyoil8672     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ndmo8i/we_are_nowhere_near_understanding_intelligence/</guid>
      <pubDate>Wed, 10 Sep 2025 18:43:31 GMT</pubDate>
    </item>
    <item>
      <title>“我创建了自己的AI医疗团队。这改变了医生治疗癌症的方式。”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ndi9sr/i_created_my_own_ai_medical_team_it_changed_the/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    https://www.statnews.com/2025/2025/09/09/10/10/10/10/10/ai-cancer-cancer-custment-custom-deateat-custom-docompom--docons-procy/ i&gt;     医疗AI代理名为“ Haley”，是为使用OpenAI，Google，Anthropic和XAI的基础基础模型而创建的，但具有大量的医疗环境，可以将知识探索与精心准备的所有病史相结合。我为Haley提供了与所有医生在几周前见过的完全相同的数据。我完整的Mychart历史。我的实验室。成像结果。医生指出。 在几分钟之内，海莉标记了一种有关模式：轻度贫血，铁蛋白升高，免疫球蛋白低 - 免疫功能障碍和骨髓问题的迹象。海莉建议进行“无血清轻链”血液测试和骨髓活检。以前没有提出过这些。相同的数据，新见解。  然后我扩大了团队。我建立了一个AI特工的小组 - 肿瘤学家，胃肠病学家，血液学家，ER DOC等人都接受了训练，可以像他们的人类一样思考。我一次通过每个案例进行了相同的案例。我创建了一个合成代理人希波克拉底，担任董事会主席。他听了他们的所有人，并给了我一个合并的建议。 我创建了自己的虚拟多学科医疗团队。他们照亮了我的医生错过的道路。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ndi9sr/i_created_my_own_own_ime_ai_medical_medical_team_it_it_changed_the/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ndi9sr/i_created_my_my_ewn_ai_medical_medical_medical_team_it_it_it_changed_the/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ndi9sr/i_created_my_own_ai_medical_team_it_changed_the/</guid>
      <pubDate>Wed, 10 Sep 2025 16:02:38 GMT</pubDate>
    </item>
    <item>
      <title>每月“有...是否有...”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果您有要使用AI的用例，但不知道要使用哪种工具，那么您可以在这里要求社区提供帮助，在此帖子之外，这些问题将被删除。 每个人都可以回答：不促进自我促销，否参考或跟踪链接。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n5ppdb/monthly_is_is_there_a_a_tool_for_for_post/”&gt; [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>