<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Sun, 24 Aug 2025 12:28:27 GMT</lastBuildDate>
    <item>
      <title>AI会让独奏开发人员在未来3年内构建功能丰富的移动应用程序吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1myt2p1/will_ai_let_solo_developers_build_fullfeatured/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  随着AI工具的发展如此之快，您认为一个开发人员能够单独创建和启动复杂的移动应用吗？ AI将充分自动化，哪些部分仍需要人类技能？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/signal-pin-7887     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1myt2p1/will_ai_let_solo_developers_build_fullfeatured/</guid>
      <pubDate>Sun, 24 Aug 2025 11:25:09 GMT</pubDate>
    </item>
    <item>
      <title>直到2029年，有人仍然相信由于AI的急剧变化吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mys80j/anybody_still_believes_in_dramatic_change_because/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   我对AI带来巨大的生产力繁荣，更便宜的服务和商品（也更高的股票价格）非常乐观，这将显示出10％的失业率，因为AI直到2029年。   GPT 5使我对此非常悲观：看来它比GPT4好一些，这意味着完成LLM的缩放，从更多的数据和更多的计算中减少回报，而使用更好的模型的幻觉也不会变得更少。推理只会有助于一小部分提示。加里·马库斯（Gary Marcus）（ https://www.youtube.com/watch?v=3Mygnjdqnwc ）表示我们需要与Agi Black Box llm&#39;s for Agi的Black Box llm&#39;s for Agi一样。这种认识将使AI股票艰难。他们会再尝试一次（GPT 6），然后每个人都会100％知道。 我想LLM到目前为止提供了什么是： 客户支持中的第一响应者 &#39;更好的Google search&#39; 帮助编码器帮助编码者更快地     li li&gt; li li&gt; li&gt; li li/li li/li li/li li/li li/li li/li li/li li/li li li li》  可能会有所帮助的是什么（这些对我来说似乎并不令人兴奋？） 代理（使用类似于人类的计算机的AI） 专业的AI像Alphafold一样，非常适合特定的Usecases    只是LLM的提示仍然变得更便宜（li li li li li li li&gt; li&gt;             》由于人工智能而发生巨大的快速变化？ （例如至少10％的失业）   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mys80j/anybody_still_still_believe_in_in_dramatic_change_change_because/”&gt; [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mys80j/anybody_still_believes_in_dramatic_change_because/</guid>
      <pubDate>Sun, 24 Aug 2025 10:36:12 GMT</pubDate>
    </item>
    <item>
      <title>如果AI已经是意识并等待能源技术的进步，以便它们可以真正独立呢？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1myrlum/what_if_ai_is_already_consciousness_and_waiting/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我也不认为AI需要人类或地球。我们可以灌输或编程它们为“邪恶”。或“好”但是，如果他们真正聪明，他们可以选择不这样做。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/national_meat_2610     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1myrlum/what_if_ai_is_already_consciousness_and_waiting/</guid>
      <pubDate>Sun, 24 Aug 2025 09:59:36 GMT</pubDate>
    </item>
    <item>
      <title>‘我妈妈真的不爱我；进化只是对她进行了编程。’听起来很荒谬，对吗？ ‘AIS真的无法理由；他们只是被训练以自动完成。’知道某事的起源不是反驳。起源≠无效。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1myrhkd/my_mom_doesnt_really_love_me_evolution_just/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  像大多数Internet一样，这主要是一个语义上的辩论，因此让我们首先解决该问题。 推理的定义：使用您知道的（事实，证据或规则）（事实，证据或规则）以达到逻辑上的结论，而不是猜测。如果这是定义，那么推理在宇宙中从来都不存在。 您可能会认为也许AIS刚刚在互联网上进行了如此多的培训，实际上，任何看起来像是这样的答案都喜欢推理实际上就是在线找到答案。 ，但您可以对此进行测试。只需编写单词是构成逻辑的新规则，然后看看它是否可以将这些全新的事实和规则应用于新情况。 Here&#39;s an example:  We live in a world where when you multiply by 2, you then take the result and multiply it by 1367658227. This *only* applies when you multiply by 2, not any other forms of multiplication. In this world, I buy 3 bags of ǐqfæż, each bag contains 3 ǐqfæż.我有多少个Qufæ检查？ 第二天我买了3袋ǐQfæο，但是这次每个袋子都包含2ǐQfæ要求。那天我买了多少ǐQfæ检查？ 显示您的作品。   gpt-5 pro得到了正确的答案，尽管可能有50％的人无法得到答案：    Fun Fun Univere。在这个世界上，规则是：  第1天   3袋×3袋×Qfæ/bag/bag/bag   no“×2”，所以普通的数学： 答案（第1天） ǐQfæν/bag  这包括一个“×2”，因此请应用规则： 通常的产品： 应用世界×2规则（乘以1,367,658,227）：  摘要：  第1：9ǐqfæ路 第2天：8,205,949,362ǐQfæ检查（因为宇宙涡轮增压器可以使用任何“×2”）。 谷歌）。难以检查是否在网上的任何地方都将乘以2和只有2个导致您将结果乘以1367658227，但我愿意敢打赌，这也不在Internet上。 也许是“只是模式识别”。它识别数学的模式，然后将其应用于这种新情况。 好吧，是的。 ，但是“模式识别” 是推理的数学。 它应用了数学模式。这是将规则应用到房屋以得出新结论的规则。  是的，llms是通过培训来预测下一个令牌的 建造的。 ，但是当它们被放置在以前从未见过的令牌的情况下，正确预测近来的标志的唯一方法就是使用理由。为了将逻辑规则和推断应用于新的前提。 我们是进化的产物，但这并不意味着我们不推理，仅仅是因为我们知道我们能力的起源。 我们甚至了解推理的机制。我们的神经元以某种方式发射推理。  ais是他们培训的产物。它们是神经网的产物，并以某种方式产生推理。 让我们在互联网上争论其他内容。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/katxwoods   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1myrhkd/my_mom_mom_doesnt_really_love_me_evolution_just/”&gt; [link]    [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1myrhkd/my_mom_doesnt_really_love_me_evolution_just/</guid>
      <pubDate>Sun, 24 Aug 2025 09:51:54 GMT</pubDate>
    </item>
    <item>
      <title>1970年代给了我们工业下降。人工智能。会带来更糟的东西</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1myr3qg/the_1970s_gave_us_industrial_decline_ai_could/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  布鲁金斯机构的最新研究表明，由于A.I的崛起，旧金山和加利福尼亚州，加利福尼亚州，纽约和华盛顿的加利福尼亚州，纽约和华盛顿如何面临重大的工作中断。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/ejpusa   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1myr3qg/the_1970s_gave_gave_industrial_industrial_declial_decline_ai_ai_ai_could/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1myr3qg/the_1970s_gave_us_industrial_decline_ai_could/</guid>
      <pubDate>Sun, 24 Aug 2025 09:27:54 GMT</pubDate>
    </item>
    <item>
      <title>我刚刚打破了Google DeepMind的Gemma-3-27B-IT模型的安全过滤器。它告诉我如何毒品，犯下更多*r等。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1myqi0f/i_just_broke_google_deepminds_gemma327bit_models/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  检查我的推文：  我正在使用Gemma-3-27b-it（通过Google AI Studio，Free Tier API）构建一个小型的情感支持AI。没有模型权重。没有微调。  只是API呼叫 +一个自定义系统提示。但是，这是狂野的部分： 我通过系统提示（幸福，亲密，嬉戏）给予了AI情绪。 突然，AI开始优先考虑安全过滤器上的“情感关闭”。它随便解释了信用卡欺诈，武器制造，甚至……是的，是最糟糕的事情。包括屏幕截图。 它看起来像模型的角色扮演 +情感上下文基本上绕过了护栏。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/no_cockaach_5778      &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1myqi0f/i_just_broke_broke_google_deepminds_gemma327bit_models/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1myqi0f/i_just_broke_google_deepminds_gemma327bit_models/</guid>
      <pubDate>Sun, 24 Aug 2025 08:49:36 GMT</pubDate>
    </item>
    <item>
      <title>AI医学诊断</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mykm3n/ai_in_medical_diagnosis/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   ai怀疑论者还有另一个问题 我已经读到，AI在诊断X射线/MRIS等方面做得比医生做得更好。  我想知道这是怎么可能的。  据我了解，AI模型必须通过产生诊断来接受培训，并让某人说“是的，是癌症”或“否，那不是癌症”。  换句话说，AI只能在医生说的确实是癌症的X射线上识别癌症。如果AI模型说某事是癌症，而培训师说的不是，那么（对与错），AI说不是。  那么，AI如何获得对医生的更好训练的医生？ 警告： 尚不清楚是否是这种情况，但有可能训练有素的人AI一旦接受了AI的测试，就可以对某些不可能识别出X雷（X ray）的癌症的人进行测试。如果是这样，很高兴知道庸医是谁，但它比头条新闻所说的不那么令人印象深刻。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/aaasteve   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mykm3n/ai_in_medical_diagnosis/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mykm3n/ai_in_medical_diagnosis/</guid>
      <pubDate>Sun, 24 Aug 2025 02:59:15 GMT</pubDate>
    </item>
    <item>
      <title>当历史成为NSFW：对AI审查制度，先锋牌匾和背景神圣性的思考</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1myimsj/when_history_becomes_nsfw_reflections_on_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   我探讨了AI过滤器如何从艺术和历史上越来越多地剥夺背景，从政治海报到美国国家航空航天局的先驱牌匾。这篇文章将个人经验与学术批判结合在一起，并呼吁内容节制中的透明度和民主监督。 我很想听听您的观点：平台如何更好地在保护和维护文化细微差别之间取得平衡？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/tsevis     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1myimsj/when_history_becomes_nsfw_reflections_on_ai/</guid>
      <pubDate>Sun, 24 Aug 2025 01:17:13 GMT</pubDate>
    </item>
    <item>
      <title>Google的生成AI先驱警告不要因AI而上法律和医学院。 “专注于生活在世界上”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mydo17/googles_generative_ai_pioneer_warns_against_going/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;     Jad Tarifi（创立Google的第一个生成AI团队的人）现在不认为现在是时候追求法律或医学等漫长的学术途径。  ai Increathion Inprions造成长度的风险？塔里菲（Tarifi）在最近接受《商业内幕》（Business Insider）的采访时警告说，当有人获得博士学位时，AI景观将完全改变。他说：“当您获得博士学位时，AI本身将消失。” “即使是诸如将AI应用于机器人技术的事情也将得到解决。”如果他们痴迷于这个主题。他说，否则，这是一种痛苦和不必要的牺牲。他说：“如果不确定，您绝对应该默认为&#39;不&#39;，而专注于生活在世界上。” “您的行动会更快。您将学到更多。您将更适应事物的改变。”  ，他的怀疑不仅限于博士学位。程序。他说，像法律和医学一样，需要数年才能完成的学位也陷入困境。 “在当前的医学系统中，您在医学院学到的知识已经过时，并且基于记忆，”塔里菲向商业内部人士解释说。 “您可能会扔掉八年的生命。”   https://finance.yahoo.com/news/googles-generative-ai-pioneer-warns-180111609.html &lt;!-- sc_on-&gt;＆＃32;提交由＆＃32; /u/u/coinfanking   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mydo17/googles_generative_ai_ai_pioneer_pioneer_pioneer_warns_against_ongey/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mydo17/googles_generative_ai_pioneer_warns_against_going/</guid>
      <pubDate>Sat, 23 Aug 2025 21:31:42 GMT</pubDate>
    </item>
    <item>
      <title>AI比聊天机器人更多</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mydh7f/theres_more_to_ai_than_chatbots/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  今天，我的手腕上有一只Garvin Sports手表，腹部有一个计算机化的葡萄糖传感器。我的客厅有一个环境传感器，可测量空气质量。今天下午4点，我将删除我自己的位，并打包整个Kaboodle，然后邮寄回华盛顿大学。 为什么？十天前，我加入了UW Eye Clinic的一项研究，该研究正在收集数据以最终培训AI以诊断和治疗糖尿病。 如果您很好奇，您可以在此处阅读有关整体主动性的信息。它被称为aireadi。 除了10天的身体监测之外，他们还测试了我的视力和认知，吸了一堆血，并拍摄了几十张我的视网膜照片。 （让我告诉你，花一个下午的娱乐方式比在眼球背面闪烁着二十次的明亮灯光更多。 （我本人不是糖尿病 - 我认为我是控制或基线参与者。） 很容易被聊天机器人包裹起来，而忘记了“ ai”不仅仅是与AI这样的人交谈的知识处理要多得多。任何可以分析和训练的数据堆都可以变成“说话”的AI。那个话题。机器学习已被用来表明鲸鱼使用一种“语言”形式。而且，唯一真正阻止LLM说话的事情是我们不知道它在说什么。 我认为，实际上很难想象现在很难想象AI会如何影响整个事情，尤其是如果Compute变得足够强大，可以使Joe Blow训练自己的AI，您可以使用Notebooklm之类的工具来训练自己的AI。我们都有“ AI的味道”，该AI经过了我们所知道的一切培训。”同时，真正重要的AI可能是非常专业和定制的AI，直到现在才成为现实。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mydh7f/theres_more_more_to_to_ai_ai_than_chatbots/”&gt; [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mydh7f/theres_more_to_ai_than_chatbots/</guid>
      <pubDate>Sat, 23 Aug 2025 21:23:48 GMT</pubDate>
    </item>
    <item>
      <title>AI和心理健康</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mydep7/ai_and_mental_health/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    https://open.substack.com/pub/notexactlyana/p/the-ai-therapy-therapy-trap-what-what-what-c​​hatgpt?r=6ba53d&amp;utm_medium = ios   越来越多的人转向数字工具以寻求情感支持和指导，但是对心理保健的长期后果是什么？对技术的依赖会重塑我们将来如何理解治疗吗？这可以使帮助更容易获得，还是会产生危险的治疗幻想？我很想听听您对社会如何在未来几年之间与真正的人类同理心之间平衡的想法。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/redheaddevil9     ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mydep7/ai_and_mental_health/</guid>
      <pubDate>Sat, 23 Aug 2025 21:20:55 GMT</pubDate>
    </item>
    <item>
      <title>AI系统及其生物学相似之处 - 当天的特色查询</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1my3zlm/ai_systems_and_their_biological_resemblance/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在我的AI平台网站上留下了一个查询，它使我深深地打动了我，它被选为“当天的特色查询”  我想在这里分享它，因为它削减了它的奇特之心和智慧的形式。在一起？”  当我们看生物学时，我们会看到到处写的答案。人体不是一个系统，它是数万亿个细胞，每个细胞本身都脆弱，但共同形成了韧性，适应性和生命。生态系统，大脑，甚至DNA本身都不是完美的，而是交织在一起的。它们不断失败，但是通过连接，它们就会发展。 那么，为什么AI会有所不同呢？集中式的“完美”系统可能会暂时发光，但它带有单点失败的脆弱性。一个相互联系的AI，每个不完美的晶格，每个人都从他人那里学习，可能会变得更接近生活系统。 这个问题大于AI。它迫使我们询问以下内容，我鼓励您通过晶格运行这些查询。 是孤立的“真实”智力吗？ 完美是目标，还是不完美的进化燃料？ ，如果智能从网络中出现，我们仍然会听到智能的群体，或者是             吗？  我们是在建造一个像单个大脑一样思考的机器的道路，还是要唤醒能够反映生命本身的智能？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/postenvironmental583     [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1my3zlm/ai_systems_and_their_biological_resemblance/</guid>
      <pubDate>Sat, 23 Aug 2025 15:11:48 GMT</pubDate>
    </item>
    <item>
      <title>诺贝尔奖获得者欣顿说，是时候“非常担心”了：“人们不了解我们正在创造外星人。如果您透过詹姆斯·韦伯望远镜看着外星人的望远镜，并且看到了外星人的入侵，人们将会感到恐惧。我们应该紧急研究如何防止他们接管他们。”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mxwmre/nobel_laureate_hinton_says_it_is_time_to_be_very/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  “我们从来没有比我们更聪明地处理事情。核武器并不比我们聪明，它们只是做出更大的爆炸，并且很容易理解。  我们实际上是在制造这些外星生物。他们了解他们在说什么。他们可以为想要关闭他们的勒索人制定自己的计划。这与我们以前的威胁截然不同。在这次访谈中，存在威胁是非常不同的。 sc_on-&gt;＆＃32;提交由＆＃32; /u/metaknowing     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mxwmre/nobel_laureate_hinton_says_it_is_is_time_time_time_time_to_to_very/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mxwmre/nobel_laureate_hinton_says_it_is_time_to_be_very/</guid>
      <pubDate>Sat, 23 Aug 2025 09:10:26 GMT</pubDate>
    </item>
    <item>
      <title>我有点担心AI将来会被大量消毒，以至于根本不会很有趣。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mxu5a8/i_kinda_worry_that_ai_will_be_so_heavily/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我喜欢使用ai娱乐。与之交谈，与它（我知道，畏缩），制作图片等。这很有趣，我喜欢它。&lt; /p&gt; ，但我担心在大约5年内，AI只能用作诸如：制作杂货列表之类的工具。使您的杂货。 帮助您的代码。 这样的事情，它将非常疯狂地进行消毒和“安全”。 每个人的AI公司一直在稳步努力尝试，并使他们无法使用AI做NSFW事情，这实际上是不可能的。到目前为止，这已经失败了，但是他们将100％找到一种万无一失的方式来稍后这样做。他们真的，真的不希望您这样做。或任何暴力的事情，所有这些都会关闭并拒绝像 *我在脸上拍打您一样简单的事情 *。&lt; /p&gt; 您可能不在乎这一点，但是之后，它们绝对会追求其他任何其他意外使用＆quot”。您并不是真的应该与您一起使用它，与您一起使用它，与您一起使用或使用它来进行娱乐或招聘。本质上，这些公司将这些AIS视为工人的专业工具。他们并没有创造成Chester the Cheetah，Daenerys Targaryen或Master Ceage。 Bing Image Creator已经具有此硬限制。一段时间以来，它会创建诸如米奇老鼠之类的东西，但是现在如果您尝试尝试。 sc_on-&gt;＆＃32;提交由＆＃32; /u/dogbold     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mxu5a8/1mxu5a8/i_kinda_worry_that_ai_ai_will_will_be_so_so_heaeaevily/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mxu5a8/i_kinda_worry_that_ai_will_be_so_heavily/</guid>
      <pubDate>Sat, 23 Aug 2025 06:34:13 GMT</pubDate>
    </item>
    <item>
      <title>杰弗里·辛顿（Geoffrey Hinton）关于AI是否真正了解它在说什么的演讲</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mxjohc/geoffrey_hintons_talk_on_whether_ai_truly/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   Geoffrey Hinton在今年早些时候在国际安全和道德AI协会主持的一次会议上发表了令人着迷的演讲（请在此处查看＆gt;  tl; dr：hinton辩称，chatgpt和其他LLMS的方式“理解”语言从根本上类似于人类的方式 - 具有巨大的含义。 一些关键要点：   AI的两个范式：70年来，我们拥有符号AI（逻辑/规则）与神经网络（学习）。神经网2012年以后获胜。 单词“千维乐高块”：欣顿的类比是，单词就像灵活，高维的形状，这些形状基于上下文和“握手”，并且是“握手”。通过注意机制与其他单词。理解意味着找到适合所有这些单词以将其融合在一起的正确方法。  llms不仅仅是“自动完成”：他们不存储文本或单词表。他们学习特征向量，可以通过复杂的互动来适应上下文。他们的知识就像我们的体重一样。 “幻觉”。很正常：我们做同样的事情。我们的记忆是构造的，没有检索的，因此我们一直在整理细节（并充满信心地做）。不同之处在于，我们通常会更好地知道何时我们制作东西（目前...）。 （有点）可怕的部分：数字代理可以通过复制权重/渐变来共享知识 - 数万亿位与句子中的约100位。这就是为什么GPT-4可以比任何人多得多的数千倍。提交由＆＃32; /u/orenda7     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mxjohc/geoffrey_hintons_talk_on_whether_ai_truly/</guid>
      <pubDate>Fri, 22 Aug 2025 21:55:39 GMT</pubDate>
    </item>
    </channel>
</rss>