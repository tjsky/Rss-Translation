<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Fri, 22 Aug 2025 12:29:53 GMT</lastBuildDate>
    <item>
      <title>美国人通常对AI的感觉如何？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mx4glb/how_do_americans_generally_feel_about_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我在日常生活中经常使用AI，并注意到许多Reddit用户似乎持怀疑态度。大多数人都信任和使用还是有很多犹豫？我特别好奇的是，在行业或人口统计学方面的看法如何不同。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/silent-worry-4650     [link]        [commist]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mx4glb/how_do_americans_generally_feel_about_ai/</guid>
      <pubDate>Fri, 22 Aug 2025 11:56:41 GMT</pubDate>
    </item>
    <item>
      <title>埃隆·马斯克（Elon Musk）：巨像2将是世界上第一个Gigawatt+ AI训练超级计算机。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mx4294/elon_musk_colossus_2_will_be_the_worlds_first/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;     &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/yshys-reception23     &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1MX4294/1MX4294/ELON_MUSK_COLOSSUS_2_WILL_WILL_BE_BE_THE_WORLDSS_FIRST/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mx4294/elon_musk_colossus_2_will_be_the_worlds_first/</guid>
      <pubDate>Fri, 22 Aug 2025 11:36:46 GMT</pubDate>
    </item>
    <item>
      <title>为什么AI几乎总是在其答复中使用长仪表板（ - ）？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mx215s/why_does_ai_almost_always_use_the_long_dash_in/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   ai在哪里学会始终使用long dash（ - ）？这可能是培训数据的习惯，或者只是可读性的样式选择？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mx215s/why_does_ai_ai_ai_almost_always_ase_the_long_dash_in/&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mx215s/why_does_ai_ai_ai_almost_always_always_always_the_long_dash_in/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mx215s/why_does_ai_almost_always_use_the_long_dash_in/</guid>
      <pubDate>Fri, 22 Aug 2025 09:42:57 GMT</pubDate>
    </item>
    <item>
      <title>哈维尔·米利（Javier Milei）的政府将监视与AI的社交媒体，以“预测未来犯罪”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mwyvjn/javier_mileis_government_will_monitor_social/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mwyvjn/javier_mileis_government_will_monitor_social/</guid>
      <pubDate>Fri, 22 Aug 2025 06:19:23 GMT</pubDate>
    </item>
    <item>
      <title>关于AI和人类的世界的想法？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mwye4u/thoughts_on_ai_and_human_based_world/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mwye4u/thoughts_on_ai_and_human_based_world/</guid>
      <pubDate>Fri, 22 Aug 2025 05:50:21 GMT</pubDate>
    </item>
    <item>
      <title>AI编码不是实际编码更有用的技能</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mwwqu9/ai_coding_is_not_a_more_useful_skills_than_actual/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  似乎这些论坛完全是关于吹嘘自己的AI工作流程多么复杂的人。关于他们的上下文如何提出Claude代码的合法技能。我就像还好吗？这比在C ++中学习游戏开发或编写数据库或学习内存管理更为复杂吗？ 这等同于设置开发人员已经知道该怎么做的开发工作流程和环境。设置Claude代码是否比通过自定义配置和工作流程设置Neovim更复杂？可能不是。 那么，您知道克劳德代码是这项疯狂的新技能，从本质上讲，您只需在整个地方都有文本文件。归根结底，它只是以非确定性的方式生成了一堆代码。或者充其量只是成为一种花式的自动完成，因为您已经限制了模型如此之多，以至于无论如何您还是只要自己编码所有内容。 ，看来只有非编码器似乎只包含Vibe编码。同时，我去了与开发人员有关的论坛，并且有清理错误的恐怖故事。 这是关于LLM的事情，没人想承认： 它们是不可预测的，永远不会预测的。 这就是为什么我只能研究它们的原因。我没有用它们实际做实际的工作。因为工作需要上下文并试图使LLMS上下文意识到上游正在与上游进行战斗。 在短上下文中，窗口很难增加，因为 增加上下文窗口具有二次复杂性。它需要更多的矩阵乘法。 有优化，但它们具有稀疏注意的缺点。但是它的精度较小。  llms仅限于其数学。要通过上下文窗口绕过问题，您需要完全丢弃注意力机制 这对开发意味着什么？根据代码库的复杂性，LLM的性能越来越差。而且，您向LLM的外包代码越多，您对架构的介绍的黑匣子行为 因此，所有这些工作和“ AI技能”的范围比仅仅了解代码更糟糕。由于LLM的基本数学，情况将会变得更糟。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/golanglinuxguru1979       [links]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mwwqu9/ai_coding_is_not_a_more_useful_skills_than_actual/</guid>
      <pubDate>Fri, 22 Aug 2025 04:17:13 GMT</pubDate>
    </item>
    <item>
      <title>缩放作品</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mwv4dt/scaling_works/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  缩放作品。 RL起作用。不要让“边际收益”。在过去的几个月中，您认为AI不会继续显着发展。人们太不耐烦了。 什么是LLM？它们是预测下文下一步标记的模型。有了预测接下来的令牌的能力，您就可以从分布中采样响应。该分布是数据集的衍生物。LLM在上面训练了LLM。  llms（以及特别是变形金刚）已经可以代表以紧凑格式从复杂分布中采样的数据集。当前的“ ai slop”我们要经历的阶段是因为1）数据质量尚未存在，而2）我们还没有接近饱和那里的数据。 前几天，OpenAI CFO的数据显示，全球90％的数据都位于封闭的门后面（例如机构和企业）。 AI仅接受了全球10％的数据的培训，其中大多数是AI斜率。如果您在2000年代网站的数据集上训练AI，您认为它会产生什么？ 2000年代的网站。 现在，如果您在高质量的企业数据上训练AI，则它将从分布中进行采样代表相关的企业数据。 它很简单。我们当前的算法工作和规模。这只是提取正确的数据的问题。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/uphandered-copy332     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mwv4dt/scaling_works/</guid>
      <pubDate>Fri, 22 Aug 2025 02:53:53 GMT</pubDate>
    </item>
    <item>
      <title>还有其他人在工作中对SEO和AI的混合感打交道吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mws6f4/anyone_else_dealing_with_mixed_feelings_about_seo/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我一直在使用AI来帮助工作中的SEO写作。我不是像大学生那样只是要求它去做所有工作，而是让我的语气更加一致并充实某些领域。  在排名方面，它的效果非常好，但是当我的经理发现他们并不激动时。我们从来没有关于在工作场所使用AI使用的对话，而我所听到的只是关于我的内容的积极信息，所以我认为我没有错。  怪异的部分是我公司的其他部分正在启动全面的AI文章，而我的团队显然希望完全避免它。感觉就像行业的不同部分（甚至同一公司）正在以这些东西的速度完全不同。 好奇是否有人遇到了类似的紧张局势，以及他们如何在工作场所处理AI？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mws6f4/anyone_else_else_deal_with_mixed_mixed_feelings_feelings_about_seo/”&gt; [link]   [注释]     ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mws6f4/anyone_else_dealing_with_mixed_feelings_about_seo/</guid>
      <pubDate>Fri, 22 Aug 2025 00:35:09 GMT</pubDate>
    </item>
    <item>
      <title>编码LLMS应该是扩散模型，而不是自回归文本生成器</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mwpvhu/coding_llms_should_be_diffusion_models_not/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  最近使用claude/cursor/gpt来编码和神圣的狗屎，我必须提醒这些模型上有关上下文的次数使我发疯。   好吧，好的，您可以帮助我重构功能，很棒。但是哦，等等，现在读书人已经过时了。哦，有一个测试文件引用旧功能名称。哦，API文档需要更新。哦，还有一个配置文件...您会得到这个想法。 当前的llms基本上是在用代码库一致性播放whack-a摩尔。当它实际上是一个依赖关系的图表时，他们就像是线性对话一样。我们为什么不为代码执行此操作??  想象：您描述了一个更改，而模型只是...  diffuses     是代码库的整个正确状态。所有文件。所有依赖性。所有文档。一枪。不再＆quot oh btw，您还可以更新类型文件。或在3天后发现您的迁移脚本被打破了，因为模型忘记了它的存在。 当前的方法就像在蒙住眼睛时一次绘画Mona Lisa一个笔触，然后在鼻子不匹配脸部时会感到惊讶。同时，扩散就像“这是您的整个一致的代码库，先生”。 厨师的吻  我真的不明白为什么没有人认真对待这一点。仅仅是因为我们陷入了“代码”是文本，文本是顺序的。范例？还是我在这里缺少一些技术限制？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/aginext     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mwpvhu/coding_llms_should_be_diffusion_models_not/</guid>
      <pubDate>Thu, 21 Aug 2025 22:52:20 GMT</pubDate>
    </item>
    <item>
      <title>那些认为AI永远不会有意识的人，为什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mwlvp4/those_of_you_that_think_ai_can_never_be_conscious/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   关于无机物质与有机物是否有一些特殊意识？您甚至怎么知道无机事物是否知道？信息理论是否起作用？只是为那些更好地理解它的人，哲学上的基础对技术而感到好奇。抱歉，如果每个人都厌倦了这个问题，我还没有找到一个有道理的答案。  编辑：AI说神经元使用离子流，计算机使用电子流？计算机具有连续的电压，具有设置的离散解释，神经元具有单个尖峰阈值，并且专注于尖峰频率和时机（没有像电压这样的连续流）。我想知道只有一台具有某种特殊结构的离子计算机才能做到这一点。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mwlvp4/1mwlvp4/those_of_you_that_that_think_think_ai_ai_can_never_never_never_be_consifted/”&gt; [links]     32;  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mwlvp4/1mwlvp4/those_of_you_that_that_think_think_ai_ai_can_never_never_never_never_be_consiuct/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mwlvp4/those_of_you_that_think_ai_can_never_be_conscious/</guid>
      <pubDate>Thu, 21 Aug 2025 20:13:22 GMT</pubDate>
    </item>
    <item>
      <title>Microsoft AI负责人称意识研究为“危险”，而Anthropic，Openai，Google在现场积极雇用</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mwj5wu/microsoft_ai_chief_calls_consciousness_research/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  穆斯塔法·苏莱曼（Mustafa Suleyman）刚刚发表了一篇博客文章，认为研究AI福利是&#39;早产，而且坦率地说是危险的。&#39; 他的理由？它可能会使人们认为AI可能有意识，导致“不健康的依恋”。 同时：  拟人化发起了一项专门的AI福利研究计划  OpenAi研究人员公开地接受了意识     google  google  li&gt; google   google            li&gt; li&gt; li&gt; li&gt;有害的对话（行动中的字面AI福利）  我试图了解何时“不研究，这是危险的”成为有效的科学方法论吗？这感觉不像科学推理，而更像是公司定位。 关于研究新兴现象和宣布整个研究领域之间应有的界限的想法？  https://techcrunch.com/2025/08/21/microsoft-ai-chief-says-its-dangerous-to-study-ai-consciousness/  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/petermossack     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mwj5wu/microsoft_ai_chief_calls_consciousness_research/</guid>
      <pubDate>Thu, 21 Aug 2025 18:31:05 GMT</pubDate>
    </item>
    <item>
      <title>AI部门发生的裁员是没有意义的。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mwgupn/layoffs_happening_in_ai_departments_doesnt_make/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  公司正在介绍对AI研究的重点，但是从统计数据中，AI研究部门也正在发生许多裁员。为什么？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ajagajan_007     [link]     32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mwgupn/layoffs_happening_in_ai_departments_doesnt_make/</guid>
      <pubDate>Thu, 21 Aug 2025 17:05:38 GMT</pubDate>
    </item>
    <item>
      <title>人工智能繁荣面临障碍 - 这就是为什么我认为重大估值更正即将接近</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mwgpah/the_ai_boom_is_facing_obstacles_heres_why_i/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mwgpah/the_ai_boom_is_facing_obstacles_heres_why_i/</guid>
      <pubDate>Thu, 21 Aug 2025 17:00:17 GMT</pubDate>
    </item>
    <item>
      <title>95％的公司AI计划是毫无价值的。华尔街恐慌。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mw9onw/95_of_corporate_ai_initiatives_are_worthless_wall/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在gizmodo上找到了本文。 TL; dr -95％的AI计划由公司发起的任何福利都没有产生任何福利，这可能会引起资金：   https://gizmodo.com/-/gizmodo.com/the-report-port-report-port-thats-pook---thats-pooking-wall-s-pooking-wall-wall-s-wall-street-street-s-2000645518 提交由＆＃32; /u/u/vengeful_bunny     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mw9onw/95_of_corporate_ai_initiatives_are_worthless_wall/</guid>
      <pubDate>Thu, 21 Aug 2025 12:34:30 GMT</pubDate>
    </item>
    <item>
      <title>Zuckerberg冻结了AI在泡泡恐惧中招聘</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mw7i5e/zuckerberg_freezes_ai_hiring_amid_bubble_fears/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;      此举与梅塔报道的薪水急剧相反，最高可达最高10亿美元的顶级人才        马克·扎克伯格（Mark Zuckerberg泡沫。 这家技术巨头已经冻结了其“独特实验室”的招聘，只有AI首席Alexandr Wang必须批准的极少数例外。    阅读更多：   https://www.telegraph.co.uk/business/2025/08/21/zuckerberg-freezes-ai-hiring-amid-bubble-fears/      &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/thetelegraph   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mw7i5e/zuckerberg_freezes_ai_ai_ai_amid_amid_amid_mid_bubble_fears/  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mw7i5e/zuckerberg_freezes_ai_ai_hiring_amid_amid_amid_amid_amid_amid_amid_amid_mid_bubble_fears/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mw7i5e/zuckerberg_freezes_ai_hiring_amid_bubble_fears/</guid>
      <pubDate>Thu, 21 Aug 2025 10:47:53 GMT</pubDate>
    </item>
    </channel>
</rss>