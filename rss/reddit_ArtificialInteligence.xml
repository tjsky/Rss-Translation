<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Sat, 26 Jul 2025 12:30:15 GMT</lastBuildDate>
    <item>
      <title>Openai在IOI 2025的存在</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m9qtg1/openais_presence_in_ioi_2025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我是积极的OpenAi的模型，也将在IOI上尝试 它在2025年IMO上获得了金牌，并在Atcoder Heuristical the Atcoder Hearistics竞赛中获得了第二名     &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/plem_read_7020     [link]    ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m9qtg1/openais_presence_in_ioi_2025/</guid>
      <pubDate>Sat, 26 Jul 2025 11:17:59 GMT</pubDate>
    </item>
    <item>
      <title>🚨赶上AI行业，2025年7月26日</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m9oek2/catch_up_with_the_ai_industry_july_26_2025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    AI治疗师脱离了轨道  Delta的AI间谍必须禁止“提高”价格。模式  Google推出了opal来构建AI Mini-Apps   Google和UC Riverside创建新的DeepFake检测器    来源：     https://futurism.com/ai-therapist-haywire-mental-mental-health     &gt; https://arstechnica.com/tech-policy/2025/07/deltas-ai-spying-to-jack-up-prices-must-be-be-be-band--be-band-band-makers-say/      https://www.testingcatalog.com/microsoft-prepares-copilot-for-gpt-5-with-with-new-new-smart-mode-indevelopment/     https://develovelers.googleblog.com/en/introducing-opal/  href=&quot;https://www.sciencedaily.com/releases/2025/07/250724232412.htm&quot;&gt;https://www.sciencedaily.com/releases/2025/07/250724232412.htm   ＆＃32;提交由＆＃32; /u/u/psycho_apple_juice     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m9oek2/catch_up_with_the_ai_industry_july_26_2025/</guid>
      <pubDate>Sat, 26 Jul 2025 08:41:58 GMT</pubDate>
    </item>
    <item>
      <title>云供应商的ML证书是什么意思？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m9ndh5/what_are_ml_certs_by_cloud_vendors_really_about/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我一直从AWS，Azure，Google和Oracle看到ML认证。 I’m wondering what are these certs are actually about? Do they only test your knowledge of their platforms, or do they help make ML work easier, like through services that let you build models without needing to know much about the math or code behind it? Basically: can you start doing ML with these cloud tools without knowing deep AI theory, or are these certs more for people who already understand the fundamentals? &lt;!-- sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1m9ndh5/what_are_are_are_ml_certs_by_cloud_vendors_really_about/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1m9ndh5/what_are_are_ml_certs_by_by_cloud_vendors_vendors_really_about/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m9ndh5/what_are_ml_certs_by_cloud_vendors_really_about/</guid>
      <pubDate>Sat, 26 Jul 2025 07:33:27 GMT</pubDate>
    </item>
    <item>
      <title>什么时候使用AI停止创意工作？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m9mb8o/when_does_using_ai_stop_being_creative_work/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  ，所以我注意到在使用AI时，我确实被解雇了很多工作。我不相信人们了解创建产品的工作。例如，我通过绘制设计并完善特定方面创建了一个设计，然后使用AI生成可以使用的东西。然后，我在Paint Shop Pro和决赛入围者中编辑该设计，全部增加了7-8个小时的工作和研究，但由于“ AI”而被解雇，因为它是“ AI”。 我完全理解是否只是要求它生成某些东西，然后我声称自己是我自己的。 这也对小小的观点呈现出来，用ai的意见来确定 a priond a priend o a&#39;&#39;我在这里错了？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/stbojangles   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1m9mb8o/when_does_usis_ai_ai_stop_being_creative_work/”&gt; [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m9mb8o/when_does_using_ai_stop_being_creative_work/</guid>
      <pubDate>Sat, 26 Jul 2025 06:27:38 GMT</pubDate>
    </item>
    <item>
      <title>格兰诺拉麦片 - 您的会议笔记是公开的！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m9lox6/granola_your_meeting_notes_are_public/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果您使用格兰诺拉麦片应用程序进行注释，然后读取。 默认情况下，您创建的每个音符都有一个可共享的链接：任何人都可以访问您的笔记。这些链接没有索引，但是如果您共享或泄漏一个链接（即使是偶然的），   对找到它的人来说是公开的。  将您的设置转换为“私人”只能保护未来的笔记。您所有早期的笔记都保持暴露，直到您一一手动将其锁定为止。没有回顾性的大量更新。  立即将您的格兰诺拉麦片设置更改为私人。审核您的旧笔记。删除您不想漂浮的链接。不要自满 - ＃隐私从来都不是默认值。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/floating-pointer     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m9lox6/granola_your_meeting_notes_are_public/</guid>
      <pubDate>Sat, 26 Jul 2025 05:50:42 GMT</pubDate>
    </item>
    <item>
      <title>人工智能势头之后的人类智能</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m9fcev/human_intelligence_in_the_wake_of_ai_momentum/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  ，因为我们人类正在慢慢选择提供自己的答案（合理的是 - 这是更实用的），所以我们需要变得更好地提出问题。   ，我的意思是，我们需要在提出更好的问题上提出更好的问题。我的意思不是更好地提示或抗拒，以“破解” LLM机器的答案功能，但我的意思是要问更多，充电，多样化和创造性的后续问题，以便我们从原始的答案中获得答案。因为保护和保留我们的脑容量的流量和发展要比从AI中获得我们需要的东西要重要得多。 实时时间。增强我们的好奇心并喂食它（我们的大脑，而不是AI），学习更广泛或更深入。 学习枪支查询，就像您在一个伪装游戏中一样，或者那个众所周知的盲人感觉到大象的脚并试图猜测大象。   不一定要获得更好的答案，而是要在各个方面得到一个自我的兴奋，而是要在各个方面加强自己的知识。而且不一定要精确（提出正确的问题），而是掌权（想了解更多）。 这是我们唯一的希望。由于我们大脑中的某些肌肉在生长中受到阻碍，因此我们需要成长其他肌肉，以免它自己吃掉。我们正在离开知识时代，并通过好奇心  进入发现时代（我在单独的媒体中将其作为评论，内容涉及AI的主题，因为AI已经接管了我们批判性思考的能力。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1m9fcev/human_intelligence_in_the_wake_wake_wake_of_ai_momentum/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m9fcev/human_intelligence_in_the_wake_of_ai_momentum/</guid>
      <pubDate>Sat, 26 Jul 2025 00:16:53 GMT</pubDate>
    </item>
    <item>
      <title>试图指导出色的软件工程师建立出色的提示</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m9c4x2/trying_to_guide_great_software_engineers_on/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m9c4x2/trying_to_guide_great_software_engineers_on/</guid>
      <pubDate>Fri, 25 Jul 2025 21:56:10 GMT</pubDate>
    </item>
    <item>
      <title>当地运行AI的实际原因？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m9ajed/practical_reason_to_run_ai_locally/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嗨，我正在寻找人们想在本地运行AI的实际原因吗？ :)我知道： *隐私（大个子） *省略限制/审查（生成裸体等） *离线工作 * Fun/Learning  看来，在大多数地区，其他任何东西都比电力更便宜。我喜欢为我的东西运行它的想法，这样做很酷（有趣/学习），但要寻找任何实际的理由：d   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/larumis     [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m9ajed/practical_reason_to_run_ai_locally/</guid>
      <pubDate>Fri, 25 Jul 2025 20:50:43 GMT</pubDate>
    </item>
    <item>
      <title>使用稳定的扩散（或类似）来解决新的英国面部验证要求</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m97k58/using_stable_diffusion_or_similar_to_get_around/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  对于那些思考的人，您在1984年做什么？” here in the UK we&#39;ve just come under the new Online Safety Act, after years of it going through parliament, which means you need to verify your age for a lot of websites, Reddit included for many NSFW subs, and indeed many non-NSFW subs because the filter is broken. However, so not everyone has to include personal details, many websites are offering a verification method whereby you show your face on camera, and it tells you if it thinks you&#39;re old 足够的。可能是一个有缺陷的系统 - 它正在使用AI来确定您的年龄，因此会有很多错误，但这让我想到了 -   您可以通过使用AI？ 欺骗AI？使用稳定的扩散和一些不同的模型。幸运的是，一个伴侣已经下载了很多模型，因为Civit AI现在在英国被完全封锁了 - 甚至无法证明您的年龄，该立法对他们的小型专用团队无法处理，因此整个国家都被锁定了。      do  die 都要求您在前视图中工作，然后稍微转过头，然后再稍稍旋转一侧，另一个是另一个。我们没有人足够先进，无法知道如何制作像这样的视频AI脸/头部。但是，很有趣的是知道是否有人管理了这个问题？地点。现在，大多数人都想检查一下。 是的，我可以使用VPN，但是a）我不想支付VPN，除非我真的需要付费，否则大多数色情网站都不会使用验证工具，他们只是不在乎，他们只是不在乎我的定期使用，而且我对AI和p）的兴趣很感兴趣，而且我真的很感兴趣， [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m97k58/using_stable_diffusion_or_similar_to_get_around/</guid>
      <pubDate>Fri, 25 Jul 2025 18:52:18 GMT</pubDate>
    </item>
    <item>
      <title>为什么大多数AI模型都具有像徽标这样的星星？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m97c5g/why_most_of_the_ai_models_has_star_like_logo/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  喜欢Google Gemini，Apple Intelligence等。另一个是在给出答案时，该模型给出了魔术标记sorta   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ggravating_soil8988      [links]        [注释]     ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m97c5g/why_most_of_the_ai_models_has_star_like_logo/</guid>
      <pubDate>Fri, 25 Jul 2025 18:43:37 GMT</pubDate>
    </item>
    <item>
      <title>AI的新技能不是提示的，而是上下文工程</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m973yp/the_new_skill_in_ai_is_not_prompting_its_context/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  构建功能强大可靠的AI代理在寻找魔术提示或模型更新方面变得越来越少。这是关于上下文的工程，并在正确的时间以正确的格式提供正确的信息和工具。这是一个跨职能挑战，涉及了解您的业务用例，定义您的产出并构建所有必要的信息，以便LLM可以“完成任务。     [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m973yp/the_new_skill_in_ai_is_not_prompting_its_context/</guid>
      <pubDate>Fri, 25 Jul 2025 18:34:49 GMT</pubDate>
    </item>
    <item>
      <title>让AI记住关键信息的任何技巧吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m94rtc/any_tricks_for_getting_ai_to_remember_key/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   chat gpt对于我来说，聊天GPT对我来说是不可用的，因为它似乎只是在给出答案之前简要介绍任何项目文档或最近的提示。我可以将自己的写作中的30页上传供参考，以便在我的声音中写入，但是它仍然默认为典型的聊天gptism和写下节奏，同时试图将悬念塞入其他每一行。或者我可以在提示中两次告诉它不要使用EM破折号，但仍然会。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/master_wash9334     [link]      [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m94rtc/any_tricks_for_getting_ai_to_remember_key/</guid>
      <pubDate>Fri, 25 Jul 2025 17:05:10 GMT</pubDate>
    </item>
    <item>
      <title>LLM同意我说的一切。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m8y88w/llm_agrees_to_whatever_i_say/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我们都知道一个超级积极的朋友。 您问他们任何事情，他们会说是。需要帮助吗？是的。想一起建立一家初创公司吗？是的。凌晨2点有一个疯狂的主意吗？让我们来做！ 这就是大多数AI模型现在的感觉。超级聪明，超级乐于助人。但也太愉快了。 询问llm的任何东西，它将尝试说是的。即使是含义：弥补事实，同意有缺陷的逻辑，在应该说“我不知道”时产生某些内容。 有时，这种盲目的积极性不是智慧。这是幻觉的根源。 ，事实是我们不仅需要更聪明的AI。我们需要更多诚实的人工智能。 AI说不。向后推的AI。问“确定吗？”的AI  那是真正的智能开始的地方。不是对所有事物都说“是”，而是知道什么时候不。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/prajwal_gote    href =“ https://www.reddit.com/r/artcoverinteligence/comments/1m8y88w/llm_agrees_to_to_to_to_to_to_towhatewhate_i_say/”&gt; [link]    ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m8y88w/llm_agrees_to_whatever_i_say/</guid>
      <pubDate>Fri, 25 Jul 2025 12:47:02 GMT</pubDate>
    </item>
    <item>
      <title>AI会加速通往新狂欢的途径吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m8wd17/will_ai_accelerate_a_pathway_towards_neofeudalism/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我们近几十年来经历了全球收入和财富不平等的增加。目前，我们将不可避免地会创建一类超级富裕的“土地所有者”的狭窄AI，还是只有在开发一般AI时才会散发？ 是否有可能将来可以维持当前的财富不平等水平？ 后续问题。如果/当开发一般AI时，您是否认为它将被扩散并能够由普通个人控制，或者您认为它只会由公司或超级富人拥有和控制？还是会有更好，更糟糕的一般AI模型相互竞争，因此更富有的人可能可以使用更好的模型？ ，对不起，如果我们确实有一般的AI模型相互竞争，那么对社会，个人和市场的影响实际上会是什么样？提交由＆＃32; /u/ushabl ___ bee     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m8wd17/will_ai_accelerate_a_pathway_towards_neofeudalism/</guid>
      <pubDate>Fri, 25 Jul 2025 11:13:03 GMT</pubDate>
    </item>
    <item>
      <title>太多的人试图使Jarvis不够试图制作wall-e</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m8sp74/too_many_people_trying_to_make_jarvis_not_enough/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   wall-e表示对周围世界的同理心，好奇心和真正的关心。尽管Jarvis作为一种工具令人印象深刻，但Wall-E体现了形成有意义的联系并在简单事物中看到美丽的AI。也许我们需要更多欣赏日落的AI。这不是很好的策划，但是您怎么看？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/ok_report_9574     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1m8sp74/too_many_people_people_trying_tro_trying_to_make_jarvis_jarvis_not_enot_enough/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m8sp74/too_many_people_trying_to_make_jarvis_not_enough/</guid>
      <pubDate>Fri, 25 Jul 2025 07:18:45 GMT</pubDate>
    </item>
    </channel>
</rss>