<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Sun, 27 Jul 2025 04:04:00 GMT</lastBuildDate>
    <item>
      <title>17岁时，我该如何领先于AI曲线？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mac5sm/how_can_i_as_a_17_year_old_get_ahead_of_the_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿，我永远从事技术和编程，我很喜欢它。但是AI最近一直很害怕我，因为它从事工作，使一切自动化，并且总体上使我的热情无用。所以我的问题是，我17岁时该怎么办，以确保我长大时在AI中拥有未来？我应该学习如何制作自己的AI，学习如何将AI实施到日常生活中等。 我要在大学里进行工程学，我可能会专注于计算机或电气工程，但是在这一点上，我什至不知道如果未来将通过AI运行，我是否应该这样做。任何答案都是巨大的帮助，谢谢！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/newbuilder2212     [links]      &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mac5sm/how_can_i_i_as_a_a_17_year_year_get_get_get_ahead_ahead_ahead_of_of_the_ai/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mac5sm/how_can_i_as_a_17_year_old_get_ahead_of_the_ai/</guid>
      <pubDate>Sun, 27 Jul 2025 03:26:05 GMT</pubDate>
    </item>
    <item>
      <title>对未来极为恐惧</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1maat71/extremely_terrified_for_the_future/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   Thraway帐户，因为很明显。我真的为未来感到恐惧。我有一个七个月大的儿子，我几乎后悔拥有他，因为我把他带到了一个注定要失败的世界。他将根据不可能争论的预测来遭受痛苦和过着短暂的生活。预计将在未来十年中达到AGI，然后ASI随后到达。我们达到对齐方式或对齐方式甚至可能是如此苗条，几乎是不可能的。我为此自杀。我知道我将在这篇文章上被嘲笑，而且我敢肯定，这个潜艇中的每个人都会认为我是一个巨大的三衣。我只是为我的孩子担心。如果我没有儿子，我可能会挂上它。我丈夫告诉我，一切都会好起来的，没有人希望人类去世，那是“他们”会在它变大之前停止它，但变量太多。我们将在我们的一生中到达ASI，这将摧毁我们。我对此有螺旋式的态度。还有其他吗？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/fizzyB0MB    href =“ https://www.reddit.com/r/artcoverinteligence/comments/1maat71/extremely_terrified_for_for_for_the_future/”&gt; [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1maat71/extremely_terrified_for_the_future/</guid>
      <pubDate>Sun, 27 Jul 2025 02:14:31 GMT</pubDate>
    </item>
    <item>
      <title>可能是愚蠢的想法，但是：AI（或正确的术语是）可以存在“消费者”吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ma8lkc/potentially_silly_idea_but_can_ai_or_whatever_the/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这听起来很愚蠢，就像十岁的孩子问我们为什么根本不能“打印”无限的钱一样。但是这里…… 很多人一直在问，如果人们（目前大多是失业者）没有资源来负担这些产品或服务，那么拥有大多数自动化劳动力的经济才能运作。随着机器占用了所有工作，我们其他人的失业和破产，整个事情本身就崩溃了，然后是BAM：社会崩溃/核大赛。 现在，我们知道金钱本身就是一种社会结构 - 这意味着量化和从我们的商品和劳动中量化物质价值。此外，即使是加密货币（例如加密货币）也是由运行复杂计算的机器自主“挖掘”的，该价值将用于所花费的上述机器的所有者。但是，除非我们能够自动化所有工作并生活在理论上的“货币后经济”中，否则我们需要保持资本主义机器的运转（或推翻整个事情，但这是另一个帖子的故事）。但是，资本主义算法要求通过NLMS及其继任者不惜一切代价进行无限增长，这是其新的且可能不可阻挡的降低成本措施，使公司和股东无法面对可怕的事物，这些事情称为“季度损失”。因此，为什么我们根本不能“打印”或“我的”更多的钱，因为它需要与它创造的具体价值息息相关，或者我们得到通货膨胀（我认为？备份我，实际的经济学家）。 因此，随着机器逐渐逐渐成为我们的主要生产商，我们还可以牵强的工具或仿真的工具和仿真，以便像“消费者”那样的工具和仿真来购买？他们可以拥有银行帐户和所有内容。他们的大多数“收入”以很高的税率（考虑到他们更有限的“需求”）征税，这些税收中的所有价值都可以用于为UBI和其他计划为美国肉袋提供资金，而其余的则用于维护服务器或其他任何东西。因此，…  corporations获得了使他们保持富裕的消费类别，工作阶层的人能够生存（直到我们弄清楚整个“无钱的社会”的事情，直到我们找出整个“无钱的社会”的事情），✅政治使每个人都保持快乐，并且在逃脱的风险很低……  p&gt; p&gt;   puge          工作。授予机器“人格”实际上是一种解决方案吗？谁能控制整个事情？他们购买的所有狗屎会发生什么？ 但是快点吧，我想在诺斯特罗普·格鲁曼（Northrop-Grumman）赞助的OpenAi度假村度过剩下的时间里喝Roomba服务的玛格丽塔酒。   &lt;！ -  sc_on- sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ma8lkc/potentyly_silly_silly_idea_but_but_can_ai_ai_or_or_er_whatewer_theyter_/&gt; [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ma8lkc/potentially_silly_idea_but_can_ai_or_whatever_the/</guid>
      <pubDate>Sun, 27 Jul 2025 00:22:18 GMT</pubDate>
    </item>
    <item>
      <title>未来的人工智能依赖和人类社会</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ma8asx/ai_dependency_and_human_society_in_the_future/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我对这种AI情况感到好奇，AI已经很强大，可以帮助人们无限获取知识并帮助他们决定自己的选择。人们将如何从AI泡沫中出来并以实践方式看待世界。他们会失去社交技能，人类的信任，人际关系和孤独吗？当每个人都与彼此脱离并生活在自己的口袋尺寸时，整个社会将会发生什么。？提交由＆＃32; /u/u/maximusnaidu    href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ma8asx/ai_depperency_and_human_society_in_in_future/”&gt; [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ma8asx/ai_dependency_and_human_society_in_the_future/</guid>
      <pubDate>Sun, 27 Jul 2025 00:07:06 GMT</pubDate>
    </item>
    <item>
      <title>热门：软件工程师不会消失，但是软件（我们知道）将会</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ma09yz/hot_take_software_engineers_will_not_disappear/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  随着AI模型的提高，推理和解决问题的技能，未来对软件开发人员的未来需求总是会出现…… ，但是，如果软件开发作为“技能”将变得民主和可用于每个人，那么在经济上，这意味着要付费一个人，这意味着要付费。您想要的功能费用以及其他客户想要的功能b）自己开发它（字面上是您自己，或雇用了“技能”的十亿人中的任何人），以实现您想要的功能，仅此而已。 您会选择什么？什么实际上会提供最佳的ROI？ 开发自己的CRM，人力资源系统，库存管理系统等的成本在历史上一直很高，因为软件开发不值得。因此，您可以满足您需求的最佳SaaS。  但是，在不久的将来，自我开发和完全拥有您组织所需软件的IP的投资回报率（除非可能具有超级高级和任务至关重要的一项关键软件）实际上可能是有道理的。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ma09yz/hot_take_software_engineers_will_will_not_disappear/”&gt; [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ma09yz/hot_take_software_engineers_will_not_disappear/</guid>
      <pubDate>Sat, 26 Jul 2025 18:15:59 GMT</pubDate>
    </item>
    <item>
      <title>只有20％的就业机会，工作后经济将是什么样的？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m9xlx6/with_just_20_employment_what_would_a_postwork/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在领先的AI研究人员中，一场辩论已经结束 - 他们估计有80％至85％的概率，只有20％的成年人仍将在2040年代中期有带薪工作（Grace K.等人，2022年，2022年，2022年）。 （Susskind D，2020年），“机器人规则” （Ford M.，2021） 大多数经济学家的注意力现在集中在我们其他人的可持续后工作世界（Susskind D.，2020; Srnicek＆amp＆amp; Williams，2015年）。 。但是不确定其他功能可能还包括在内。 Such as, automation dividends, universal basic services (food, housing, healthcare), and unpaid jobs retained for social and other non economic purposes (Portes J. et al., 2017; Coote &amp; Percy, 2020). A key question remains: Who will own the AI and robotics infrastructure? But what do you think a sustainable hybrid economic model will actually look喜欢？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/ferggusmed   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1m9xlx6/with_just_20_20_employment_what_would_a_postwork/&gt; [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m9xlx6/with_just_20_employment_what_would_a_postwork/</guid>
      <pubDate>Sat, 26 Jul 2025 16:27:21 GMT</pubDate>
    </item>
    <item>
      <title>初中AI科学家角色的AI/ML副总裁的最终采访 - 我应该期待什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m9x10e/final_interview_with_vp_of_aiml_for_junior_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嗨， 我在AI启动时，我的最后一轮面试即将参加初级ML工程师职位。最后一轮是与AI/ML的副总裁的对话，我真的很想准备好的准备，尤其是因为与某人一起，高级资深😅 在这种情况下，我应该从副总裁级别的访问者那里期待哪些类型的问题？尤其是因为我是一名初级科学家，但是具有强大的研究背景。 会很喜欢任何建议 - 示例问题，心态提示或要强调的事情以给人留下深刻的印象。谢谢！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/extension-finish-365     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m9x10e/final_interview_with_vp_of_aiml_for_junior_ai/</guid>
      <pubDate>Sat, 26 Jul 2025 16:03:41 GMT</pubDate>
    </item>
    <item>
      <title>初中AI科学家角色的AI/ML副总裁的最终采访 - 我应该期待什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m9wu8f/final_interview_with_vp_of_aiml_for_junior_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我在AI初创公司的AI科学家实习中进行了最后的采访。最后一轮是与AI/ML副总裁的对话，我真的很想做好准备 - 尤其是因为与某人一起，对于我应该在这种情况下我应该从VP级访问者那里期待哪些类型的问题的任何想法？   会欣赏任何建议，以使任何建议示例，以使您的想法，以使您的意见，或者表现出强烈的印象。谢谢！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/maxmain_vegetable592     [link]   [注释]    ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m9wu8f/final_interview_with_vp_of_aiml_for_junior_ai/</guid>
      <pubDate>Sat, 26 Jul 2025 15:56:18 GMT</pubDate>
    </item>
    <item>
      <title>我们都是令人毛骨悚然的阴谋理论家吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m9tmsu/are_we_all_creepy_conspiracy_theorists/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我来自德国。我本人不是来自IT领域，但我仍然在一个很小的IT中心完成了学业。我想说的是，我对软件和硬件的编程具有基本知识。我本人在业余时间已经编程了25年以上。那时我仍在编程Q Basic。然后C ++，Java脚本等。但是，我不会说我与在大学学习这些知识并且已经在其职业生涯中具有编程经验的人相提并论。我一直在观察人工智能的发展已经很长时间了，当然，尤其是过去十二个月，这非常有成形，对未来也很重要。我在熟人的圈子中看到了它，我在认真的报纸和其他媒体中读到了它：人工智能已经处于使许多职业变得过时的水平。就在昨天，我再次阅读了一家拥有20个程序员的公司。 16人被冗余。这是董事总经理简单的Milquetoast计算。我现在的问题是：当我与不来自这个领域的环境中的人们谈论这个话题时，他们经常以一种稍微光顾的方式对我微笑。 我也注意到媒体已经接受了这个话题，但主要是在传递中。我很清楚，世界政治局势目前非常脆弱，需要提及其他重要问题。我最近越来越经常问自己的问题是什么：我是在意见泡沫中吗？我是那种说地球平坦的人吗？在我看来，我似乎与人交谈并告诉他们1 + 1是两个，每个人都说：“不，这是错误的，1 + 1是三个。您在这方面有什么经验？您如何处理它？ 编辑： 非常感谢您已经写过的所有答案！这些给我带来了进一步的问题。但是，我想提前提到，我的职业与技术完全无关，而且我当然不是一个好的程序员。因此，我依赖与其他人的互动，尤其是专家。但是，这里的情况类似于COVID时代：一位流行病学的教授兼专家说了一件事，而另一位教授在同一天说的相反。那是并且正在愤怒。换句话说，我将尝试再次描述我的观点： 许多人喜欢将人工智能领域的当前发展与工业革命进行比较。然后有人认为这当然具有成本工作，但也创造了新的工作。但是，我认为我收集了足够的信息，我相信我知道蒸汽机绝不会与今天已经可用的人工智能相同。后者是一个全新的维度，它已经自主工作（幸运的是仍在受保护的房间中脱机 - 直到硅谷中的一位百万富翁吞咽过多的LSD，并认为将设备连接到互联网会很有趣）。我什至不认为它一定是LSD：这种技术背后的令人难以置信的效力是天堂中的果实。在某个时候，有人会想知道这种效力的真正高度，并且每天都在增长。在这种情况下，我们将没有更多的工作。在这种情况下，我们将是奴隶，是旨在最大化效率的系统的属性。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/lawflenseunhappy458     [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m9tmsu/are_we_all_creepy_conspiracy_theorists/</guid>
      <pubDate>Sat, 26 Jul 2025 13:40:50 GMT</pubDate>
    </item>
    <item>
      <title>Openai在IOI 2025的存在</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m9qtg1/openais_presence_in_ioi_2025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我是积极的OpenAi的模型，也将在IOI上尝试 它在2025年IMO上获得了金牌，并在Atcoder Heuristical the Atcoder Hearistics竞赛中获得了第二名     &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/plem_read_7020     [link]    ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m9qtg1/openais_presence_in_ioi_2025/</guid>
      <pubDate>Sat, 26 Jul 2025 11:17:59 GMT</pubDate>
    </item>
    <item>
      <title>🚨赶上AI行业，2025年7月26日</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m9oek2/catch_up_with_the_ai_industry_july_26_2025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    AI治疗师脱离了轨道  Delta的AI间谍必须禁止“提高”价格。模式  Google推出了opal来构建AI Mini-Apps   Google和UC Riverside创建新的DeepFake检测器    来源：     https://futurism.com/ai-therapist-haywire-mental-mental-health     &gt; https://arstechnica.com/tech-policy/2025/07/deltas-ai-spying-to-jack-up-prices-must-be-be-be-band--be-band-band-makers-say/      https://www.testingcatalog.com/microsoft-prepares-copilot-for-gpt-5-with-with-new-new-smart-mode-indevelopment/     https://develovelers.googleblog.com/en/introducing-opal/  href=&quot;https://www.sciencedaily.com/releases/2025/07/250724232412.htm&quot;&gt;https://www.sciencedaily.com/releases/2025/07/250724232412.htm   ＆＃32;提交由＆＃32; /u/u/psycho_apple_juice     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m9oek2/catch_up_with_the_ai_industry_july_26_2025/</guid>
      <pubDate>Sat, 26 Jul 2025 08:41:58 GMT</pubDate>
    </item>
    <item>
      <title>格兰诺拉麦片 - 您的会议笔记是公开的！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m9lox6/granola_your_meeting_notes_are_public/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果您使用格兰诺拉麦片应用程序进行注释，然后读取。 默认情况下，您创建的每个音符都有一个可共享的链接：任何人都可以访问您的笔记。这些链接没有索引，但是如果您共享或泄漏一个链接（即使是偶然的），   对找到它的人来说是公开的。  将您的设置转换为“私人”只能保护未来的笔记。您所有早期的笔记都保持暴露，直到您一一手动将其锁定为止。没有回顾性的大量更新。  立即将您的格兰诺拉麦片设置更改为私人。审核您的旧笔记。删除您不想漂浮的链接。不要自满 - ＃隐私从来都不是默认值。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/floating-pointer     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m9lox6/granola_your_meeting_notes_are_public/</guid>
      <pubDate>Sat, 26 Jul 2025 05:50:42 GMT</pubDate>
    </item>
    <item>
      <title>人工智能势头之后的人类智能</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m9fcev/human_intelligence_in_the_wake_of_ai_momentum/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  ，因为我们人类正在慢慢选择提供自己的答案（合理的是 - 这是更实用的），所以我们需要变得更好地提出问题。   ，我的意思是，我们需要在提出更好的问题上提出更好的问题。我的意思不是更好地提示或抗拒，以“破解” LLM机器的答案功能，但我的意思是要问更多，充电，多样化和创造性的后续问题，以便我们从原始的答案中获得答案。和切向的。因为保护和保留我们的脑容量的流量和发展要比从AI中获得我们需要的东西要重要得多。 实时时间。增强我们的好奇心并喂食它（我们的大脑，而不是AI），学习更广泛或更深入。 学习枪支查询，就像您在一个伪装游戏中一样，或者那个众所周知的盲人感觉到大象的脚并试图猜测大象。   不一定要获得更好的答案，而是要在各个方面得到一个自我的兴奋，而是要在各个方面加强自己的知识。而且不一定要精确（提出正确的问题），而是掌权（想了解更多）。 这是我们唯一的希望。由于我们大脑中的某些肌肉在生长中受到阻碍，因此我们需要成长其他肌肉，以免它自己吃掉。我们正在离开知识时代，并通过好奇心  进入发现时代（我在单独的媒体中将其作为评论，内容涉及AI的主题，因为AI已经接管了我们批判性思考的能力。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1m9fcev/human_intelligence_in_the_wake_wake_wake_of_ai_momentum/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m9fcev/human_intelligence_in_the_wake_of_ai_momentum/</guid>
      <pubDate>Sat, 26 Jul 2025 00:16:53 GMT</pubDate>
    </item>
    <item>
      <title>AI的新技能不是提示的，而是上下文工程</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m973yp/the_new_skill_in_ai_is_not_prompting_its_context/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  构建功能强大可靠的AI代理在寻找魔术提示或模型更新方面变得越来越少。这是关于上下文的工程，并在正确的时间以正确的格式提供正确的信息和工具。这是一个跨职能挑战，涉及了解您的业务用例，定义您的产出并构建所有必要的信息，以便LLM可以“完成任务。     [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m973yp/the_new_skill_in_ai_is_not_prompting_its_context/</guid>
      <pubDate>Fri, 25 Jul 2025 18:34:49 GMT</pubDate>
    </item>
    <item>
      <title>LLM同意我说的一切。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m8y88w/llm_agrees_to_whatever_i_say/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我们都知道一个超级积极的朋友。 您问他们任何事情，他们会说是。需要帮助吗？是的。想一起建立一家初创公司吗？是的。凌晨2点有一个疯狂的主意吗？让我们来做！ 这就是大多数AI模型现在的感觉。超级聪明，超级乐于助人。但也太愉快了。 询问llm的任何东西，它将尝试说是的。即使是含义：弥补事实，同意有缺陷的逻辑，在应该说“我不知道”时产生某些内容。 有时，这种盲目的积极性不是智慧。这是幻觉的根源。 ，事实是我们不仅需要更聪明的AI。我们需要更多诚实的人工智能。 AI说不。向后推的AI。问“确定吗？”的AI  那是真正的智能开始的地方。不是对所有事物都说“是”，而是知道什么时候不。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/prajwal_gote    href =“ https://www.reddit.com/r/artcoverinteligence/comments/1m8y88w/llm_agrees_to_to_to_to_to_to_towhatewhate_i_say/”&gt; [link]    ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m8y88w/llm_agrees_to_whatever_i_say/</guid>
      <pubDate>Fri, 25 Jul 2025 12:47:02 GMT</pubDate>
    </item>
    </channel>
</rss>