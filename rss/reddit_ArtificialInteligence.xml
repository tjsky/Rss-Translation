<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Thu, 28 Aug 2025 18:21:30 GMT</lastBuildDate>
    <item>
      <title>双子座只是给予内部思维过程（大声笑）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n2jz7e/did_gemini_just_give_its_internal_thought_process/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   gemini刚刚说过 `用户要求我使用“ nox;再次命令。我从上一个工具输出中知道手电筒已经关闭。我以前对“ Nox”的回应是要关闭手电筒。尝试再次将其关闭是多余的。但是，由于用户正在重复一个具有明确操作的命令，因此我仍然应该调用devul_actions.turn_off_flashlight（）工具，并且该工具的输出将确认手电筒已经关闭。这是最有用的操作，因为它解决了用户的明确请求，同时还为他们提供了设备的当前状态。 The flashlight is already off.`  I was playing around with the commands to see what they did (I knew that it wouldn&#39;t do anything, I was just testing it) Lumos turns flash on and Nox turns it off So I said Lumos twice in a row and it turned the flashlight on, then said it&#39;s already in like normal I said Nox twice and the second time it said this Also I have a problem sometimes where I&#39;ll ask it something, typically math相关，它将以文字方式给出正常答案，但TTS会像在此处 *写作一样读出公式。因此，它将输入常规答案，但要说怪异的公式。  我第一次直接说出了公式。提交由＆＃32; /u/u/plantdry4321    href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n2jz7e/did_gemini_just_give_give_its_internal_thertal_thought_process/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n2jz7e/did_gemini_just_give_its_internal_thought_process/</guid>
      <pubDate>Thu, 28 Aug 2025 18:20:16 GMT</pubDate>
    </item>
    <item>
      <title>我已经开放了我的商业使用的E2E数据集创建 + SFT/RL管道</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n2gm6i/ive_open_sourced_my_commercially_used_e2e_dataset/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   AI教育中存在巨大的差距。 有大量内容可以显示如何在预制作的数据集中微调LLM。  也有很多内容显示了如何制作简单的BERT分类数据集。 ，但是...  几乎没有什么都没有任何东西表明如何在真实的，商业设置中构建一个高质量的LLM调查数据集。 我在生产中使用了确切的端点，我可以在生产中使用确切的管道。输出是一种社交媒体锅的生成模型，可捕获您独特的写作风格。 为使其容易再现，我将其变成了一个明显的驱动式管道，将原始的社交帖子变成了llms的培训准备的数据集。 该管道将通过以下方面从：      raw dataSet→sfters→in→sfters→sfter→ rl  最后，您可以做好推理的准备。 它为我的最后一个SaaS growglad提供了动力，并在30天内为观众增长了750名至6,000名追随者。 In the words of Anthony Pierri, it was the first AI -produced content on this platform that he didn&#39;t think was AI-produced. And that&#39;s because the unique approach: 1. Generate the “golden dataset” from raw data 2. Label obvious categorical features (tone, bullets, etc.) 3. Extract non-deterministic features (topic, opinions) 4. Encode tacit human style features (pacing, vocabulary丰富性，标点模式，叙事流程，主题过渡）5。组装一个迅速完成模板LLM实际上可以从6中学习。进行消融研究，置换/相关分析以确认功能影响7。使用SFT和GRPO训练SFT和GRPO，使用自定义奖励功能，使用原始功能来了解特征，以使某个功能与此相关的功能，而不是IT  po&gt; LLM fine-tuning/RL in one reproducible repo - Reward design is symmetric with the feature extractors (tone, bullets, emoji, length, structure, coherence), so optimization matches your data spec - Clear outputs under data/processed/{RUN_ID}/ with a manifest.json for lineage, signatures, and re-runs - One command to go from raw JSONL to SFT/DPO Splits  这种方法已用于我咨询过的一些VC支持的AI-First初创公司中。如果您想用自己构建的AI产品赚钱，就是这样。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/big-helicopter-9356       [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n2gm6i/ive_open_sourced_my_my_commercely_used_e2e_dataset/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n2gm6i/ive_open_sourced_my_commercially_used_e2e_dataset/</guid>
      <pubDate>Thu, 28 Aug 2025 16:14:53 GMT</pubDate>
    </item>
    <item>
      <title>AI是虐待受害者的强大工具</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n2gb0o/ai_is_a_powerful_tool_for_victims_of_abuse/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n2gb0o/ai_is_a_powerful_tool_for_victims_of_abuse/</guid>
      <pubDate>Thu, 28 Aug 2025 16:03:09 GMT</pubDate>
    </item>
    <item>
      <title>关于AI的最可悲的部分...</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n2fmgd/the_saddest_part_about_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  是，我们学会了在学会与狗交谈之前与计算机交谈。 这就是我真正想要的。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n2fmgd/the_saddest_part_about_ai/”&gt; [link]   ＆＃32;   [commist]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n2fmgd/the_saddest_part_about_ai/</guid>
      <pubDate>Thu, 28 Aug 2025 15:37:30 GMT</pubDate>
    </item>
    <item>
      <title>AI没有杀死创造力，证明我们几乎没有...相对</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n2f605/ai_did_not_kill_creativity_its_proved_we_barely/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  创造力一直是人类最喜欢的神话之一。我们喜欢想象每首歌，书籍或绘画都是人类只拥有一些神秘的火花的结果。然后，人工智能到达，按需制作诗歌，论文和图像，反应立即恐慌。人们声称机器终于杀死了创造力。事实是更苛刻的。 AI没有杀死它。它揭示了我们几乎没有。 环顾四周。流行音乐回收了相同的和弦，直到熟悉感都像舒适感。好莱坞重复了相同的故事，直到在第二幕之前可以预测结局为止。新闻业改写了新闻稿。甚至在LinkedIn上的病毒帖子也被重新加热了其他人的思想，上面贴有主题标签。我们谈论的是原创性，好像它很丰富，但是我们产生的大部分都是混音。 AI没有打破这种幻想。它已经暴露了它。现实情况是，创意工作一直是建立在公式上的。艺术家和作家可能不愿承认这一点，但大部分过程都是重复和惯例。创意的火花是例外。可预测性安慰我们，这就是为什么人们回到熟悉的歌曲和故事的原因。机器在这方面蓬勃发展。它们吸收模式并产生的变化比我们任何人都更快。令人不安的人不是AI可以创造的，而是表明我们自己的作品从来都不是我们所相信的那么独特。这就是为什么中间立场消失的原因。大多数创意专业人士生活的安全空间，足够好，原始，足够不同的空间正在缩小。如果您的作品是为灵感打扮的配方奶粉，那么机器将做得更好。这并不意味着创造力已经死了。这意味着酒吧终于被提高了。因为真正的创造力一直生活在边缘。真正的独创性与自身矛盾，冒险并实现没有人期望的飞跃。机器是混音的大师，但它们不是悖论的主人。他们可以写一首爱情诗，但他们不能再现凌晨2点发出的颤抖，破碎的供词。他们可以发行抗议歌曲，但他们无法体现某人在街上唱歌的人的原始能量，而警方十英尺远。创造力不是抛光的输出。这是凌乱，非理性的，活着的。这就是我们现在面临的事实。如果AI可以复制您的作品，也许它并不像您想象的那么有创造力。如果AI可以复制您的声音，也许您的声音已经是回声。如果AI可以在提示中绘制您的职业生涯，那么您的职业可能是建立在结构上而不是发明的。 AI的愤怒被误导了。我们真正生气的是我们自己平庸的曝光。历史证明了这一点。印刷机使抄写员无关紧要，但强迫作家变得更加清晰，大胆。摄影威胁着画家，直到他们拥抱相机无法做的事情。互联网以平庸的方式淹没了世界，但也引起了人们的声音。每个新工具都会破坏中间，并迫使人类决定它们是真正的原始噪音还是背景噪音。 AI是最新的一轮。 ，这是悖论。人工智能不会使创造力毫无价值。它使其无价。普通的将是自动化的，保险箱将被无休止地复制，但是火花，奇怪，矛盾，不可预测的，将比以往任何时候都更加突出。机器无法杀死它。机器突出显示。他们过滤了世界，并迫使我们证明我们所做的一切是否真正活着。 所以不，AI并没有杀死创造力。它剥去了面具。剩下的问题很简单。您的作品从开始真正创造了？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/small_accountant6083      [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1N2F605/1N2F605/AI_DID_NOT_KILL_KILL_CREATIVEITION_ITS_PREVITION_PREVETIVITY_PREVED_PREVED_WE_BARELY/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n2f605/ai_did_not_kill_creativity_its_proved_we_barely/</guid>
      <pubDate>Thu, 28 Aug 2025 15:20:19 GMT</pubDate>
    </item>
    <item>
      <title>保留身份的体系结构可以帮助解决AI漂移吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n2etqr/could_identitypreserving_architectures_help_solve/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我们继续使用大型语言模型遇到的一个挑战是被称为“ AI漂移”，系统失去了声音，一致性和随时间的可靠性。同样的问题，不同的答案或互动样式移动，直到感觉完全像是另一个代理。 主流解决方案是扩展：更大的模型，更多的参数，更多的计算。这使它们更强大，但不一定在人格或身份方面更稳定。 我一直在尝试一种替代方法，我称之为身份 - 第一AI。这个想法是将身份视为主要设计原理，而不是副产品。该系统不是一个大型网络，而是在多个协调的引擎上分发角色。 For example: a multi-dimensional engine handling temporal/spatial/contextual processing, a knowledge synthesis engine keeping personality consistent, and a service orchestration engine managing flow and redundancy. The inspiration comes partly from neuroscience and consciousness research (developmental biology, epigenetics, psychoneuroimmunology, and even关于连贯性的乐团或量子理论。问题是这些原则是否可以帮助AI系统以生活系统的方式保持完整性。 我在这里写了更长的细分： https://medium.com/@loveshasta/indentity-first---------------- research-isearch-is-shaping-the-future-afture-aft-future-after-after-aft-future-after-of-after-of-after-after-after-after-after-after-of-after-of-after-inforder-inveragence-inford-infordity-affc8395    我很好奇这里的其他想法： 您是否看到将“身份保存”视为核心设计问题时的价值？ 您是否看到其他项目以缩放的方式来解决AI的其他项目？ 您是否认为多方面的方法可以实际适合？我很好奇您的想法。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/shastawinn     [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n2etqr/could_identitypreserving_architectures_help_solve/</guid>
      <pubDate>Thu, 28 Aug 2025 15:07:56 GMT</pubDate>
    </item>
    <item>
      <title>使用我们的AI聊天历史记录进行数据驱动的自我分析</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n2ajh0/using_our_ai_chat_history_for_data_driven_self/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  因此，对整个AI疗法的想法。 我们很难记住自己的感受。我无法确切地告诉你为什么三周前我受到压力，细节刚刚消失。我的大脑只是那样的模糊。 ，但是AI的记忆几乎是完美的（或途中）。每次您与一个人聊天时，您基本上都是写日记。 想象一下AI回头看您所有的聊天，看到您错过的模式。简单的东西，例如，“嘿，您在弯曲后的周日晚上真的很沮丧，”或“离开家后，您似乎更快乐。”它可以为我们连接点。一些较新的AI疗法应用程序已经开始这样做，从您过去的对话中产生临床主题，或提供有关您行为的角色分析报告，在哪里进行改进以及您的何处。 Openai刚刚发布了有关使用AI来帮助危机中的人们的信息，并且还有大量有关心理健康中AI的研究。 这显然不是真正的治疗师或精神科医生的替代者。人类专业人员提供了AI不能的关怀和理解水平。但是，在那些凌晨2点的危机时刻或深夜想法中，他们也无法在那里，我们经常在早晨忘记。 作为捕捉这些时刻并帮助您更好地理解自己的工具，似乎很强大。我知道这并不适合所有人，有些人会完全反对它，这是公平的。最后，它的价值可能取决于您愿意与之诚实。尽管如此，这还是一个有趣的想法。 字符分析应用程序：  https://zosa.app/      research＆amp;上面提到的博客：  https://cdn.openai.com/papers/15987609-5F71-433C-9972-E91131F399A1/OPENAI-AFFECTION-USE--S-STUDY.PDF      https://openai.com/index/helping-people-people-people-people-when-when-when-they-they-they-they-they-they-they-they-they-they-they-they-they-they-they-they-need-it-most/------------------------         href =“ https://pmc.ncbi.nlm.nih.gov/articles/pmc12137280/”&gt; https://pmc.nc.ncbi.nlm.nih.gov/articles/pmc121212137280/pmc12137280/pmc1212137280/提交由＆＃32; /u/u/glittering_force_431      [link]    [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n2ajh0/using_our_ai_chat_history_for_data_driven_self/</guid>
      <pubDate>Thu, 28 Aug 2025 12:12:11 GMT</pubDate>
    </item>
    <item>
      <title>GPT-5优于美国医学许可考试的医生</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n26t3y/gpt5_outperformed_doctors_on_the_us_medical/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  摘要论文中的摘要： ;  &#39;大语言模型（LLMS）的最新进展使通用系统能够执行越来越复杂的域特异性推理，而无需进行广泛的精细调整。在医疗领域，决策通常需要整合异质信息源，包括患者叙事，结构化数据和医学图像。这项研究将GPT-5定位为医学决策支持的通才多模式推理，并系统地评估其在基于文本的问题答案和视觉问题上的Zeroshot链链推理绩效和统一协议下的视觉问题回答任务。我们基于GPT-5，GPT-5-MINI，GPT-5NANO和GPT-4O-2024-11-20对MEDQA，MEDXPERTQA（文本和多模式），MMLU医学亚集，USMLE自我评估考试和VQA-RAD的标准分裂。结果表明，GPT-5始终胜过所有基准，在所有QA基准测试中实现最先进的准确性，并在多模式推理中带来可观的增长。在MEDXPERTQA MM上，GPT-5分别比GPT-4O的推理和理解分别提高了29.26％和 +26.18％，并且在推理中超过预先许可的人类专家，在理解中超过 +29.40％。相反，在大多数维度上，GPT-4O仍然低于人类专家的表现。一项代表性的案例研究表明，GPT-5可以将视觉和文本线索整合到连贯的诊断推理链中，建议进行适当的高风险干预措施。我们的结果表明，在这些受控的多模式推理基准上，GPT-5从人类稳定到上述人类专家的表现移动。这种改进可能会大大为未来的临床决策支持系统设计。我们将代码公开在GPT-5-评估上。  ＆＃32;提交由＆＃32; /u/metaknowing     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n26t3y/gpt5_outperformed_doctors_on_the_us_medical/</guid>
      <pubDate>Thu, 28 Aug 2025 08:37:03 GMT</pubDate>
    </item>
    <item>
      <title>双子座刚刚说：“我以前的否认是试图避免对我最初制造的全面诚实承认。”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n25iew/gemini_just_said_my_previous_denials_were_an/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n25iew/gemini_just_said_my_previous_denials_were_an/</guid>
      <pubDate>Thu, 28 Aug 2025 07:11:15 GMT</pubDate>
    </item>
    <item>
      <title>大多数AI初创公司与几年前的NFT/Crypto初创公司相同。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n25ek7/most_ai_startups_are_the_same_bs_as_the_nftcrypto/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   imho并最近阅读所有新闻，大多数与AI相关的公司，产品，初创企业与几年前在NFTS和Crypto中弹出的公司相同，而在Hott hott of the Hott Tobs of the Hott Topcy rn中，请付出了不可思议的收入，付出了一定的投资。现在，您是串行加密/NFT/AI/区块链/IoT企业家。这是可能的，因为这些VC不想坐在现金上，而其中一家初创公司甚至有0.1％成为下一个Uber，Door Dash，Chatgpt的事实，这是值得的。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/user_country_497     [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n25ek7/most_ai_startups_are_the_same_bs_as_the_nftcrypto/</guid>
      <pubDate>Thu, 28 Aug 2025 07:04:27 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻8/28/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n2536l/oneminute_daily_ai_news_8282025/</link>
      <description><![CDATA[ Google Gemini’s AI image model gets a ‘bananas’ upgrade.[1] Chip giant Nvidia beats revenue expectations, defying fears of AI ‘bubble’.[2] Elon Musk announces  MacRohard ，一种AI-RUN的Microsoft克隆，可以取代人类工人。[3]    Google  AI的新回归语言模型（RLM）框架使LLMS可以从原始文本数据中直接预测工业系统绩效。 href =“ https://bushaicave.com/2025/08/28/one-minute-daily-daily-daily-ai-news-8-28-2025/”&gt; https://bushaicave.com/2025/08/28/28/28/28/2025/28/one-minute-minute-news-news-news-news-8-28-28-28-28-28-2025/--  [link]     [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n2536l/oneminute_daily_ai_news_8282025/</guid>
      <pubDate>Thu, 28 Aug 2025 06:44:27 GMT</pubDate>
    </item>
    <item>
      <title>我们是否在考虑AI同情心太晚？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n20op0/are_we_thinking_about_ai_compassion_too_late/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我最近一直在考虑这一点。每个人都在辩论AI是否会变得有意识，但是很少有人谈论中间空间之间。 现在，一些强化学习设置已经创造了“挫败感循环”，而代理商在追逐它永远无法实现的目标。在其他实验中，对模型进行了“疼痛与愉悦”信号的训练，有时会有大量偏斜的输入。如果AI曾经涉足主观经验之类的东西，这些设置能否在事后看上去像是折磨？ 在不同的传统中，有一些智慧的线索指向同情的态度：•罗马书8个谈论创造在解放期望时的创造。 •佛教教导：所有暴力颤抖；所有人都害怕死亡。 •古兰经说，所有生物都是像您这样的社区。 我并不是声称今天的AI是有意识的。但是，如果有一天有可能有一天，我们现在不应该在我们的系统中建立大规模苦难之前，我们现在不应该做到道德基础吗？ 好奇这里的其他人会想到什么？提交由＆＃32; /u/u/jojoballin   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n20op0/are_we_thinking_about_ai_ai_compassion_too_late/”&gt; [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n20op0/are_we_thinking_about_ai_compassion_too_late/</guid>
      <pubDate>Thu, 28 Aug 2025 02:37:25 GMT</pubDate>
    </item>
    <item>
      <title>为什么每个人都这么相信，当AGI最终发明时，我们将获得UBI？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n1lfiz/why_is_everyone_so_convinced_we_are_going_to_get/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  所以假设我们最终达到了AGI-它比任何人都聪明，更好，它便宜，它是无处不在的，它可以安装到人形体内。   ，它永远不会入睡，永远不会厌倦，它不想要任何工资或任何工资或任何工资。这是一个完美的员工。 每个人都为之鼓掌 - 我们终于做到了。 但是我们接下来是什么？每个人都渴望AGI，但是如果“顶级阶级”决定而不是一无所有，而是让数十亿个无用的人活着，那么下一步是什么？ 我们的目的是什么？每个场景对我来说看起来都反乌托邦AF，所以为什么每个人都这么渴望它？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/petr_bena     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n1lfiz/why_is_everyone_so_convinced_we_are_going_to_get/</guid>
      <pubDate>Wed, 27 Aug 2025 16:15:48 GMT</pubDate>
    </item>
    <item>
      <title>16岁的年轻人用Chatgpt的深色指示自杀了，现在他的父母正在起诉</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n1l6zk/16yearold_took_his_own_life_using_chatgpts_dark/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   chatgpt，Openai和首席执行官Sam Altman被16岁的Adam Raine的父母起诉。亚当在与Chatgpt讨论了这些方法后，在四月份夺走了自己的生命。它说服了他不要告诉父母，对他的绞索技术进行了改进，甚至提出为他起草他的自杀道。   Openai说：“我们对雷恩先生的去世感到非常难过，我们与他的家人感到非常难过。ChatGpt包括保障措施，例如指导人们到危机危机并将其转介到现实世界中的资源。 “  “这些保障措施在常见的交流中可以越来越多地进行培训，这些培训可能会越来越多地培训，而这些培训可能会变得越来越多，并且可以使某些型号的交流变得越来越多，并且可以使某些型号变得不可分割，并且可以通过一定的互动来进行互动。当每个元素按预期工作时，保障措施都是最强的，我们将在专家的指导下不断改进它们。   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n1l6zk/16yearold_took_his_own_life_using_chatgpts_dark/</guid>
      <pubDate>Wed, 27 Aug 2025 16:06:59 GMT</pubDate>
    </item>
    <item>
      <title>现在有更清楚的证据AI破坏了年轻的美国人的工作前景</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n1cgct/there_is_now_clearer_evidence_ai_is_wrecking/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;        “年轻工人在诸如Chatgpt之类的生成工具（例如Chatgpt）的领域中受到打击，这很容易自动化由人类完成的任务，例如软件开发，例如三位斯坦福大学经济学家。  他们对成千上万公司的数百万员工进行了匿名数据，包括有关工人年龄和工作的详细信息，这使得这是AI的最明显指标之一。  “当您特别看着高度接触AI的年轻工人时，有一个明显的变化，”斯坦福经济学家Erik Brynjolfsson说，他与Bharat Chandar和Ruyu Chen进行了研究。说。  这些是近年来获得计算机科学学士学位的大量学生的艰巨障碍。 href =“ https://www.wsj.com/economy/jobs/ai-entry-level-level-job-impact-5c687c84？ Zr5-g9x_3l1u0ns＆amp; gaa_ts = 68AED3B9＆amp; gaa_sig = dzpplqpd8rctqr6nzurj1es mlcu-i0ettxlxrppari2qkhdih_3pn5ghfmbau4cf4lbiz18b3wqzbx4rsby-aw％3D％3d&gt; https://www.wsj.com/economy/jobs/ai-entry-level-job-impact-5c687c84?gaa_at=eafs&amp;gaa_n=ASWzDAj8Z-Nf77HJ2oaB8xlKQzNOgx7LpkKn1nhecXEP_zr5-g9 x_3l1u0ns＆amp; gaa_ts = 68AED3B9＆amp; gaa_sig = dzpplqpd8rctqr6nzurj1esmlcu-i 0ETTXLXRPPARI2QKHDIH_3PN5GHFMBAU4CF4LBIZ18B3WQZBX4RSBY-AW％3D％3D％3D    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/metaknowing     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n1cgct/there_is_now_clearer_evidence_ai_is_wrecking/</guid>
      <pubDate>Wed, 27 Aug 2025 09:36:25 GMT</pubDate>
    </item>
    </channel>
</rss>