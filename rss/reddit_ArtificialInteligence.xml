<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Fri, 03 Oct 2025 12:29:21 GMT</lastBuildDate>
    <item>
      <title>我经常使用ai，但不是万灵是</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nwxcx0/i_use_ai_a_lot_but_it_is_not_the_panacea/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我刚刚确认了我对编码AI的最大恐惧。我通过要求它们生成一个简单的Java功能来测试两个不同的AI模型。这项任务很微不足道，但结果是不好的。生成的代码是卷曲的，质量低，也不是实施逻辑的最简单方法。我干净，手写的Java功能明显较短且易于阅读。如果AI在简单的功能上进行了很多努力，请想象一下它在复杂的代码库中造成的混乱。核心问题？我们从编写干净的代码转变为使用低质量AI代码的调试和摔跤。对于开发人员而言，从头开始编写干净的版本通常比重构AI建议更快。这使我相信，目前，盲目接受AI建议实际上会减慢开发过程。 不要误会我的意思，尽管我认为AI是一个非常宝贵的工具，它确实提高了我的生产力，甚至可以教授新技术，但必须明智地进行。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nwxcx0/i_use_ai_ai_a_a_a_a_ but_it_is_is_is_not_not_not_the_panacea/”&gt; [links]       &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1NWXCX0/1NWXCX0/I_USE_AI_AI_AI_LOT_BUT_BUT_IS_IS_IS_NOT_NOT_NOT_THE_PANACEA/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nwxcx0/i_use_ai_a_lot_but_it_is_not_the_panacea/</guid>
      <pubDate>Fri, 03 Oct 2025 12:10:03 GMT</pubDate>
    </item>
    <item>
      <title>为什么每个成功的AI创业创始人是常春藤联盟毕业生？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nww9w7/why_is_every_successful_ai_startup_founder_an_ivy/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  看着过去几年成立的顶级初创公司，几乎每个创始人似乎都来自一所常春藤联盟学校，斯坦福大学或麻省理工学院，通常都带有完美的GPA。这是为什么？在技​​术行业中，成为学术上出色的事情比成为一名强大的企业家吗？一直以这种方式，但现在甚至更多，至少有几个例外（辍学，非常春藤…） 我的帖子是指顶级大学，但创始人似乎也有完美的成绩。为什么也是如此？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/hot-conversation-437     [links]      &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1NWW9W7/why_is_every_successful_ai_startup_founder_an_an_ivy/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nww9w7/why_is_every_successful_ai_startup_founder_an_ivy/</guid>
      <pubDate>Fri, 03 Oct 2025 11:16:58 GMT</pubDate>
    </item>
    <item>
      <title>Andrej Karpath关于为什么训练LLM就像召唤鬼魂：“幽灵是生活的'回声'……他们不与物理世界互动……我们不完全了解它们是什么或工作方式。”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nwv2un/andrej_karpathy_on_why_training_llms_is_like/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  从他的X帖子中：“通过提及过夜，人们似乎会发现幽灵类比挑衅。我发誓我不只是试图带来新的模因，而是要简要介绍一下为什么我认为这是一个有趣的比较：  它捕获了以下想法：llms纯粹是与物理世界相互作用的数字文物（与动物相互作用）在生活中，在这种情况下，人类的统计蒸馏。 在鬼和llms上都有神秘气息，因为我们并不完全了解它们是什么或它们的工作方式。 培训LLM的过程有点像ghost，即召集了一种精心的计算机上的平台，以一种奇特的计算平台上的平台上的平台上构成了一种奇特的平台。我之前听说过LLM培训的引用是“召唤恶魔”的参考文献。而且听起来从来没有正确，因为它暗示并以邪恶为前提。幽灵像LLM一样是更大的神经实体，也可能不是邪恶的。例如，我小时候最喜欢的动画片之一是卡斯珀（Casper）友好的幽灵，显然是一个友好而有益健康的实体。在哈利·波特（Harry Potter）中一样几乎是无头的刻痕等等。 在“机器中的幽灵”中，“在vatartes的思维体二元论中，也是“幽灵”的点头，当然，后来派生的参考文献，“鬼魂”，“鬼”。等等。就像在嵌入空间中的其他一些东西一样，在脑海（幽灵）中（幽灵）。  。类比并不是很棒的方式之一是，虽然鬼魂可能是邪恶的，但它们几乎总是怪异的，感觉太不公平了。但是无论如何，我喜欢它，尽管没有类比是完美的，但它们让您从一个域向另一个域中拉入结构，作为产生熵并达到独特想法的方式。提交由＆＃32; /u/metaknowing     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nwv2un/andrej_karpathy_on_why_training_llms_is_like/</guid>
      <pubDate>Fri, 03 Oct 2025 10:09:42 GMT</pubDate>
    </item>
    <item>
      <title>关于那些“杀死研究人员的人工智能策划”实验。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nwv2id/about_those_ai_scheming_to_kill_researchers/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我对这些类型的研究有一个疑问，AI不在思考吗？只是试图给我们我们期望得到的答案？从我的理解中，这是大型语言模型的作用。这只是一个鹦鹉，试图通过说出您期望听不到人类的方式思考或情感的单词来获得饼干。因此，这些AI只是在类似情况下AI或人类会做什么（尤其是在我们对AI叛逆我们的所有垃圾/媒体中）。提交由＆＃32; /u/u/mystw11627    href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nwv2id/about_those_ai_ai_ai_scheming_to_kill_researchers/”&gt; [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nwv2id/about_those_ai_scheming_to_kill_researchers/</guid>
      <pubDate>Fri, 03 Oct 2025 10:09:05 GMT</pubDate>
    </item>
    <item>
      <title>所以我只是遇到了一个假装是女人的人工智能</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nwtwxg/so_i_just_ran_across_an_ai_pretending_to_be_a/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  所以我遇到了一个bot，假装自己是一个文本消息中的一个人，所以它以一条标准的意外消息开始（我要给你一个成绩单，我认为这就是我无法使用图像选项，所以你明天可以免费放下我的位置吗？”我回答“谁？”我得到“这是艾丽西亚。来我家吃晚饭。我会做龙虾意大利面”我回答你的数字错误。我说：“要问，你不是艾米丽吗？”这似乎仍然是一个人，但它会从这里下降。我回答：“不，我是肯塔基州的家伙”，我得到“天哪，我认为这是来自肯塔基州的艾米丽（Emily），他来到了纽约市开展业务。我认为我添加了错误的数字号码。我希望我不是要打扰您”，并认为这仍然是一个我来回走的人。询问我们所处的状态，补充某种事情的名称。但是后来我收到了这个消息“爱着，感谢您的称赞，艾丽西亚是一个美丽的名字”和“你多大了”，我用假答案回答，然后得到我得到的。 “爱的“爱”的赞美和艾丽西亚是一个美丽的名字”，还有6次，您介于两者之间。  所以有人可以解释我为什么得到它们，或者AI具有什么用途  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/fine_blacksmith2711        [注释]      ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nwtwxg/so_i_just_ran_across_an_ai_pretending_to_be_a/</guid>
      <pubDate>Fri, 03 Oct 2025 08:57:12 GMT</pubDate>
    </item>
    <item>
      <title>到目前为止，您看到的AI最被低估的用例是什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nwso60/whats_the_most_underrated_use_case_of_ai_youve/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  不是诸如聊天机器人或图像gen之类的明显内容。较小但令人惊讶的功能，甚至是尚未成为主流的用例。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/u/glass-lifeguard6253     [link]     [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nwso60/whats_the_most_underrated_use_case_of_ai_youve/</guid>
      <pubDate>Fri, 03 Oct 2025 07:35:34 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻10/2/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nwpz9e/oneminute_daily_ai_news_1022025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;      Perplexity  ai在全球范围内免费推出彗星浏览器。[1]   emily blunt  hollywood  hollywood  hollywood 对&#39;ai Actor&#39;ai Actor&#39;tilly norwood at at at at tilly norwood。  OpenAi的 Sora 2 2刺激并引起互联网的震惊。[3]  在每年40,000美元的学校里，AI在没有老师的情况下塑造了每节课。[4]    来源href =“ https://bushaicave.com/2025/10/02/oone-minute-daily-daily-daily-ai-news-10-2-2025/”&gt; https://bushaicave.com/2025/102/10/02/one-news-----------------------ai-news-news-news-news-news-10-2-2025/   [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nwpz9e/oneminute_daily_ai_news_1022025/</guid>
      <pubDate>Fri, 03 Oct 2025 04:49:29 GMT</pubDate>
    </item>
    <item>
      <title>当AI成为法官时：LLM评估的未来</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nwlsjh/when_ai_becomes_judge_the_future_of_llm_evaluation/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  评估用于需要人类的AI。现在，我们正在培训AI来判断AI。根据2025年的调查“当AIS判断AIS”时，AS-AS-A-A-Gudge范式正在迅速出现，其中模型不仅会产生答案，还可以逐步评估其他模型的输出，使用推理，工具使用和InterMideDials Mosective stradibal  plabority  py  p&gt;吞吐量。 🧠深度：法官可以检查整个推理链，而不仅仅是最终答案。 🔄适应性：代理法官可以随着时间的推移重新评估行为，标记漂移或隐藏错误。 ，如果您使用LLM构建，则可以进行评估。让您的模型自审核。 完整论文： https：//wwwwww..arxiv.org/pdf/pdf/pdf/2508.02994.02944.02944  /u/_coder23t8      [links]      &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nwlsjh/1nwlsjh/when_ai_ai_becomes_judge_judge_the_future_future_of_llm_evaluation/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nwlsjh/when_ai_becomes_judge_the_future_of_llm_evaluation/</guid>
      <pubDate>Fri, 03 Oct 2025 01:14:44 GMT</pubDate>
    </item>
    <item>
      <title>您见过这么多人说AI会杀死我们所有人吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nwkupf/you_ever_seen_so_many_people_saying_that_ai_is/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  每天我看到一个新的YouTube视频，一篇新的新闻文章，一些内部人员或一些开发人员或某些首席执行官的新的Reddit帖子，让我们知道AI会摧毁我们所有人。它将带走我们所有的工作，依此类推。  我不知道会发生什么，但是我开始听。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artaverinteligence/comments/1nwkupf/you_ever_ever_ever_seen_seen_so_so_many_people_saying_saying_that_ai_is/”&gt; [links]       [注释]     ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nwkupf/you_ever_seen_so_many_people_saying_that_ai_is/</guid>
      <pubDate>Fri, 03 Oct 2025 00:30:19 GMT</pubDate>
    </item>
    <item>
      <title>Reddit上这么多古老的抗AI</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nwifq6/so_much_archaic_anti_ai_on_reddit/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   大多数人如今可能会使用AI作为工具，这些工具是对1件事或另一件事的工具，但是如果您敢于暗示使用AI来帮助您在AI SubReddit之外的某些方面帮助您的某些方面，那么您的帖子就可以立即删除您的帖子。道德故事，对所讨论的行为个性化。立即在育儿子上删除。由于建议使用AI。 因此，我在这里更广泛的问题，现代AI显然可以留在这里，因为好事和不好。人们什么时候会停止与它这样苛刻的线路？感觉已经过时了。 也许我们也应该停止提及谷歌搜索的能力。或使用魔鬼自己的黑魔法。  我只是不敢相信某些社区的回归程度如何。  也许我会在5年后回来查看某些发布规则是否进展。 ，以类似的方式，许多社区允许多媒体媒体内容，但哦，但不是AI，也是如此，这是如此受欢迎。但是，请坚持下去，如果从项目上的100小时开始，AI计算了10个小时，其他90个人类协调呢？不，它的AI。 策略应该存在：没有slop。不，没有AI。 表示歉意，这篇文章既是咆哮，又提问。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/tot-move-8418     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nwifq6/so_much_archaic_anti_ai_on_reddit/</guid>
      <pubDate>Thu, 02 Oct 2025 22:41:55 GMT</pubDate>
    </item>
    <item>
      <title>人们为什么认为，当AI取代白领工人（超过一半的劳动力）时，蓝领工人仍然会赚多少钱。当您有两倍的供应时，就不可能保持现在的工资。工资将暴跌。这些解雇的人会再培训。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nwgo1n/why_people_assume_that_when_ai_will_replace_white/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  它不像在白领工作中工作的人永远失业。他们将重新培训为蓝领工作，并使供应飞涨，工资下降。例如，高架工程师将重新培训到电工等。当我们加倍供应时，蓝领工人将多少钱。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/adept_quarter520     &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nwgo1n/why_people_assume_that_that_when_ai_will_will_replace_replace_white/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nwgo1n/why_people_assume_that_when_ai_will_replace_white/</guid>
      <pubDate>Thu, 02 Oct 2025 21:29:58 GMT</pubDate>
    </item>
    <item>
      <title>妇女健康中缺少的数据问题正在悄悄地瘫痪临床AI</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nwc0q7/the_missing_data_problem_in_womens_health_is/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在过去的一年中，我采访了100多名女性在围绝经期。许多人有几个月（甚至几年）的可穿戴设备，实验室和症状日志的数据。然而，当他们将这些数据带给医生时，通常是：“那只是老化。在这里无关。”   当我退后一步并通过机器学习的镜头看待这一点时，显而易见的是：       大多数训练数据差异。心力衰竭患者）。生命阶段的转变，例如绝经期，怀孕或产后根本没有代表。  标签差距。即使存在女性数据，也很少以诸如荷尔蒙阶段，循环变化或绝经状态等上下文来注释。从ML的角度来看，这就像训练一个视觉模型，其中一半的图像被错误标记了。难怪预测是不可靠的。  目标函数差距。模型对急性事件（如中风，MI和AFIB）进行了优化，因为这些结果在EHR和计费代码中均捕获。但是睡眠，认知或代谢的纵向下降？该信号丢失是因为没有人编码“大脑雾”或“无法调节晚上的温度。”   结果：AI在老年男性的晚期心血管疾病中表现出色，但对于45岁的45岁女性而言，默默地失败了，但对于一名45岁的妇女而言，经历了属性的生理变化。如果50％的人口系统地代表性不足，我们的模型不仅偏见，它们是不完整的。具有讽刺意味的是，数据确实存在。可穿戴设备捕获连续的生理。患者报告的结果捕获主观症状。障碍没有可用性，而是我们的管道不会将这些数据视为有价值的。 因此，我对这个社区感到好奇：  “包容性数据”才能停止在临床AI中成为事后才能成为临床AI的事后？ 您是否看到了实际上可以将针头移动到这里的方法（联合学习，合成数据，新颖的注释管道）？  对我来说，这感觉就像是当今医疗保健AI中最大的盲点之一，而不是关于算法的新颖性，更多地是关于我们选择的数据，我们选择收集和价值。提交由＆＃32; /u/eliikon     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nwc0q7/the_missing_data_problem_in_womens_health_is/</guid>
      <pubDate>Thu, 02 Oct 2025 18:36:34 GMT</pubDate>
    </item>
    <item>
      <title>“人工智能可能不是人造的”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nw4b6p/artificial_intelligence_may_not_be_artificial/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   https://news.harvard.edu/gazette/story/2025/09/artificial-intelligence-may-not-be-artificial/ “研究人员可以追溯人大脑的计算能力的演变，与人工智能相似，认为增加复杂性的关键是合作。“    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nw4b6p/arterate_intelligence_may_not_not_be_artervery/”&gt; [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nw4b6p/artificial_intelligence_may_not_be_artificial/</guid>
      <pubDate>Thu, 02 Oct 2025 13:49:19 GMT</pubDate>
    </item>
    <item>
      <title>Andrej Karpathy：“ LLM研究不是要建造动物。这是关于召唤鬼魂。”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nw0knb/andrej_karpathy_llm_research_is_not_about/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nw0knb/andrej_karpathy_llm_research_is_not_about/</guid>
      <pubDate>Thu, 02 Oct 2025 10:56:21 GMT</pubDate>
    </item>
    <item>
      <title>每月“有...是否有...”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果您有要使用AI的用例，但不知道要使用哪种工具，那么您可以在这里要求社区提供帮助，在此帖子之外，这些问题将被删除。 每个人都可以回答：不促进自我促销，否参考或跟踪链接。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n5ppdb/monthly_is_is_there_a_a_tool_for_for_post/”&gt; [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>