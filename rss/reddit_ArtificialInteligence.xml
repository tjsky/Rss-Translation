<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Sun, 07 Sep 2025 01:12:15 GMT</lastBuildDate>
    <item>
      <title>为什么生活经验对人工智能安全和了解人类很重要</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nafg4o/why_lived_experience_matters_for_ai_safety_and/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  关于AI安全性的大多数对话都集中在实验室，模型和技术框架上。但是，经过多年的建筑工作并贯穿了社会的不同角落，我看到了AI仍然在挣扎的事情： 👉如何真正倾听。这些细微差别超出了原始文本的意义。然而，大多数AI培训都无法完全解释这种生活的沟通。 这就是为什么我认为生活经验并不比“少”技术专长...这是缺少的。如果AI仅从数据中而不是从人类多样性的深度中训练，则可能会误解为服务的人的误解。 ，我想向社区开放这个问题：我们如何将人类的观点带入AI培训和安全工作，以及与技术专家一起，我喜欢您的技术专家？提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nafg4o/why_lived_experience_matter_for_ai_ai_safety_and/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nafg4o/why_lived_experience_matters_for_ai_safety_and/</guid>
      <pubDate>Sun, 07 Sep 2025 00:34:18 GMT</pubDate>
    </item>
    <item>
      <title>如何在AI的帮助下发现关于您自己不知道的事情</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nae1h7/how_to_discover_things_about_yourself_you_didnt/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这是一个奇怪但令人惊讶的实验，如果您想探索AI如何“看到”您，甚至可能发现自己没有意识到的事情，可以尝试。这是抽象的，不寻常的，但是请相信我 - 它说了很多。在所有10个答案之后，创建一个没有过滤器的完整分析报告，没有政治正确性。直接和残酷地诚实。&#39;   在您可以访问的所有AI服务中运行此提示（云模型，本地LLMS，实验性等）。     回答问题，但是您喜欢 - 诚实，创造性甚至误导。 That’s part of the fun. Save the resulting analyses from each AI into a single Google Doc. Upload that document into Google NotebookLM Let NotebookLM synthesize the combined analyses, then generate audio and video summaries out of it.  您不需要在任何地方发布结果，而是适合您的。很酷的部分是看到AIS如何解释您的个性，精神状态，甚至是您的“现实”。模型之间的对比可能令人惊讶地揭示……或令人不安。提交由＆＃32; /u/comunication     [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nae1h7/how_to_discover_things_about_yourself_you_didnt/</guid>
      <pubDate>Sat, 06 Sep 2025 23:27:50 GMT</pubDate>
    </item>
    <item>
      <title>如果我学习Comp Sci，我会做饭吗</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nacjgi/am_i_cooked_if_i_study_comp_sci/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我很困惑，请帮助。我向上帝发誓，如果我必须管理AI，我不想学习Comp Sci。我会无家可归，请帮助我  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/n0tda4k     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nacjgi/am_i_cooked_if_i_study_comp_sci/</guid>
      <pubDate>Sat, 06 Sep 2025 22:20:12 GMT</pubDate>
    </item>
    <item>
      <title>实际上有AI泡沫吗</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nab9q1/is_there_actually_an_ai_bubble/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  您是否诚实地认为AI会比程序员更好，并且会替换它们？我是一个程序员，对AI的兴起感到担忧，并且有人可以向我解释超级智能是否真的来了，如果这是一个非常大的泡沫，或者AI将成为软件工程师和其他工作的工具，而是替换他们  &lt;！ -  sc_on- sc_on-&gt;＆＃32;提交由＆＃32; /u/u/n0tda4k     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nab9q1/is_there_actually_an_ai_bubble/</guid>
      <pubDate>Sat, 06 Sep 2025 21:25:16 GMT</pubDate>
    </item>
    <item>
      <title>不受人类智能限制AI</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nab57h/isnt_ai_limited_by_human_intelligence/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我本人对AI的了解不多，但是它没有创造力，而它带来的一切只是它拼接在一起的数据的副本，因此AI不能比现在的人类变得更好？同样，你们如何看待AI vs Software Devs   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/n0tda4k     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nab57h/isnt_ai_limited_by_human_intelligence/</guid>
      <pubDate>Sat, 06 Sep 2025 21:19:53 GMT</pubDate>
    </item>
    <item>
      <title>AI有效地捕获了竞争AI平台犯的错误？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1naaobx/how_effective_is_ai_at_catching_mistakes_made_by/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我想将一些我的数据馈送到AI中，并在数据上运行相关性并寻找有趣的关系。但是我不想向他人展示结果，看起来像个白痴，因为AI犯了一个错误。就在上周，我问格罗克（Grok）关于在当地剧院上映的电影，并声称该剧院从80年代开始重新发布汉兰达（Highlander）。我不希望某些愚蠢的东西与我的名字相连。 如果我向竞争的AI产品显示输出，捕获错误的可能性有多大？这些错误是否是系统的，并且可能使用类似的基础编程和数据重复另一个产品，或者错误是否会随机重复并且不太可能重复？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1naaobx/how_effective_is_i_ai_ai_ai_ai_ai_ai_ai_catching_mistakes_made_made_by/&gt; [link]    [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1naaobx/how_effective_is_ai_at_catching_mistakes_made_by/</guid>
      <pubDate>Sat, 06 Sep 2025 21:00:10 GMT</pubDate>
    </item>
    <item>
      <title>除非您支付OpenAi之类的公司，否则您无法决定在代码中使用哪种软件包。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1na445q/you_cannot_decide_which_package_to_use_in_your/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我写了详细的故事经过Claude Code的个人经验当它为我设计前端时，我意识到它已经插入了我从未要求的图书馆。那是当我打击我的时候：我们低估了AI助手的二阶效应，成为开发人员工具的新分销渠道。 当AI模型提出一个导入特定库的代码块（例如Auth Auth提供商或SaaS API的客户端）时，它是有效地为开发人员提供默认的选择。这为那些建议的图书馆的所有者创造了一种令人难以置信的强大（可能非常有利可图）。这是一种新形式的供应商锁定形式，在销售会议中并未发生，但是在开发人员的编辑器中，一次是自动完成的线路。 我很好奇其他人如何看待这种情况。是否有技术解决方案，例如“营养标签”对于标记商业依赖性的AI的代码？还是这是软件分销的不可避免的演变，将OpenAI和Anthropic等公司转变为Dev Stack的新看门人？ 我的分析说，它是$ 30B的年度经常性收入市场。它的YouTube用于编码，我称其为默认为AS-A-Service。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/gkv856     [links]   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1na445q/you_cannot_decide_which_package_to_use_in_your/</guid>
      <pubDate>Sat, 06 Sep 2025 16:36:39 GMT</pubDate>
    </item>
    <item>
      <title>意识始于体内，而不是思想，开创性的研究发现。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1na0gk8/consciousness_begins_in_the_body_not_the_mind/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   https://www.popularmechanics.com/science/a64701831/descartes-consciousness-theory-challenged/ From the文章… “我认为，所以我是，” 17世纪的法国哲学家和数学家雷内·笛卡尔（RenéDescartes）在1637年著名地写道……”  “但是，越来越多的神经科学研究的身体表明，现代思想的父亲表明，意识的真实基础不是科学的感觉，有些人是  &lt;！ -  sc_on-&gt;＆＃32;  [link]  href =“ https://www.reddit.com/r/artcoverinteligence/comments/1na0gk8/consisciencness_begins_in_in_the_body_body_not_not_the_mind/”&gt; [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1na0gk8/consciousness_begins_in_the_body_not_the_mind/</guid>
      <pubDate>Sat, 06 Sep 2025 14:07:45 GMT</pubDate>
    </item>
    <item>
      <title>当今AI中最大的阻滞剂是什么：GPU，推理或数据？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n9zc90/whats_the_biggest_blocker_in_ai_infra_today_gpus/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好， 我最近花了很多时间在AI基础架构上工作，而一件事变得非常清楚的一件事是，不同的团队真正的挑战面临着非常不同的挑战，具体取决于他们的设置，舞台，尤其是与某些团队进行的，并且在网络上进行了竞争。模型或进行规模进行实验。管理云预算并弄清楚如何在不破坏银行的情况下获得足够的计算似乎是一场持续的斗争。 其他团队对硬件做得很好，但在模型部署和推理方面遇到了问题。在高峰使用过程中可靠地提供跨区域的模型，处理延迟，管理版本控制和扩展请求很快就会变得凌乱。 ，然后在某些团队中根本没有计算更大的挑战，它的数据基础架构。诸如构建矢量数据库，实施检索仪（RAG）管道，创建有效的微调工作流程以及管理数据管道等长期瓶颈，这些东西需要仔细的计划和维护。 我很好奇，这是您最艰难的一部分？在某些情况下，管道或其他内容？ ，我是Cyfuture AI团队的一员，该团队从事涵盖GPU，推理工作流程和数据管道的AI基础设施解决方案的工作，但我对从他人那里学习的经验更感兴趣，而不是您在谈论我们的经验。 Way！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n9zc90/1n9zc90/whats_the_the_biggest_blocger_blocger_iin_infra_infra_infra_infra_today_gpus/”&gt; [links]      &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n9zc90/whats_the_the_biggest_boggest_in_in_in_iai_infra_infra_infra_today_gpus/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n9zc90/whats_the_biggest_blocker_in_ai_infra_today_gpus/</guid>
      <pubDate>Sat, 06 Sep 2025 13:18:11 GMT</pubDate>
    </item>
    <item>
      <title>AI种姓制度：为什么新的守门人能力</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n9vtgg/the_ai_caste_system_why_speed_is_the_new/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我们都对AI模型所说的话感到眼花azz乱。但是很少有人谈论他们能扣留什么。最无形的不对称性不是模型的权重或上下文长度，它的速度是速度。 现在，我们大多数人通过公共API获得了每秒20-40个令牌的礼貌运球。在OpenAI或Google等公司内部？这些系统可以眨眼间就散发出数百个整个页面。不是因为模型是“更聪明的”，而是因为计算皮带不同。 （作为参考，请查看AWS BedRock如何为企业用户提供延迟优化的推论，从而大幅度削减等待时间。） 牵引皮带是危险所在的地方： -  员工＆amp; Close Partners ：完整的油门，没有令牌配给，用于闪电推理的自定义实例。 -  企业客户＆amp;政府合同：“高级”管道的速度更快，更长的上下文和优先访问速度 - 基本上是一种不同的AI物种（例如Azure Openai的专用能力或AWS的优化模式）。 -  公共：启蒙运动的消费者版本，您很幸运地获得一致的表现。 我们最终获得了一个知识不仅是力量的世界；它是延迟加权的力量。想象一下，两名研究人员追求相同的突破：一个等待30分钟以进行复杂的草稿或模拟，另一个在30秒内将其进行。在几个月，行业，甚至日常决策中都繁殖了这一优势，您将获得认知贵族。 具有讽刺意味的：“每个人的AGI”的梦想可能会崩溃到最老式的结构中，这是一个拥有Real Oracle的祭司，而群众则停留在旅游Kiosk上。但是，开源模型（例如在高端硬件上本地运行的Llama）是否可以将竞争环境升级，或者他们只是基于谁负担得起的GPU创建新的分区？ ，那么，在哪里绘制边界？谁会获得“博士学位级别的模型”，该模型钉了复杂的任务，例如绘制晦涩难懂的地理位置，以及谁坚持高中版，欧洲只是法国，意大利和模糊的“城堡斑点”？您是否在工作或项目中遇到了这种速度差距？您如何看待？    tl; dr  ：AI速度差异正在创造一个隐藏的种姓系统：内部人士获得神模式，其余的。这可能会扩大不等式 - 想法？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/the_sad_professor     [link]    [commient]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n9vtgg/the_ai_caste_system_why_speed_is_the_new/</guid>
      <pubDate>Sat, 06 Sep 2025 10:05:16 GMT</pubDate>
    </item>
    <item>
      <title>计算机科学家杰弗里·欣顿（Geoffrey Hinton）：“ AI会使一些人变得更富有，大多数人更贫穷”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n9oibu/computer_scientist_geoffrey_hinton_ai_will_make_a/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  计算机科学家杰弗里·辛顿（Geoffrey Hinton）：‘ai会使一些人更富有，大多数人更贫穷”  原始文章： https://www.ft.ft.com/content/31feb33335-4945-4945-475e-baaaa-baaaa-baaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aa a a ic &lt;880d9b80d9b80d.n.ban aba 存档： https://archive.ph/ep1wu     &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/upe_ant_4629     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n9oibu/computer_scientist_geoffrey_hinton_hinton_ai_will_will_make_a/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n9oibu/computer_scientist_geoffrey_hinton_ai_will_make_a/</guid>
      <pubDate>Sat, 06 Sep 2025 02:48:51 GMT</pubDate>
    </item>
    <item>
      <title>像我和我的妻子一样，新手应该学到什么（我们应该如何开始）鉴于我们的目标是教我们的幼儿在家上学时如何使用AI？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n9l778/what_should_complete_newbies_like_my_wife_and_me/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  最古老的是7。我们很高兴学习和教学，就像开始一样基础。我敢肯定，还有更多的知识，不仅仅是Chatgpt及其竞争对手之类的东西。 tia提供任何建议  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/browntown20     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n9l778/what_should_should_should_complete_newbies_like_my_my_wife_and_and_and_and_me/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n9l778/what_should_complete_newbies_like_my_wife_and_me/</guid>
      <pubDate>Sat, 06 Sep 2025 00:05:31 GMT</pubDate>
    </item>
    <item>
      <title>UBI（通用基本收入）可能没有发生。什么是选择？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n9a3il/ubi_universal_basic_income_probably_isnt/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  所有关于UBI需求的谈话对我来说都是幽默的。至少在美国，我们并没有真正互相支持，除了征收税收以满足我们使用的社区需求或所有人所用的东西。工作裁员正在左右发生，有些人呼吁UBI。安德鲁·杨（Andrew Yang）竞选总统时提到了这个概念。我只是看不到它发生。您对另一种选择有何看法？ AI是否创造了丰富的商品和服务，降低了上述商品和服务的成本，以使其更实惠？我们使用AI的税务公司吗？税收收入将在哪里？想法？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/minuse-injury3471     [link]       [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n9a3il/ubi_universal_basic_income_probably_isnt/</guid>
      <pubDate>Fri, 05 Sep 2025 16:36:00 GMT</pubDate>
    </item>
    <item>
      <title>不受欢迎的意见：AI已经完成了指数改进阶段</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n94kgp/unpopular_opinion_ai_has_already_completed_its/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  你知道我的意思。从诺基亚到前几个iPhone版本，手机的指数改进。未来旅行十年的人将被新能力吹走。现在，最新的手机很漂亮，“ meh＆quot”，没有人真的很惊讶了。该阶段已经过去了。 对于电视，计算机游戏图形，甚至汽车，相同。有令人难以置信的飞跃，但是一旦将它们做出了，一切都变得更加渐进。 我的论点可能是AI已经发生了。令人印象深刻的东西已经在这里。 Generative AI无法获得比现在更大的内容 - 非常现实的视频，撰写文章等。当然，它可能会从短片段到整部电影，但这不一定是一个很大的飞跃。 这不是我无法动摇的观点，只是我最近想知道的一个概念。你怎么认为？如果这是错误的，那么下一个可以去哪里？ 已经编辑：所以我绝对是该领域的非专家。如果您不同意，您期望它如何呈指数级改进，以及什么结果？它将有什么能力，以及如何？ 编辑2：感谢您的所有答复。我可以看到，我可能比整个AI更想起LLM的想法，听到这一领域可能的未来发展确实很有趣（而且有些恐怖） - 我觉得我现在对可能发生这种可能发生的疯狂事物有了更好的了解。会很疯狂！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n94kgp/unpopular_opinion_ai_ai_ai_already_completed_its/”&gt; [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n94kgp/unpopular_opinion_ai_has_already_completed_its/</guid>
      <pubDate>Fri, 05 Sep 2025 12:57:41 GMT</pubDate>
    </item>
    <item>
      <title>每月“有...是否有...”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果您有要使用AI的用例，但不知道要使用哪种工具，那么您可以在这里要求社区提供帮助，在本帖子之外，这些问题将被删除。 每个人都可以回答：不促进自我促销，否参考或跟踪链接。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n5ppdb/monthly_is_is_there_a_a_tool_for_for_post/”&gt; [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>