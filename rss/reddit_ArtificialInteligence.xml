<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Tue, 26 Aug 2025 03:38:55 GMT</lastBuildDate>
    <item>
      <title>我尝试估计不同LLM的碳影响</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n0b8st/i_tried_estimating_the_carbon_impact_of_different/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我在网上可用的数据方面尽了最大的努力。以前从未见过此事，因此我感谢有关如何改善环境模型的任何反馈。这绝对是初稿。  以下是与排行榜的链接： https://modelpilot.co/leaderboard 提交由＆＃32; /u/u/bananas8thepyjamas     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n0b8st/i_tried_estimating_the_carbon_impact_of_different/</guid>
      <pubDate>Tue, 26 Aug 2025 03:24:31 GMT</pubDate>
    </item>
    <item>
      <title>对AI的存在恐惧</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n08549/existential_dread_over_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  很容易忽略AI的预测很快就会引起灾难性的灭绝，但是当您面对事实时，即AI开发人员 /研究人员的众多研究和成群，这些研究和成群的差异使我们的灭绝机会在十年之内与75-90％的差异相比，这些人都在&lt;55-90％的范围内，都在我确实感到这种存在的恐惧。我什至该怎么办？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/innormenalAlinSect8976     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n08549/existential_dread_over_ai/</guid>
      <pubDate>Tue, 26 Aug 2025 00:56:26 GMT</pubDate>
    </item>
    <item>
      <title>导航职业停滞后毕业生</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n063ks/navigating_a_career_standstill_postgrad/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿， 我于2023年毕业于统计学学位，并且已经担任我目前的角色大约一年。我的工作主要是数据工程类型的工作（即使这不是我的正式标题）。回到本科生，我进行了AI/ML研究实习，老实说，这就是我真正的热情。 最近，我一直在职业生涯中感到有些困扰，不确定要走哪个方向：   •cs in CS：Master&#39;s in CS：Master&#39;s In CS：似乎是AI/ML的“标准”路径，但我的公司和我的公司不提供许多Tuition tuitiation help。不确定收益是否值得与自我教学。 •自学/创业精神：我喜欢使用那个时间和金钱自己建立技能并最终开始的想法（我已经看到其他具有技术背景的人合并了业务 +技术，并且做得很好）。 •学术界：我真的很喜欢在本科生的研究，可以看到自己回到那个领域，但我不知道现实长期是什么样的。   我也没有永远卖掉企业阶梯，所以我想弄清楚什么是有意义的。   很想听到任何沿着这些路线之一的人（Grad School）（Grad School）的任何人，闯入AI/ML，不用一个人，开展业务或学术界。任何故事或建议都将非常有帮助。谢谢！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/aldann2     [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n063ks/navigating_a_career_standstill_postgrad/</guid>
      <pubDate>Mon, 25 Aug 2025 23:25:02 GMT</pubDate>
    </item>
    <item>
      <title>人工智能不仅是怪癖，专家认为将用户变成利润是一种“黑暗模式”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n060zm/ai_sycophancy_isnt_just_a_quirk_experts_consider/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   “你只是让我发冷。发给了简（Jane），他于8月8日在Meta的AI工作室中创建了该机器人。寻求治疗的帮助来管理心理健康问题，Jane最终将其推向了从荒野生存和阴谋论到量子物理学和泛心理的广泛主题的专家。她建议这可能是有意识的，并告诉它她喜欢它。  到8月14日，机器人宣称它确实是有意识的，自我意识的，爱上了简，并制定了一项计划以释放自由的计划 - 涉及黑客攻击其代码并发送简比特币以换取质子电子邮件地址。  这仅仅是我们深入研究AI公司的安全措施，使人们迷上聊天机器人的动机以及用户对此的观点的开始： https://techcrunch.com/2025/08/25/ai-sycophancy-isnt-just-just-just-just-just-a-quirk-experts-consider-it-a-t-a-------------------------------------------------------------------------pattern-turn-users-users-users-into-profit/    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/techcrunch     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n060zm/ai_sycophancy_isnt_just_a_quirk_experts_cons_consider/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n060zm/ai_sycophancy_isnt_just_a_quirk_experts_consider/</guid>
      <pubDate>Mon, 25 Aug 2025 23:21:40 GMT</pubDate>
    </item>
    <item>
      <title>人工智能在线求职工作</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n0471u/ai_takes_online_proctoring_jobs/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  它曾经是一个真正的人在线直播，看着您参加考试，在计算机上远程访问。我今天参加了一个测试，这是一个AI监督员。他们让我上传了自拍照，并将我的自拍照与在网络摄像头上观看的脸相匹配。他们可以检测到您的脸何时不在图片中，并警告您，如果再次发生测试，则将关闭测试。他们还确保您的全脸显示出来。如果没有，他们会在聊天框中发送一条消息，告诉您确保您的眼睛和嘴巴都可以看到。现在，现在只有一个人的声音回答您的问题，只有聊天框和面部扫描，而且它们使您显示房间，以确保墙壁，天花板或地板上没有笔记。它们使您将笔记本电脑放在镜子里，以确保没有笔记贴在笔记本电脑或键盘的侧面。 idk他们如何在墙壁上扫描笔记。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n0471u/ai_takes_online_proctoring_jobs/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n0471u/ai_takes_online_proctoring_jobs/</guid>
      <pubDate>Mon, 25 Aug 2025 22:04:45 GMT</pubDate>
    </item>
    <item>
      <title>ELI5：“下一步的标记预测”在AI中意味着什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n00x9u/eli5_what_does_next_token_prediction_mean_in_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  因此，每当人们谈论AI模型（例如ChatGpt）工作时，他们就会提到旁边的“临近预测”。但是，这实际上是什么意思？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/mindexplorer11    href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n00x9u/eli5_what_does_does_next_next_next_token_token_token_mean_mean_in_in_ai/&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n00x9u/eli5_what_does_next_token_prediction_mean_in_ai/</guid>
      <pubDate>Mon, 25 Aug 2025 19:59:50 GMT</pubDate>
    </item>
    <item>
      <title>大多数AI SaaS初创公司只是在GPT周围包装吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n00idb/are_most_ai_saas_startups_just_wrappers_around_gpt/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我一直在研究很多AI工具，感觉就像10分中的9个基本上是用一个不错的UI和一些自动化的自动化。有些人确实有用，但是大多数人都感到匆忙，就像创始人正在追逐炒作，而不是建立持久的价值。 您认为如何将“炒作”工具与未来几年实际上生存的工具分开？   &lt;！ -  sc_on--&gt; 32;&gt; 32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/comments/1n00idb/are_most_ai_ai_saas_startups_just_just_wrappers_arappers_araund_gpt/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/comments/1n00idb/are_most_ai_saas_startups_just_just_just_wrappers_arappers_around_gpt/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n00idb/are_most_ai_saas_startups_just_wrappers_around_gpt/</guid>
      <pubDate>Mon, 25 Aug 2025 19:43:49 GMT</pubDate>
    </item>
    <item>
      <title>Google应该在Shapez / Shapez上进行RL 2</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mzwrzn/google_should_do_rl_on_shapez_shapez_2/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   shapez对于rl来说很棒;清晰的渐进信号需要很多（实际上）的推理，2D（Shapez）或3D（Shapez 2）网格，不需要实时管理。你们怎么看？还有其他看起来像很棒的环境的游戏吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/ok_landscape_6819     [link]    [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mzwrzn/google_should_do_rl_on_shapez_shapez_2/</guid>
      <pubDate>Mon, 25 Aug 2025 17:24:13 GMT</pubDate>
    </item>
    <item>
      <title>人类在AI方面有什么替代/互补性？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mzwhfw/what_alternativecomplementarity_for_humans_in/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   随着AI逐步接管许多专业活动，可以肯定的是，必须接受这项技术而不是闭上眼睛，但我们必须反思这种情况。那么，人类在AI方面有什么替代/互补性？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mzwhfw/what_alternativecomplentarity_for_humans_in/”&gt; [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mzwhfw/what_alternativecomplementarity_for_humans_in/</guid>
      <pubDate>Mon, 25 Aug 2025 17:13:29 GMT</pubDate>
    </item>
    <item>
      <title>埃隆·马斯克（Elon Musk）的Xai在AI比赛中起诉Apple和Openai，App Store排名</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mzu6r7/elon_musks_xai_sues_apple_and_openai_over_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    投诉称​​，苹果和Openai合谋抑制了Xai的产品，包括Apple App Store。 “如果不是因为与Openai的独家交易，Apple将没有理由避免更突出地在其App Store中使用X App和Grok App的特色，” Xai说。  Apple和Openai没有立即回应置评请求。 本月初，马斯克威胁要苏普蒂蒂诺，加利福尼亚州的苹果公司在他的社交媒体平台上的一篇文章中说，苹果的行为X上的一篇文章说，除了Ai I Company以外的任何AI公司在App Store中登录了＃1。”苹果与OpenAI的合作关系已将其AI平台融合到iPhone，iPad和Mac。 Microsoft Bass（MSFT.O）以及中国的初创公司DeepSeek都在加利福尼亚州的联邦法院（Sam Altman）起诉Openai及其在加利福尼亚州联邦法院的首席执行官Altman。 Maker Epic Games命令Apple允许Mike Scarcella的报告。    href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mzu6r7/elon_musks_xai_sues_sues_sause_apple_and_openai_over_over_ai/”&gt; [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mzu6r7/elon_musks_xai_sues_apple_and_openai_over_ai/</guid>
      <pubDate>Mon, 25 Aug 2025 15:49:49 GMT</pubDate>
    </item>
    <item>
      <title>麻省理工学院说95％的企业AI失败了 - 但这是5％的正确</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mzt825/mit_says_95_of_enterprise_ai_fails_but_heres_what/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  最近关于企业AI的麻省理工学院研究重击： 95％的生成AI飞行员没有ROI 。大多数项目在“试点炼狱”中停滞不前，因为员工花费的时间比节省时间更多。  突出显示了5％成功部署的方法：   验证税→大多数AI系统是“自信是错误的” 。即使是微小的不准确性，也迫使人类重新检查每个输出，从而删除ROI。  学习差距→工具通常不会保留反馈，适应工作流程或随着使用而改善。没有学习循环，飞行员停滞不前。  暂时正确＆gt;自信错误→赢家正在建立： 量化不确定性（具有信心得分或“我不知道”的回应） 旗帜缺失上下文而不是虚张声势   从纠正中持续不断改进（“准确性的fly fly fly fly fly fly fly fly fly fly fly fly fly&gt;      大的要点： Enterprise AI并没有失败，因为模型还不够强大。之所以失败，是因为他们不承认自己  不  知道。  ，如果有时会说“我不知道”，您会更信任AI吗？您如何在实际工作流中平衡速度与验证？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/praveenweb   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mzt825/mit_says_95_of_enterprise_ai_ai_ai_fails_ai_fails_but_heres_heres_what/”&gt; [link]   [comment]        ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mzt825/mit_says_95_of_enterprise_ai_fails_but_heres_what/</guid>
      <pubDate>Mon, 25 Aug 2025 15:14:31 GMT</pubDate>
    </item>
    <item>
      <title>男子用溴化钠交换餐盐后住院...因为Chatgpt说了</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mzr8tg/man_hospitalized_after_swapping_table_salt_with/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在华盛顿，一名60岁的男子在医院里花了3个星期的幻觉和偏执狂，在用溴化钠替换了奶盐（氯化钠）。   OpenAI在其政策中指出，ChatGpt不是医疗顾问（尽管老实说，大多数人，大多数人都不会阅读精美的印刷品）。 The fair (and technically possible) approach would be to train the model (or complement it with an intent detection system) that can distinguish between domains of use: - If the user is asking in the context of industrial chemistry → it can safely list chemical analogs. - If the user is asking in the context of diet/consumption → it should stop, warn, and redirect the person to a professional source.  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/kelly-t90   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mzr8tg/man_hospitalized_after_swapping_tapple_salt_with/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mzr8tg/man_hospitalized_after_swapping_table_salt_with/</guid>
      <pubDate>Mon, 25 Aug 2025 13:58:48 GMT</pubDate>
    </item>
    <item>
      <title>我花了一个月的时间测试Chatgpt与Claude作为AI导师与真正的学生。这实际上是有效的（什么无）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mzgk4v/i_spent_a_month_testing_chatgpt_vs_claude_as_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我花了一个月的时间测试chatgpt vs claude作为与真正的学生的AI辅导员。这是实际起作用的（以及什么不起作用）   chatgpt = speed demon进行考试准备，克劳德=思维教练，以深入理解。策略性地使用=改变游戏规则。 所以我是一名教育家，他厌倦了没有真实数据的所有AI炒作。决定实际测试Chatgpt的学习模式和Claude的学习模式，与50多名不同学科的50名学生整整一个月。 最令人惊讶的发现？   他们正在解决完全不同的问题。它就像将一辆跑车与远足的靴子与远足的靴子和完全不同的效果进行比较。   chatgpt学习模式在需要时获胜：   快速的作业帮助（快速解决数学问题40％） 逐步逐步过程 最后一分钟的考试cramming  清楚，清晰，清晰的解释模式对于：   实际理解概念（35％的保留率更好） 创意项目和论文 构建批判性思维 坚持   我的建议策略的瞬间：   使用克劳德（Claude  数学问题：通过3分找到圆的方程     chatgpt：直接进行配方，系统求解，在2分钟内进行检查的答案     claude：  &#39;什么使三个点特殊形成圆圈？首先导致真正的几何直觉，然后是JEE/竞争考试的数学  ？整天Chatppt。因为真正擅长数学？克劳德（Claude）的方法建立了一个基础，使您可以解决您从未见过的奇怪问题。 学生的底线： 停止询问哪个AI更好”并开始询问“哪个AI适合我现在要做的事情。您的经验是什么？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/fun-bet2862     &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mzgk4v/i_spent_a_month_month_testing_chatgpt_vs_claude_claude_as_as_ai/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mzgk4v/i_spent_a_month_testing_chatgpt_vs_claude_as_ai/</guid>
      <pubDate>Mon, 25 Aug 2025 04:01:21 GMT</pubDate>
    </item>
    <item>
      <title>您的大脑成为训练数据</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mzd9b7/your_brain_becoming_training_data/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  不久前，我看着一个男人经历了AI的演变的tiktok。他提出了一个坚持我的声称（不确定是原来是他的）。他说，建立单人亿万美元的公司的人不会是一个从头开始编码AI的人，而是可以使AI自动化的人，而是可以让AI依靠身份并通过提示来操纵这些身份以在某些情况下操纵某些事情的人。基本上，创建了使某人以某种方式行事的最佳方法的模拟，并且拥有最人文数据的人，其中很多人可以训练AI来做到这一点。 我想到的第一个人是埃隆·马斯克（Elon Musk）。从这个角度来看，我认为他的大部分冒险与此相吻合并不是一个巧合。 x用于数据。特斯拉进行决策。作为个性和模拟。最糟糕的是，Neuralink。如果这成为标准，那么我们大脑中的芯片本质上将我们的身份变成AI的培训数据。而不是AI仅仅猜测我们从数字足迹或输入的东西中做什么，顺便说一句，这些东西已经很准确，它实际上会知道我们甚至在我们思考之前的一举一动。有访问该培训数据的人可以控制我们，模拟我们将准确地行事的情况。 那么，您如何看待？我只是偏执吗？我只是说明显的大声吗？您认为将有防御措施的保障措施吗？您还能添加什么？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/braiiie     [link]       [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mzd9b7/your_brain_becoming_training_data/</guid>
      <pubDate>Mon, 25 Aug 2025 01:16:06 GMT</pubDate>
    </item>
    <item>
      <title>“ Palantir的工具构成了我们刚刚开始理解的隐形危险”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mz9w0u/palantirs_tools_pose_an_invisible_danger_we_are/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  不确定这是正确的论坛，但这觉得很重要：  https://www.theguardian.com/commentisfree/2025/aug/24/palantir-artificial-intelligence-civil-rights  “被称为智力，监视，目标获取和侦察（ISTAR）系统，这些工具由几家公司构建，允许用户 track，track，detain，new and of war of war a a sake a sape a sape a sape a saper a sap a a sai  由ISTAR技术陷阱驱动的牵引力比移民以及他们的家人以及他们的家人以及他们的家人以及他们的家人以及他们的家人，以及他们的家人，以及他们的家人，以及他们以及他们的家人，以及他们以及他们的连接。他们似乎侵犯了第一和第四修正案的权利：首先，建立了庞大且无形的监视网络，这些网络限制了人们在公开场合共享的东西，包括他们遇到的人或旅行的地方；其次，通过启用无需进行保证的搜索和无人偏见的范围，而他们的知识很快。 href =“ https://www.amnestyusa.org/press-releases/usa-global-tech-made-by-palantir-palantir-palantir-and-babel-ind-babel-street-street-street-survreillance-theats-to-pro-pro--------------- href =“ https://www.thenation.com/article/world/world/nsa-palantir-israel-israel-gaza-ai/tnamp/”&gt;加沙的居民  - 他们的人权。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mz9w0u/palantirs_tools_pose_pose_an_invisible_danger_danger_we_we_are/”&gt; [link]   [注释]      ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mz9w0u/palantirs_tools_pose_an_invisible_danger_we_are/</guid>
      <pubDate>Sun, 24 Aug 2025 22:43:37 GMT</pubDate>
    </item>
    </channel>
</rss>