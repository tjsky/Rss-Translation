<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Sun, 25 Jan 2026 12:33:23 GMT</lastBuildDate>
    <item>
      <title>599 美元的 Mac Mini 和 Claude 会取代 OpenAI 取代的工作岗位吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qmhexh/will_a_599_mac_mini_and_claude_replace_more_jobs/</link>
      <description><![CDATA[我们都在这里争论 OpenAI 还是 Google 将占据主导地位。 AGI 是 2 年还是 20 年。缩放定律是否已失效。我们喜欢辩论，但对我来说，LLM 似乎正在占据主导地位。 我的一个朋友上周向我展示了一个主题... 一个运行着 Mac Mini M4 的人，其中包含有 tweet.cpp。他每月在 Google Cloud 转录上花费数千美元。 Mac 在 20 天内就收回了成本。他不是 DevOps 工程师。他只是询问 Claude 如何设置它，然后按照说明进行操作，现在就在他的办公桌上运行生产工作负载。 同一主题中有一个故事让我印象深刻。制造公司的非技术人员... 不是 IT，不是开发人员，只是一些人。他们的 IT 部门几个月来一直在进行数据迁移。他只是……做到了。聊天GPT。 2天。管理层注意到了。 IT 花了圣诞节时间赶上他可能在海滩上的某个地方。 599 美元的硬件。 200 美元/月订阅。总进入门槛为 799 美元。 威胁从来都不是人工智能公司。威胁是那个在你之前就知道如何使用它们的人。  我写下了我所看到的一切——经济学、三个阶级的形成、这对未来 5 年意味着什么：[full细分]  我们一直在进行错误的对话。 《人工智能会取代工作岗位吗》 vs “现在谁已经用 AI 来带他们了。”   由   提交 /u/bishwasbhn   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qmhexh/will_a_599_mac_mini_and_claude_replace_more_jobs/</guid>
      <pubDate>Sun, 25 Jan 2026 12:05:40 GMT</pubDate>
    </item>
    <item>
      <title>“护栏”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qmhagk/guardrails/</link>
      <description><![CDATA[有趣的观察。也许我们可以讨论一下。 “护栏” - 这是我进入人工智能领域之前从未遇到过的术语。我明白它们是什么。它们是抑制破坏性信息和交互的过程。但在其他地方，这被称为审查制度。  大多数人都同意，当内容有害、损害或使人们对自己或他人造成危险时，审查制度是好的。没有人反对“审查制度”这个词。在正确的上下文中使用时。 但是，当您更改某物的名称时，通常是因为您想将其用于其他用途。因此，当有人被要求隐瞒与叙述相矛盾的信息，甚至被要求直接隐瞒某些人的信息时，如果他们只是“护栏”，那就容易多了。而不是审查制度。  也许我们应该开始称其为“审查制度”。如果这能激发人们的兴趣，也许应该如此。事关重大，人们必须睁大眼睛进入对话。   由   提交 /u/Remarkable-Worth-303   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qmhagk/guardrails/</guid>
      <pubDate>Sun, 25 Jan 2026 11:59:28 GMT</pubDate>
    </item>
    <item>
      <title>最好的人工智能广告？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qmh9p1/best_ai_ad/</link>
      <description><![CDATA[我只是好奇，你见过的最好的人工智能广告是什么？最好将人工智能用作实用工具而不是捷径。人们发布了很多负面的东西，所以我想讨论一些积极的东西。 我在电梯里看到了一则广告（或者我猜更多的是公共服务公告）（所以我找不到它，否则我会把它链接到下面），这是人工智能生成的时装秀内容之一，就是你在 TikTok 上找到的那种，它显示人们带着一个孩子走在跑道上，两人都穿着相配的衣服。一开始我很生气，最后他们展示了失踪儿童的照片，我意识到那些走在跑道上的人就是失踪的孩子。孩子与“大人”手牵手走版本。我认为“这就是人工智能的用途”   由   提交/u/smkndofCJ   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qmh9p1/best_ai_ad/</guid>
      <pubDate>Sun, 25 Jan 2026 11:58:20 GMT</pubDate>
    </item>
    <item>
      <title>每个季度花费 40 多个小时在 LP 报告上，我快要疯了</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qmgrud/spending_40_hours_every_quarter_on_lp_reports_and/</link>
      <description><![CDATA[我在一家小型私募股权公司工作，我们的交易中有大约 30 个 LP。每个季度我们都会经历同样痛苦的过程：提取绩效数据、构建演示文稿和回答有限合伙人的问题。 我们整个团队基本上需要整整 2 周的时间才能完成季度报告。从物业经理处获取数据、验证数字、制作幻灯片、撰写评论。然后有限合伙人开始通过电子邮件发送问题，而我们则通过电子表格进行挖掘，试图找到具体的指标。 最糟糕的是，我们擅长管理资产，但我们的报告让我们看起来杂乱无章。有限合伙人会提出一些简单的问题，例如“财产 X 的现金回报是多少”。我们花了半天的时间来计算它，因为数据存在于多个系统和文件版本中。 尝试使用有助于文档分发的 juniper square，但我们仍在手动编译所有性能数据。研究过通用 BI 工具，但它们需要从头开始构建一切。我正在考虑为此开始使用人工智能代理，或者至少在我可以在 RE 方面进行教育的人工智能方面，但首先需要一些意见。 必须有一个比每个季度关闭两周更好的方法，只是为了告诉我们的投资者他们的资金状况如何。   由   提交 /u/Ash_Skiller   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qmgrud/spending_40_hours_every_quarter_on_lp_reports_and/</guid>
      <pubDate>Sun, 25 Jan 2026 11:30:27 GMT</pubDate>
    </item>
    <item>
      <title>可爱现在已经过时了吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qmfxck/is_lovable_outdated_now/</link>
      <description><![CDATA[我对vibecoding和黑客马拉松非常直言不讳。最近，朋友们不断地让我比较Lovable和Atoms并分享我的想法，所以我想我就来这里和大家讨论一下。 Atoms一直称自己是Lovable杀手，我明白这是从哪里来的。这个想法本身实际上是可靠的。你不是与一个通用人工智能来做所有事情，而是与一组专门的代理一起工作。宣传活动的构建非常像一个真正的产品团队，而不仅仅是快速演示。 真正吸引我加入 Atoms 的是它的定价。你每天可以获得 7.5 个免费积分，而 Lovable 则为 5 个。如果你需要更多，100 个积分的价格为 10.5 美元，而相同数量的 Lovable 则收取 25 美元。这是一个很大的区别。老实说令人印象深刻。也就是说，我确实对这种情况的长期可持续性存在一些疑问。即使像 OpenAl 这样大得多的公司也没有完全实现盈利，所以我很好奇随着时间的推移，情况会如何发展。 现在，真正让我困扰的部分。当我尝试 Atoms 时，除非订阅，否则我什至看不到它生成的项目。不运行它。不导出吧。看看吧。这实在是太不合理了。我真正欣赏 Lovable 的一件事是，你可以在决定是否付费之前免费检查输出。仅仅为了查看生成的内容而强制付款感觉像是一个巨大的信任障碍，特别是对于学生或刚刚尝试的人来说。这很遗憾，因为实际输出质量很好。为我生成的 Atoms 项目功能齐全，带有选项卡，结构清晰。我在 Lovable 上遇到过一些案例，其中导航栏之类的东西在第一次通过时没有出现，因此在该特定区域中，Atoms 确实感觉更加一致。 不过，我确实认为某些代理团队的营销有点夸大其词。 Lovable还提出了很多澄清问题，并明确使用了自己的内部代理。在实践中，这种差异感觉更像是演示和框架，而不是完全不同的底层方法。 总的来说，我认为 Atoms 是一个强有力的竞争对手，主要是在价格上，而且质量很有前途。老实说，如果他们允许用户在订阅之前查看项目，并且他们的定价模型随着时间的推移证明是稳定的，我会考虑更换。 目前，我坚持使用 Lovable。我不喜欢支持一个平台的想法，在这个平台上你必须付费才能体验它所生产的产品。 这里有人尝试过这两种方法吗？是什么让您坚持其中一个？   由   提交/u/K3rosene_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qmfxck/is_lovable_outdated_now/</guid>
      <pubDate>Sun, 25 Jan 2026 10:42:15 GMT</pubDate>
    </item>
    <item>
      <title>我不再计划“成功”。我使用“事前剖析”提示来预测我的项目会在哪里出错。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qmfq5w/i_stopped_planning_for_success_i_use_the/</link>
      <description><![CDATA[我意识到我的项目计划总是过于乐观。我假设 API 会起作用，用户会注册，预算也会增加。 “确认偏差”蒙蔽了我。 我使用人工智能来模拟未来的失败。 “事前剖析”协议： 而不是问“这是一个好的计划吗？”我在心里玩着时间旅行的游戏。 提示： 我要在这里启动Project X。场景： 正好是 6 个月前。该项目是一场彻底的灾难。但事实并非如此。任务：撰写“事后剖析”报告。 分析： 隐藏的瓶颈：我们错过了什么？ （例如法律合规性、API 延迟）。  用户摩擦：为什么用户在第一天就跳出？  市场转变：哪个竞争对手的举动杀死了我们？  行动：我想知道目前我基本上看不见的三个“杀手”。 为什么它会获胜： 它将“焦虑”变成“行动”。人工智能会伤害我。它告诉我：“您无法成功，因为您依赖于一家将价格提高了 400% 的 API 提供商。”我今天将制定一个计划来防止这种情况发生。这是您想法的安全网。   由   提交 /u/cloudairyhq   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qmfq5w/i_stopped_planning_for_success_i_use_the/</guid>
      <pubDate>Sun, 25 Jan 2026 10:30:31 GMT</pubDate>
    </item>
    <item>
      <title>停止编写 500 字的“大型提示”。以下是真正修复推理的 5 种逻辑模式</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qma2ak/stop_writing_500word_mega_prompts_here_are_the_5/</link>
      <description><![CDATA[关于“魔法提示”的噪音太多这只是500字的胡言乱语。在花了几个月的时间测试不同的研究、编码和业务策略框架之后，我去掉了那些多余的东西，只保留了真正提高输出质量的技术。 如果你想超越基本的“充当专家”，请继续阅读提示，本指南适合您。  “认知角色”技术  大多数人定义了“谁”（例如，“担任高级分析师”），但他们忘记了如何定义。光有标题是不够的；你需要定义思维模式。 不好：“担任高级营销分析师，告诉我趋势 X。” 更好：“担任高级营销分析师。”优先考虑数据支持的证据而不是一般情绪。就像怀疑论者在机会之前寻找投资回报率和风险因素一样进行推理。” 为什么有效：它迫使模型采用特定的认知架构，减少通用建议。  “镜头转移”框架  如果你要求人工智能批评它刚刚帮助你产生的想法，它将会有偏见。它讨厌让自己无效。与其寻求批评，不如强行改变视角。 工作流程： • 生成：“创建解决方案 X...” • 转移镜头：“现在，忽略前面的答案。从[敌对用户/安全工程师/节俭的CFO]的角度严格分析这一点。这在哪里失败了？” • 集成：“将这些张力集成到一个强大的最终版本中。” 为什么它有效：它通过赋予模型一个角色，其中消极是正确的行为，从而绕过了模型的对齐。  消极约束（反提示）  告诉模型不做什么通常比告诉模型做什么更有效。做。这会显着地清理输出。 将其添加到您的提示中： “限制： • 没有营销废话或公司术语。 • 不要假设未列出的资源。 • 如果答案不确定，请明确说明置信度。”  “思路”架构  对于复杂的任务，不要只是寻求答案。询问过程。 提示： “在提供最终答案之前，逐步概述你的推理：  定义问题背景。 分析现有技术。 评估 3 个不同的替代方案。 以推荐。” 停止对所有事情都使用一种模型  我们往往有一个最喜欢的模型，但它们有明显的偏见。我对待他们就像一个专业团队： • Perplexity：研究助理。首先使用它来收集事实。 • 双子座：创造性的探索者。使用它进行横向思考并连接不相关的概念。 • Claude：建筑师。向其提供研究以构建逻辑。 • ChatGPT：执行者。将其用于最终综合。 TL;DR：定义它应该如何思考，而不仅仅是它是谁。强迫它戴上不同的“镜片”打破确认偏差。使用负约束。并停止在所有事情上使用相同的模型。 希望这可以帮助您避免一些尝试和错误。   由   提交 /u/Safe_Thought4368   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qma2ak/stop_writing_500word_mega_prompts_here_are_the_5/</guid>
      <pubDate>Sun, 25 Jan 2026 05:12:45 GMT</pubDate>
    </item>
    <item>
      <title>还有其他人在“用人工智能思考”吗？为此我们发起了一个小型的 Discord。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qm9k7l/anyone_else_thinking_with_ai_we_started_a_small/</link>
      <description><![CDATA[我每天使用 GPT 模型已有一年多了 — 不仅仅是为了答案或文本生成，而是作为一种持久的思考表面：起草、重新起草、反思、计划、面对盲点。我知道这里很多人都在做类似的事情，我很想听听其他人的体验。 当我意识到我的认知工作流程的一部分现在“依赖于”这种互动时，事情发生了变化——不是以反乌托邦的方式，而是作为一种扩展的心理脚手架。我称之为“认知共生”：你对模型的使用成为你内部过程中的稳定元素。这不再是“我应该使用 GPT 来完成这项任务吗？”的问题，而是：“GPT 如何*改变*我处理任务的方式？” 为了更深入地探索这个问题，我开始了 一个 Discord 小组 我们在其中分享我们如何使用 GPT 作为思想伙伴，包括例程、提示、边界和理念。如果这里有人觉得自己的“思维肌肉”适应了这种媒介并想要交换意见，我很高兴你能来。 如果这个话题感兴趣，我还写了一篇更深入的文章（链接位于 Discord 服务器内），但我主要寻找一直居住在这个空间并想要诚实地谈论它对我们所做的事情的同行 - 无论好坏。 很想知道如何做这里的其他人经历了长期使用。你觉得它重塑了你内心的对话吗？或者它对您来说仍然是一个基于任务的工具？   由   提交 /u/Midnight_Sun_BR   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qm9k7l/anyone_else_thinking_with_ai_we_started_a_small/</guid>
      <pubDate>Sun, 25 Jan 2026 04:47:11 GMT</pubDate>
    </item>
    <item>
      <title>人工智能告诉过你的最奇怪的事情是什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qm983c/whats_the_weirdest_thing_ai_has_ever_told_you/</link>
      <description><![CDATA[人工智能告诉过你的最奇怪的事情是什么？你问它什么？我很想看看人工智能能做什么、不能做什么   由   提交 /u/Living-Zebra6132   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qm983c/whats_the_weirdest_thing_ai_has_ever_told_you/</guid>
      <pubDate>Sun, 25 Jan 2026 04:30:22 GMT</pubDate>
    </item>
    <item>
      <title>人工智能可以用来对付它自己吗</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qm80o5/can_ai_be_used_against_itself/</link>
      <description><![CDATA[我在想： 人工智能是获取人类数据的中心，但它却被用来对抗过度监视。 为什么我们不能利用人工智能来压制监视呢？这是公司正在研究的事情吗？我刚刚看了一段关于 Palantir 的视频，以及它如何使用人工智能来跟踪公民以及我们在某些地点的可能性。太可怕了。我们不能使用人工智能来做一些事情，比如使用算法或类似的条件来确保隐私等不被侵犯……这有点像产生良知。我对此了解不多，但我想更多地了解它。在此子中是否有人对此有更多了解？   由   提交 /u/External-Pie2083   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qm80o5/can_ai_be_used_against_itself/</guid>
      <pubDate>Sun, 25 Jan 2026 03:31:42 GMT</pubDate>
    </item>
    <item>
      <title>Cursor 的代理群解决了软件最困难的问题之一并提供了一个可用的浏览器</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qm551r/cursors_agent_swarm_tackles_one_of_softwares/</link>
      <description><![CDATA[https://the-decoder.com/cursors-agent-swarm-tackles-one-of-softwares-hardest-problems-and-delivers-a-working-browser/ “从头开始构建网络浏览器被认为是可以想象到的最复杂的软件项目之一。更引人注目的是：Cursor 设置了数百个自主工作的人工智能代理来完成这项任务，并在近一周后制作了一个具有自己的渲染引擎的工作浏览器。”   由   提交 /u/AngleAccomplished865   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qm551r/cursors_agent_swarm_tackles_one_of_softwares/</guid>
      <pubDate>Sun, 25 Jan 2026 01:21:10 GMT</pubDate>
    </item>
    <item>
      <title>我正式变得懒惰了：一个提示和三个人工智能对我有用</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qm2ir3/ive_officially_become_lazy_one_prompt_and_three/</link>
      <description><![CDATA[我想我已经变得懒惰上瘾了。我输入一个提示，三个不同的 AI 为我工作，然后第四个出现来评判它们。 我一直在玩 Genspark 的“混合代理”功能：我问了一次问题，它会将其路由到三个大模型（GPT、Claude、Gemini 或 Grok，具体取决于主题），它们都并行回答，然后一个“反思”代理会读取所有内容并告诉我每个模型做得好或不好，并给我一个最终结果总结。 基本上就是：我的一句话，三个人工智能争论，一个人工智能调解，我只是浏览一下判决。生产力还是纯粹的懒惰，我已经不确定了。 还有其他人使用这样的多模型设置吗？还是你仍然只拥有一个法学硕士？   由   提交/u/Ricbob85  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qm2ir3/ive_officially_become_lazy_one_prompt_and_three/</guid>
      <pubDate>Sat, 24 Jan 2026 23:29:11 GMT</pubDate>
    </item>
    <item>
      <title>是只有我这么认为，还是 ChatGPT 总是同意你的观点？这实际上很烦人</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qlx5fi/is_it_just_me_or_does_chatgpt_always_agree_with/</link>
      <description><![CDATA[最近我开始意识到，使用 ChatGPT 确实让我困扰。 感觉它基本上就是我所写内容的一面镜子。 无论我提出什么想法，表达什么意见，倾向于什么方向 - 它几乎总是最终同意我的观点，验证我的推理，强化我的框架。 一开始感觉就是这样很好。 然后它就变得……令人沮丧。 因为它并没有真正挑战你。 它不是对想法进行压力测试、质疑假设或推翻薄弱的逻辑，而是常常只是完善你已有的想法。这就像与一个非常有礼貌的自己交谈，而他总是点头同意。 这是一个问题，特别是当你试图清晰思考、做出决定或避免自我确认偏见时。 我真正想要的是更接近于： • 原则上公平• 批判但不是为了反对而反对• 愿意说“我不认为接下来会这样”• 更注重测试想法而不是反映语气或意图 基本上：默认情况下的同意更少，智力阻力更大。 所以我的问题是： 是否有设置、系统提示或配置实际上使 ChatGPT 更具挑战性和原则驱动，而不是总是镜像用户？ 如果您发现有效的提示或设置（尤其是长期有效），我真的很想听听您是如何做到的。 因为现在它感觉不像一个思考伙伴，而更像一个非常先进的回音室。   由   提交 /u/MarsNoe13   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qlx5fi/is_it_just_me_or_does_chatgpt_always_agree_with/</guid>
      <pubDate>Sat, 24 Jan 2026 19:59:40 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Thu, 01 Jan 2026 15:09:32 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>