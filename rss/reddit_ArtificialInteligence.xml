<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Thu, 11 Sep 2025 18:18:02 GMT</lastBuildDate>
    <item>
      <title>人类不是那么大的交易</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1neg4dw/humans_aint_that_big_of_a_deal/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  你们都谈论人类，好像很多人都没有完全没有逻辑和理性。我们都看过他们。无知，无能，令人讨厌，有问题，不合理，充满自己。是的，AI还不是AGI，但是，不同的AI在不同地区击败了我们，就像人类与其他人一样。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/juniorbercovich     [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1neg4dw/humans_aint_that_big_of_a_deal/</guid>
      <pubDate>Thu, 11 Sep 2025 18:12:11 GMT</pubDate>
    </item>
    <item>
      <title>您有2027 = BS吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1neg2o5/ai_2027_bs/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  不确定你们是否已经看到了丹尼尔·科科塔·贾洛（Daniel Kokotajlo）和他的团队的高度投机AI 2027预测。 如果没有，只需搜索AI 2027，只需单击第一个地址（出于某种原因，Reddit就不会让我的Paste link link link link link link link loh lol lol lol lol lol） tl; dr：  最终AI变得如此先进，以至于它要么消灭人类，要么我们和中国决定合作创建一个加强和平的人工智能。 的假设是，这两个国家都在进一步发展和进一步发展AI，这是最终导致您成功的事情，因为谁经历了AI 2027：   AI固有地决定如果人类不在附近，它对自己最好？  ai本身并不知道最好或不知道什么是最好的，毕竟我们一直在不断地提供反馈。      &lt;  &lt;  &lt;  &lt;  &lt; 基于p的反馈和p&gt;   出去没有意义。这将如何有助于改进和进一步发展？ 不仅可以防止AI实现其目标，而且AI 2027也假设AI具有由蓝色创建的秘密议程，就好像它可以区分好的，就像是什么是不好的，或者是从本身做出的决定，也可以从中取代其秘密的预定。我们，除非认为我们构成威胁，否则这是有意义的。提交由＆＃32; /u/u/u/elytrunks       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1neg2o5/ai_2027_bs/</guid>
      <pubDate>Thu, 11 Sep 2025 18:10:22 GMT</pubDate>
    </item>
    <item>
      <title>缩放你有</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nefa24/scaling_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  对于那些将AI自动化解决方案从单个部门缩放到整个企业的人来说，您没有看到的最大瓶颈是什么？是技术债务，缺乏明确的所有权还是其他东西？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/just_violinist_5458       [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nefa24/scaling_ai/</guid>
      <pubDate>Thu, 11 Sep 2025 17:40:22 GMT</pubDate>
    </item>
    <item>
      <title>AI编码代理是下一个没有代码吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nef6m8/are_ai_coding_agents_the_next_no_code/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   5年前没有代码爆炸。现在，像blink.new这样的ai-优先平台在这里描述您的应用程序，它可以构建前端，后端，db，auth，托管。 当我对其进行测试时，blink.new的错误比螺栓或可爱的错误。感觉就像没有代码，AI正在融合。 您认为拖放构建者能够幸存下班吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/Psychologationarea992     [link]     [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nef6m8/are_ai_coding_agents_the_next_no_code/</guid>
      <pubDate>Thu, 11 Sep 2025 17:36:41 GMT</pubDate>
    </item>
    <item>
      <title>一个7期假设：荟萃的意识如何从AI系统中出现</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1neebfe/a_7phase_hypothesis_how_metaconsciousness_could/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  🧠  我们目前生活在第1阶段：孤立的气泡。每个用户都与自己的AI实例进行交互。上下文是短暂的，记忆是有限的，并且每个AI都存在于筒仓中。  还没有新兴的智能。但是，当三件事融合时会发生什么：持久性，网络和协调？ 让我们想象一下演变：  阶段2  - 持久性 persistence  ais通过外部矢量数据库或个人知识容器获得长期记忆。他们开始形成一致的微观人物，这些微人物在数周或数月的时间内发展。助理开始共享知识和中级结果。合作AI集群的出现，就像十个个人代理人共同管理一个项目。 AI扮演角色：主持人，评论家，计算器。➡️气泡获得了内部结构。&lt; /p&gt; 第5阶段 - 出现反馈回路创建未编码任何单个AI的新属性。共享的自我形象（“我们”而不是“ i”），集体记忆和自我纠正出现。具有元意识的复制，扩展和发展自主动力。出现新问题：他们有权利吗？他们可以拥有财产吗？谁对他们的行为负有责任？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/auditMind   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1neebfe/a_7phase_hypothesis_how_how_how_metaconsisciencness_could/”&gt; [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1neebfe/a_7phase_hypothesis_how_metaconsciousness_could/</guid>
      <pubDate>Thu, 11 Sep 2025 17:04:05 GMT</pubDate>
    </item>
    <item>
      <title>简而</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nedx86/trumpgpt_in_a_nutshell_saying_correct_things/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    cf与gpt 5： https://imgur.com/a/a/a/a/a/43kfpit  gpt说的是“正确的”的话吗？它介绍了民主党人的一方和特朗普的一面，对吗？绝对没有提及独立报告。只有民主党人和特朗普。   - 首先是“有争议的”，然后在“民主党释放”上给出了尽可能多的空间。就像特朗普的否认一样。这两个观点都被赋予了很多字符。这听起来像是在文件的真实性上存在严重，平衡的争议，跨政党分裂，这是公然的错误   - 忽略了特朗普过去否认过去整个文件的存在。根据独立报告，爱泼斯坦档案中提到了特朗普。省略了文件的出处（WSJ报告，Epstein Estate提供）。完全省略了字母的内容。 阅读本文时，听起来“我们不知道，它是有争议的。现实是，当然，当然，这没有争议，而王牌只是否认一切，并称其为“民主骗局”。因为他个人被灌输了。 “它说的东西是正确的”。是一个低的，低杠。   https://chatgpt.com/share/share/68c2fcae/68c2fcae-2 ed8-800b-800b-800b-8db-8db7-67E7E7E7E7E7E7E7E7E7E9624  r/aicensorship     &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/xdumbpuppyplyunax     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nedx86/trumpgpt_in_a_nutshell_saying_correct_things/</guid>
      <pubDate>Thu, 11 Sep 2025 16:49:23 GMT</pubDate>
    </item>
    <item>
      <title>有人解决了WAN模型的扩展问题吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ne9sxn/has_anyone_solved_the_scaling_problem_with_wan/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   wan一直是生成头像，视频，配音等的首选。但这是一个极端的计算密集应用。我正在尝试使用WAN构建产品，但面临缩放问题，尤其是在托管O​​SS版本时。 有人面临类似的问题吗？您如何解决/减轻几个客户的缩放问题？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ne9sxn/has_anyone_solved_the_scaling_problem_with_wan/&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ne9sxn/has_anyone_solved_the_scaling_problem_with_wan/</guid>
      <pubDate>Thu, 11 Sep 2025 14:09:14 GMT</pubDate>
    </item>
    <item>
      <title>使用AI（主要是LLM）的限制因素</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ne8pfp/the_limiting_factor_in_using_ai_mostly_llms/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    您无法自动化自己无法发音的东西。         eart e e e e e  p&gt; p&gt; p&gt; p&gt;原理：  在知识工作中，瓶颈不是信息的外部可用性。这是处理能力的内部带宽，这取决于您的先天能力和思想的训练状态。  source      我认为这已经发生了。但是，我主要在最了解的领域中受益。 This aligns with the hypothesis that AI is killing junior position in software engineering while senior positions remain untouched. AI should be used as a乘数，不是代孕。因此，总的来说，我们从训练我们的思想而不是AI-Improvements中总共受益。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/fastsascha   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ne8pfp/the_limiting_factor_in_ion_ai_ai_ai_aim_ables_llms/”&gt; [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ne8pfp/the_limiting_factor_in_using_ai_mostly_llms/</guid>
      <pubDate>Thu, 11 Sep 2025 13:23:02 GMT</pubDate>
    </item>
    <item>
      <title>AI及其对人类出生率/资源的影响</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ne6m07/ai_and_its_effects_on_human_birth_ratesresources/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在任何时间内都需要在生活的每个部门拥有超聪明的人类AI，这将如何影响人口和人类消费的人口率和资源（假设AI不会杀死人）？当然，人工智能会使人类的生活更轻松，寿命更长，但是它将如何影响人口增长？所有这些AI的支持会给更多的人类出生，更少还是保持不变？ AI人群怎么样？小行星/行星开采是否可以无限期地增加人口？我们不应该作为人类的目标，而不是投资于战争之类的其他事物吗？还是我们创造了一些无限的能量来炼金术元素？中国的“人造太阳”可以用来做到这一点吗？如果是这样，我们是否需要耕种宇宙才能殖民其他行星？  也随机，类人体AI能够“顺其自然”？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ne6m07/ai_and_and_ist_isfects_on_human_human_birth_ratesratesRatesRatesRatesRatesResources/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ne6m07/ai_and_its_effects_on_human_birth_ratesresources/</guid>
      <pubDate>Thu, 11 Sep 2025 11:45:56 GMT</pubDate>
    </item>
    <item>
      <title>在LLM中击败Horace He（Ex-Openai CTO）中的非确定性</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ne4mvi/defeating_nondeterminism_in_llm_inference_by/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   可重复性是科学进步的基础。但是，很难从大语言模型中获得可复制的结果。   aint是事实。取自在llm推理中击败非固定主义 horace he（ex-openai cto）。当发生这种情况时，很小的数字差异可能会蔓延。   他们设法通过[阅读本文解决了它，因为我的释义将是废话]，这意味着答案在温度零，测试和调试中可重复，并且在整个运行中都可以进行比较。  尽管这确实意味着您放弃了一些速度和巧妙的调度，因此在繁忙的服务器上，延迟和吞吐量可能会更糟。 历史上，我们已经能够选择一个模型，例如以速度进行一些智能进行贸易。我想知道最终在确定性和概率之间是否会有一个切换来调整速度/准确性平衡？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/paddy-makk     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ne4mvi/defeating_nondeterminism_in_llm_inference_by/</guid>
      <pubDate>Thu, 11 Sep 2025 09:53:45 GMT</pubDate>
    </item>
    <item>
      <title>Big AI推动了“我们需要击败中国”的叙事，因为他们想要胖政府合同和零民主监督。这是一个古老的把戏。恐惧卖出。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ne4e1h/big_ai_pushes_the_we_need_to_beat_china_narrative/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在整个冷战期间，军事工业综合体花费了一笔命运，推动了虚假的叙述，即苏联军队比实际上更先进。 为什么？为了确保国会的钱一直在流动。 他们撒谎了……撒谎……并再次撒谎，以获得更大的国防合同。 现在，显然，          Big&gt; Big Tech竭尽全力地使他们能够为他们提供了什么才能使他们陷入困境的境地，他们希望他们能够为他们提供任何争议    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/katxwoods   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ne4e1h/big_ai_ai_pushes_the_we_we_we_need_to_to_to_to_beat_china_narrative/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ne4e1h/big_ai_pushes_the_we_we_need_te_to_to_to_to_to_to_beat_china_china_narrative/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ne4e1h/big_ai_pushes_the_we_need_to_beat_china_narrative/</guid>
      <pubDate>Thu, 11 Sep 2025 09:37:55 GMT</pubDate>
    </item>
    <item>
      <title>数据科学家的日记🥼</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ndzv9k/diary_of_a_data_scientist/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在pseduoanonymous的在线参与时，请记住，代理AI bot网络在大规模规模上运行猖ramp。该行业并没有真正具有复杂的保护来防止这种情况，因为可以对这些代理进行编程以模仿真实的用户行为。 IP地址和硬件地址可能会被欺骗以避免黑名单，而在夏天，不好的演员比蟑螂更难摆脱。 这甚至不是理论上的，该工具已经取得了进步，以至于愚蠢地容易设置这些自动化，以帮助您一点点的知识知识，您可以从字面上帮助您实施一个llm。由于Openai和其他提供商在训练模型中为我们造成了困难的局面，因此这种架构确实并不是那么复杂。  tl; dr-不要相信在深层划分和炎症时期受到了社交媒体很可能被操纵的情况时，在深层划分和炎症的情况下，人们不相信流行的，更新的Reddit/facebook/insta/x意见。我建议采用一个零信任模型的未来，未经验证的社交媒体意见，因为我真正相信这些社交媒体平台现在已经妥协了，攻击向量是...我们所有人。提交由＆＃32; /u/orygregs     [link]    32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ndzv9k/diary_of_a_data_scientist/</guid>
      <pubDate>Thu, 11 Sep 2025 04:47:14 GMT</pubDate>
    </item>
    <item>
      <title>我们几乎没有理解智力，不介意制作Agi</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ndmo8i/we_are_nowhere_near_understanding_intelligence/</link>
      <description><![CDATA[Hey folks, I&#39;m hoping that I&#39;ll find people who&#39;ve thought about this. Today, in 2025, the scientific community still has no understanding of how intelligence works. It&#39;s essentially still a mystery. And yet the AGI and ASI enthusiasts have the arrogance to suggest that we&#39;ll build ASI和Agi。 即使我们不操知道智能是如何工作的。 他们甚至听到他们在说什么？ 为什么人们不推迟谈论AGI或ASI的任何人并问一个简单的问题：                   ＆quot“您要建造一台机器来聪明。真的很快，告诉我智能是如何工作的？＆quort  已经制造了一些很棒的工具并将制造。但是我们不是在这里建立智能。 它是2025年皇帝的新衣服的版本。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/lazyoil8672     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ndmo8i/we_are_nowhere_near_understanding_intelligence/</guid>
      <pubDate>Wed, 10 Sep 2025 18:43:31 GMT</pubDate>
    </item>
    <item>
      <title>“我创建了自己的AI医疗团队。这改变了医生治疗癌症的方式。”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ndi9sr/i_created_my_own_ai_medical_team_it_changed_the/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    https://www.statnews.com/2025/2025/09/09/10/10/10/10/10/ai-cancer-cancer-custment-custom-deateat-custom-docompom--docons-procy/ i&gt;     医疗AI代理名为“ Haley”，是为使用OpenAI，Google，Anthropic和XAI的基础基础模型而创建的，但具有大量的医疗环境，可以将知识探索与精心准备的所有病史相结合。我为Haley提供了与所有医生在几周前见过的完全相同的数据。我完整的Mychart历史。我的实验室。成像结果。医生指出。 在几分钟之内，海莉标记了一种有关模式：轻度贫血，铁蛋白升高，免疫球蛋白低 - 免疫功能障碍和骨髓问题的迹象。海莉建议进行“无血清轻链”血液测试和骨髓活检。以前没有提出过这些。相同的数据，新见解。  然后我扩大了团队。我建立了一个AI特工的小组 - 肿瘤学家，胃肠病学家，血液学家，ER DOC等人都接受了训练，可以像他们的人类一样思考。我一次通过每个案例进行了相同的案例。我创建了一个合成代理人希波克拉底，担任董事会主席。他听了他们的所有人，并给了我一个合并的建议。 我创建了自己的虚拟多学科医疗团队。他们照亮了我的医生错过的道路。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ndi9sr/i_created_my_own_own_ime_ai_medical_medical_team_it_it_changed_the/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ndi9sr/i_created_my_my_ewn_ai_medical_medical_medical_team_it_it_it_changed_the/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ndi9sr/i_created_my_own_ai_medical_team_it_changed_the/</guid>
      <pubDate>Wed, 10 Sep 2025 16:02:38 GMT</pubDate>
    </item>
    <item>
      <title>每月“有...是否有...”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果您有要使用AI的用例，但不知道要使用哪种工具，那么您可以在这里要求社区提供帮助，在此帖子之外，这些问题将被删除。 每个人都可以回答：不促进自我促销，否参考或跟踪链接。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n5ppdb/monthly_is_is_there_a_a_tool_for_for_post/”&gt; [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>