<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的方方面面提供一个门户，并促进有关我们所知的人工智能思想和概念的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、如何开发人工智能/机器学习项目、商业中的人工智能、人工智能如何影响我们的生活、未来可能的发展方向以及许多其他主题。欢迎。</description>
    <lastBuildDate>Wed, 08 Jan 2025 01:09:47 GMT</lastBuildDate>
    <item>
      <title>您对人工智能监管有何看法？（企业相关）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hw7dpd/whats_your_take_on_ai_regulation_enterprise/</link>
      <description><![CDATA[我很好奇社区对人工智能监管的想法。随着对治理、合规框架的讨论越来越多（喜欢随着人工智能逐渐成为一种趋势，例如人工智能的监管（例如，ISO 42001）以及全球范围内不断出台的新政府政策，您认为我们需要对人工智能进行正式监管吗？还是该行业应该保持自治？ 我还想知道您的工作场所或您参与的任何人工智能项目是否已经在解决人工智能监管问题。这些讨论是否在您的团队中进行，还是这个话题还没有引起人们的注意？如果您有任何见解或经验，我很乐意听听！  您相信严格的人工智能法规还是更喜欢指导方针？ 人工智能治理是否是您工作中的话题？ 对于开始谈论监管的团队，您可以分享任何最佳实践或轶事吗？  提前感谢您分享您的观点！    提交人    /u/Natural_Photograph16   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hw7dpd/whats_your_take_on_ai_regulation_enterprise/</guid>
      <pubDate>Wed, 08 Jan 2025 01:02:53 GMT</pubDate>
    </item>
    <item>
      <title>使用 NER 准确检测幻觉</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hw6r7b/accurate_hallucination_detection_with_ner/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hw6r7b/accurate_hallucination_detection_with_ner/</guid>
      <pubDate>Wed, 08 Jan 2025 00:32:33 GMT</pubDate>
    </item>
    <item>
      <title>人类会对医疗影像领域的人工智能进行事实核查吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hw3fc4/do_humans_factcheck_ai_in_healthcare_imaging/</link>
      <description><![CDATA[这是具体的，但我收到一封电子邮件，说我去的一家影像中心正在使用人工智能，我想避免这种情况，除非我知道有医学学位的人至少会仔细检查影像。这听起来像是它可能会意外错过一些严重的事情并夺走某人的生命。    提交人    /u/idklol5000   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hw3fc4/do_humans_factcheck_ai_in_healthcare_imaging/</guid>
      <pubDate>Tue, 07 Jan 2025 22:05:07 GMT</pubDate>
    </item>
    <item>
      <title>有任何“免费”的语音克隆吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hw1jgr/any_free_voice_cloning/</link>
      <description><![CDATA[如果这是一个重复出现的问题，请原谅，但是是否有任何免费的语音克隆工具可供我上传语音笔记，并让生成的语音响应我写的任何文本？    提交人    /u/Mean_While_1787   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hw1jgr/any_free_voice_cloning/</guid>
      <pubDate>Tue, 07 Jan 2025 20:46:19 GMT</pubDate>
    </item>
    <item>
      <title>您对新的 Nvidia Project Digits 有何看法？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hw19bo/what_do_you_think_about_the_new_nvidia_project/</link>
      <description><![CDATA[Nvidia 刚刚公布了项目数字，据他们说这将是一台个人 AI 超级计算机，成本将从 3,000 美元起。 我认为这是一款不错的 Nvidia 产品，但至少现在超出了我的预算，我希望随着时间的推移它的价格会下降。 我想知道你们现在用什么来构建 AI 原型或运行 AI 模型？ https://nvidianews.nvidia.com/news/nvidia-puts-grace-blackwell-on-every-desk-and-at-every-ai-developers-fingertips    提交人    /u/Halcon_ve   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hw19bo/what_do_you_think_about_the_new_nvidia_project/</guid>
      <pubDate>Tue, 07 Jan 2025 20:34:40 GMT</pubDate>
    </item>
    <item>
      <title>当公司发现人工智能 95% 以上的准确率的成本高于普通人类员工 99% 以上的准确率时，会发生什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hvx5v0/what_happens_when_corporations_discover_that_95/</link>
      <description><![CDATA[OpenAI 的 o3 最近发布，引发了通用人工智能 (AGI) 已经到来的谣言。要将准确率从 75% 提高到 85%，需要将成本提高 10 倍才能实现这一结果。 鉴于许多员工的准确率有望达到 99-100%，雇主似乎必须满足相当高的成本曲线才能真正取代许多工人……或者我猜他们只能接受由于效率低于肉人而导致的成本增加。 我们是否应该预期官僚主义的增加，这是因为所有东西都必须由肉体审查员进行审查，然后跟进稍微准确一些的 AGI？我们是否应该预期某些行业会发现 AI 的运行成本比肉体员工更高？    提交人    /u/jennixred   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hvx5v0/what_happens_when_corporations_discover_that_95/</guid>
      <pubDate>Tue, 07 Jan 2025 17:46:01 GMT</pubDate>
    </item>
    <item>
      <title>2025 年人工智能将失败？专家呼吁权力下放以避免灾难？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hvv1xz/ai_failures_by_2025_expert_calls_for/</link>
      <description><![CDATA[刚刚读了一篇福布斯文章，作者是 Max Li 博士（OORT 首席执行官），文章中讨论并预测，如果发展仍然过于集中（想想所有主要公司），AI 故障可能在 2025 年开始出现。 随着 AI 发展呈指数级增长，他认为，去中心化的方法，即使用区块链或分布式网络，可能会支持过度集中系统的风险，同时还可以提高整体透明度。 对这个话题有什么看法？这一切都是实用的还是只是炒作？    提交人    /u/Mattie_Kadlec   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hvv1xz/ai_failures_by_2025_expert_calls_for/</guid>
      <pubDate>Tue, 07 Jan 2025 16:18:54 GMT</pubDate>
    </item>
    <item>
      <title>没人谈论这个...</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hvukgb/nobodys_talking_about_this/</link>
      <description><![CDATA[在 Devin 热潮之后，不可避免地发现这主要是炒作，我开始思考所有这些新的 AI 代理是如何专注于工人阶级任务的，例如会计、编码、写作和库存艺术品……而不是 CEO 等高管职位。你会看到像 Altman 先生这样的人接受采访，向“博士级员工”推销每月 2000 美元的补贴，这很好，但该工具似乎只是高层管理人员用来证明裁员合理性的工具。 没有人谈论的事情只是……为什么不制作执行代理？你在软件开发中看到的 LLM 的问题和致命错误实际上似乎与 CEO 的美德非常吻合。虽然幻觉在代码中是不好的，但当 CEO 试图说服投资者参与一项风险投资时，自信地说出听起来不错的话是净积极因素。我们大多数人都不是高管，因此，如果软件开发人员的项目只需要一个 AI C-Suite 代理，就可以帮助他们获得资金而无需经历所有步骤，那么这对软件开发人员来说难道不是最好的选择吗？    提交人    /u/enspiralart   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hvukgb/nobodys_talking_about_this/</guid>
      <pubDate>Tue, 07 Jan 2025 15:58:27 GMT</pubDate>
    </item>
    <item>
      <title>对于实施能够取代人类工人的人工智能软件的 IT 专业人员来说，这是一个道德问题</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hvu5t4/a_moral_question_for_it_professionals/</link>
      <description><![CDATA[我的主要问题是：公司自动化负责人的立场是什么，尤其是当自动化通常会导致完全取代工作时？我的意思是，我们还没有明确的 UBI（全民基本收入）前景，或者充其量，一个全新的经济模式。我们是否会继续保持我们的竞争精神，相信强者将生存？这不是一个非常乐观的前景。举一个实际的例子，你是一名 IT 人员，在呼叫中心实施人工智能软件，那里的许多员工都是有孩子的单身母亲，但她们突然失去了工作。 说实话，再培训其他职位似乎也不可行，因为大多数人没有智力能力将自己教育到如此高的水平以从事更专业的工作，这绝对不是他们的错。有些人擅长体力劳动，但可能难以完成智力任务，而另一些人在这两方面都不擅长。这只是短期观点，因为随着时间的推移，大多数工作最终都会实现自动化。 我们无法放慢脚步，为未来做好充分的准备，这非常可怕，因为其他人——无论是个人、公司还是国家——都会在进步中超越我们。目前，似乎大多数人都相信这种情况会以某种方式自行解决。但如果没有呢？我们看到的不是合作精神和对他人的关心，而是对个人或国家利益的关注。这更有可能导致阶级和国家之间出现巨大分歧的独裁反乌托邦，而不是世界范围的乌托邦。    提交人    /u/Goanny   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hvu5t4/a_moral_question_for_it_professionals/</guid>
      <pubDate>Tue, 07 Jan 2025 15:40:35 GMT</pubDate>
    </item>
    <item>
      <title>我曾经很纠结于如何确定任务的优先顺序......</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hvs9j7/i_used_to_struggle_with_prioritizing_tasks/</link>
      <description><![CDATA[老实说，我一直很难确定任务的优先顺序。你知道该怎么做：我会列一个清单，然后被要做的事情的数量压得喘不过气来，然后因为不知道从哪里开始而拖延。 今年，我尝试了一些不同的东西。我没有坚持使用传统的待办事项清单（说实话，它只是列出事情），而是开始使用人工智能来倾听我的目标并将它们组织成可管理的顺序。 因此，人工智能不再只是写“完成项目 X”，而是帮助我将其分解为编写大纲、研究来源和起草介绍等步骤。这就像有一个私人助理随时指导我下一步。我不再浪费时间思考先做什么或接下来要处理哪个任务。这不是拥有一个花哨的工具，而是拥有一个真正理解你想要实现的目标并为你组织起来的简单系统。虽然有时我仍然需要规范计划的一些细节，但我认为在有了这些经验之后，将来我可以自己完成这一步！ 我知道对于许多智慧来说这只是一个小小的提示。但是......自从我开始使用这种方法以来，我一直在更有效地坚持我的目标。我想知道是否有更有效的提示来帮助你完成你的待办事项？    提交人    /u/No-Tax-1444   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hvs9j7/i_used_to_struggle_with_prioritizing_tasks/</guid>
      <pubDate>Tue, 07 Jan 2025 14:11:41 GMT</pubDate>
    </item>
    <item>
      <title>人工智能社区存在盲点，而且情况越来越糟</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hvp13s/the_ai_community_has_a_blindspot_and_its_getting/</link>
      <description><![CDATA[最近有件事困扰着我：当我们在这里讨论最新的人工智能发展时，大量从事全球卫生、发展和人道主义工作的专家却选择不参与人工智能。 想想看：那些在解决复杂的全球挑战、处理道德困境和在不同文化背景下实施解决方案方面拥有数十年经验的人却置身于人工智能革命之外。他们的专业知识正是我们确保人工智能以造福人类的方式发展所需要的。 但是我们的言论正在把他们赶走。当每个头条新闻都在大肆宣扬失业、偏见和机器人霸主时，我们能责怪他们决定人工智能不值得他们花时间吗？ 讽刺的是：由于担心道德和偏见而回避人工智能，这些专家实际上更有可能使人工智能发展缺乏解决这些问题所需的观点。 你怎么看？我们如何才能让人工智能讨论更吸引科技行业以外专业人士的关注？ [顺便说一下，这里有更多关于这个话题的想法/评论]    提交人    /u/Francetim   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hvp13s/the_ai_community_has_a_blindspot_and_its_getting/</guid>
      <pubDate>Tue, 07 Jan 2025 11:03:35 GMT</pubDate>
    </item>
    <item>
      <title>“NVIDIA 让 Grace Blackwell 出现在每一张办公桌上，触手可及”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hvjgzz/nvidia_puts_grace_blackwell_on_every_desk_and_at/</link>
      <description><![CDATA[CES”NVIDIA 今天发布了 NVIDIA ® Project DIGITS，这是一款个人 AI 超级计算机，可让全球的 AI 研究人员、数据科学家和学生使用 NVIDIA Grace Blackwell 平台的强大功能。 Grace Blackwell AI 超级计算触手可及。 借助 Grace Blackwell 架构，企业和研究人员可以在运行基于 Linux 的 NVIDIA DGX OS 的本地 Project DIGITS 系统上对模型进行原型设计、微调和测试，然后将其无缝部署在 NVIDIA DGX Cloud™、加速云实例或数据中心基础架构上。 这使开发人员能够在 Project DIGITS 上对 AI 进行原型设计，然后使用相同的 Grace Blackwell 架构和 NVIDIA AI Enterprise 软件平台在云端或数据中心基础架构上进行扩展。 Project DIGITS 用户可以访问广泛的 NVIDIA AI 软件库进行实验和原型设计，包括 NVIDIA 中提供的软件开发套件、编排工具、框架和模型NGC 目录和 NVIDIA 开发者门户上。开发者可以使用 NVIDIA NeMo™ 框架微调模型，使用 NVIDIA RAPIDS™ 库加速数据科学，并运行 PyTorch、Python 和 Jupyter 笔记本等常见框架。 为了构建代理 AI 应用程序，用户还可以利用 NVIDIA Blueprints 和 NVIDIA NIM™ 微服务，这些微服务可通过 NVIDIA 开发者计划用于研究、开发和测试。当 AI 应用程序准备好从实验转移到生产环境时，NVIDIA AI Enterprise 许可证可提供 NVIDIA AI 软件的企业级安全性、支持和产品版本。  “NVIDIA 将 Grace Blackwell 放在每一张办公桌上以及每一位 AI 开发人员的指尖上” https://www.investing.com/news/press-releases/nvidia-puts-grace-blackwell-on-every-desk-and-at-every-ai-developers-fingertips-93CH-3799085    提交人    /u/coinfanking   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hvjgzz/nvidia_puts_grace_blackwell_on_every_desk_and_at/</guid>
      <pubDate>Tue, 07 Jan 2025 04:34:41 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI 为杜克大学资助 100 万美元关于人工智能和道德的研究，您有什么想法吗，道德会成为一个日益严重的问题吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hvh59m/openai_funds_1_million_study_on_ai_and_morality/</link>
      <description><![CDATA[OpenAI 正在向杜克大学的一个项目投资 100 万美元，以研究人工智能如何与道德互动。随着人工智能在决策和人类生活中发挥越来越大的作用，道德问题变得至关重要。这项研究旨在将人工智能基于逻辑的系统与复杂的、充满价值观的人类伦理联系起来。 你的想法是什么？人工智能真的能掌握人类道德的细微差别吗？尝试一下是否有风险，或者这是人工智能未来融入社会的必要步骤？我认为这可能是一个真正的问题，这取决于人工智能未来的发展方向。 文章参考： 链接   由    /u/QuantumQuicksilver  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hvh59m/openai_funds_1_million_study_on_ai_and_morality/</guid>
      <pubDate>Tue, 07 Jan 2025 02:32:19 GMT</pubDate>
    </item>
    <item>
      <title>每月“是否有一个工具可以……”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用 AI 的用例，但不知道使用哪种工具，您可以在这里请求社区提供帮助，在此帖子之外，这些问题将被删除。 对于每个回答的人：没有自我宣传，没有参考或跟踪链接。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:09:07 GMT</pubDate>
    </item>
    <item>
      <title>每月自我推销贴</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4l16/monthly_self_promotion_post/</link>
      <description><![CDATA[如果您有产品要推广，可以在这里进行推广，本帖之外的内容将被删除。  禁止引用链接或带有 utms 的链接，请遵守我们的推广规则。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4l16/monthly_self_promotion_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:03:08 GMT</pubDate>
    </item>
    </channel>
</rss>