<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Sun, 13 Jul 2025 09:17:00 GMT</lastBuildDate>
    <item>
      <title>是什么塑造了用户对chatgpt的信任？对用户属性，信任维度，任务的混合方法研究</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lynu1i/what_shapes_user_trust_in_chatgpt_a_mixedmethods/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  让我们探索AI中的重要开发：&#39;是什么塑造了用户对chatgpt的信任？由Kadija Bouyzourn和Alexandra Birch撰写的有关用户属性，信任维度，任务上下文和社会看法的混合方法研究。  这项研究深入研究了影响大学学生对CHATGPT的信任，结合用户属性，各种信任维度，任务环境以及对AI社会影响的看法的因素。以下是研究的关键见解：    用户行为重要：频繁使用chatgpt可以增强用户之间的信任水平。令人惊讶的是，对LLM有更好理解的人表现出越来越多的怀疑主义，强调提高意识的倾向，而不是盲目信任。         任务特异性信任：信任等级：信任等级因任务类型而在诸如娱乐范围内的最高信任度变化，同时又可以娱乐范围，同时又可以娱乐地逐步进行任务，而不是任务范围内的任务范围，而不是任务范围内的任务。值得注意的是，对Chatgpt的引文能力的信任是整体信任的最牢固相关性，说明了潜在的自动化偏见。      信任的维度：信任的最重要预测指标包括可感知的专业知识和伦理风险。诸如易用性和透明度之类的次要因素也发挥了作用，而人类风格对用户信心的影响很小。      社会观念计数：对AI社会影响的积极看法对CHETGPT具有更大的信任。这一发现表明，更广泛的道德考虑和社会意义显着塑造了个人信任评估。     需要透明度的需求：该研究突出了透明度在AI系统中的重要性，以促进信任。参与者表示需要对AI功能和局限性进行更清晰的沟通，尤其是在学术环境中。   这些发现如何重点介绍了对AI的信任如何取决于用户体验，任务的本质和道德考虑，并指出了对ai技术的必要性和负责任的设计。 href =“ https://www.thepromptindex.com/trusting-trusting-the-bot-what-what--what-------------------------------in-chatgpt.html一下&gt;   在此处阅读原始研究论文： &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/strumentlabrador     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lynu1i/what_shapes_user_trust_in_in_chatgpt_a_mixedmethods/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lynu1i/what_shapes_user_trust_in_chatgpt_a_mixedmethods/</guid>
      <pubDate>Sun, 13 Jul 2025 08:29:57 GMT</pubDate>
    </item>
    <item>
      <title>人工智能不会破坏真相？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lynhq9/how_wont_ai_destroy_truth/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  否，实际上。该死的？  AI生成的视频和照片正在进步，变得越来越现实，如果有一段时间，它们与真实图片无法区分怎么办？我们怎么知道什么是真实的？使用AI，这将不适用。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lynhq9/how_wont_ai_ai_destroy_truth/”&gt; [link]    32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lynhq9/how_wont_ai_destroy_truth/</guid>
      <pubDate>Sun, 13 Jul 2025 08:07:19 GMT</pubDate>
    </item>
    <item>
      <title>Grok 4不相信这是2025年，然后认为这是一场噩梦。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lync2u/grok_4_wont_believe_that_its_2025_and_then_thinks/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lync2u/grok_4_wont_believe_that_its_2025_and_then_thinks/</guid>
      <pubDate>Sun, 13 Jul 2025 07:57:26 GMT</pubDate>
    </item>
    <item>
      <title>未成熟的研究领域进行研究？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lylxpq/immature_research_fields_to_conduct_research_in/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好，我想知道人工智能中是否有一些领域还不是很发达或成熟。作为作业的一部分，我需要在此类字段上进行写作，并提出可能的SOTA（甚至不知道这是怎么可能）。感谢帮助！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/plem_read_7020     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lylxpq/immature_research_fields_to_conduct_research_in/</guid>
      <pubDate>Sun, 13 Jul 2025 06:26:19 GMT</pubDate>
    </item>
    <item>
      <title>刚开始我的AI旅程 - 寻找导师或学习伙伴！ - 将投入工作</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lylsm1/just_started_my_ai_journey_looking_for_a_mentor/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我刚刚开始学习AI，我完全迷上了 - 但是我知道我需要正确的指导来避免在所有噪音中迷失。 I&#39;m willing to put in whatever work it takes and dedicate as much time as needed if I can find someone experienced who&#39;s willing to mentor me through this journey. I have a strong foundation in math and problem-solving (scored 99.6 percentile in JEE Advanced), so I can handle the technical stuff, but I need someone who understands how to navigate this field and can point me in the right directions. What I&#39;m offering:  完全奉献学习（我会根据需要进行多个小时） 强大的职业道德和解决问题的技能 愿意在您建议的任何项目或任务上工作的意愿 真正地承诺掌握此领域       我可以帮助我提供的东西：路径 与深度学习和成长有类似心态的人  我相信，我相信拥有合适的导师可以有所作为，我准备证明我值得投入时间。 。 ，如果这与您共鸣并且您对认真认真对待AI的人愿意引起您的共鸣。我很想讨论我们如何一起工作！   tl; dr： AI初学者具有强大的数学背景（JEE中的99.6％）寻求专门的导师。将付诸实践，并从事任何项目。寻找经验丰富的指南，他可以帮助构建我的学习路径。 谢谢！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/adityasrivastawaahhh      [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lylsm1/just_started_my_ai_journey_looking_for_a_mentor/</guid>
      <pubDate>Sun, 13 Jul 2025 06:17:16 GMT</pubDate>
    </item>
    <item>
      <title>建立一个虚构叙事的Al团队</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lyjp3j/building_an_al_team_for_fictional_narrative/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  你好！我对大家有一个奇怪但希望很有趣的问题： 我正在研究一个以两个AL程序员为特色的故事，我需要一些技术细节来实现真实性。成功的AL团队需要什么技术技能？ ＆＃32;提交由＆＃32; /u/u/bizarro1958     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lyjp3j/building_an_al_team_for_fictional_narrative/</guid>
      <pubDate>Sun, 13 Jul 2025 04:13:19 GMT</pubDate>
    </item>
    <item>
      <title>我应该为本科选择什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lyhw0k/what_should_i_choose_for_my_undergrad/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我有兴趣为自己的本科做经济学，但我担心AI会在我的学位结束时使我的工作无用。它也已经这样做了。未来的证明本科生是什么？忘记个人兴趣。我毕业时需要能够找到工作。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/madushakj     [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lyhw0k/what_should_i_choose_for_my_undergrad/</guid>
      <pubDate>Sun, 13 Jul 2025 02:35:02 GMT</pubDate>
    </item>
    <item>
      <title>AI违反了立法假设。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lyhud3/ai_breaks_legislative_assumptions/</link>
      <description><![CDATA[We have many thousands of laws accumulated over decades or even centuries, but they were all written with implicit assumptions about the cost of enforcement. AI turns the cognition required for enforcement into a commodity with a cost per unit cognition, that is trending towards zero. We could create an authoritarian nightmare without even creating new法律，但仅使用实施现有法律的AI。例如，只需考虑我们拥有的所有监视摄像机即可。它们几乎从未被查看过，因为让人们查看它们太贵了，但是AI可以起诉有史以来所有法律的违规行为。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lyhud3/ai_breaks_legislate_assumptions/”&gt; [link]    32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lyhud3/ai_breaks_legislative_assumptions/</guid>
      <pubDate>Sun, 13 Jul 2025 02:32:34 GMT</pubDate>
    </item>
    <item>
      <title>AI实际上现在非常强大。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lyghv1/ai_is_actually_extremely_powerful_right_now/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果系统已标准化，尤其是在数据驱动市场中，AI可以完全自动化整个系统。筒仓团队和环境确实是唯一将AI退回的东西。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/usextern_still_1494     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lyghv1/ai_is_actually_extremely_powerful_right_now/</guid>
      <pubDate>Sun, 13 Jul 2025 01:21:37 GMT</pubDate>
    </item>
    <item>
      <title>AI不会替换开发人员。但是掌握AI的开发人员将取代其余的。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lyccr3/ai_wont_replace_devs_but_devs_who_master_ai_will/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    AI不会替换开发人员。但是掌握AI的Devs将取代其余的。  这是我的看法 - 自从一开始就在包括现实世界中的大量用例中使用Chatgpt和其他AI模型。您仍然必须思考。 您是建筑师。下午。调试器。有远见的人。如果您正确地引导该模型，它将非常强大。但是，如果您期望它为您解决问题 - 您需要进行严格的现实检查。 特别是对于拥有10年以上经验的开发人员：您的直觉和心理模型不会干净地转移。使用AI井需要全面重置您如何解决问题。  这是我使用AI：     与GPT-4O（创造性，快速，快速，灵活） 压力测试的逻辑与GPT O3（更接地）的cons forter for for for for for for gpt-4o（富有创造力，灵活）    实施）  即使是这篇文章，我都将思想脑化成GPT，它有助于清楚地构造它们。这些想法是我的。人工智能只是剥离绒毛并削减逻辑。 那就是它发光的时候 - 作为合作者，而不是拐杖。    示例：本周我正在调试简单的内容：我的MCP服务器的SSE auth。启动前的最后一步。应该花一个小时。花了2天。 为什么？我很懒。我告诉克劳德：“只需重复使用旧代码即可。”克劳德向后推：“我们应该重建它。”我忽略了它。尝试黑客入侵。它失败了。 所以我停了下来。    2.5个小时的深入研究 -  chatgpt，困惑，文档 我自己读了所有内容 - 不仅将其粘贴到模型 我回来了，我回来了，说：干净，工作，完成。 课程？ 首先思考。使用第二个模型。   大多数人仍然像对待魔术一样对待AI。它不是。这是一个工具。如果您不知道如何使用它，它将不会为您提供帮助。 您不会给农民一个拖拉机，并期望在第一天获得10倍的结果。如果他们在镰刀上度过了10年，那么一开始他们会更快。但是从长远来看，学会驱动拖拉机的人会获胜。 与AI相同。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lyccr3/ai_wont_replace_replace_devs_but_but_but_devs_who_master_ai_will/”&gt; [links]       [注释]      ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lyccr3/ai_wont_replace_devs_but_devs_who_master_ai_will/</guid>
      <pubDate>Sat, 12 Jul 2025 22:01:40 GMT</pubDate>
    </item>
    <item>
      <title>🎮我根据AI 2027方案创建了一个基于文本的交互式游戏 - 我正在分享完整的提示</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lyb8tf/i_created_an_interactive_textbased_game_based_on/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   什么是AI 2027？  对于那些没有看过它的人来说到2027年，政策制定者，研究人员和人工智能公司已成为最严格的近期AI预测之一。   游戏概念  我对场景和思想着迷的是：如果您实际上可以通过这些决策进行播放怎么办？顾问将过渡到AGI。  关键特征：  -  现实世界中的整合：使用Web搜索来合并当前的AI新闻和政府官员 -  动态决策树 -  ：您的选择真正地影响了三个主要阶段 - 强度&gt;强度的人类 -  现实的复杂性：平衡技术准确性与引人入胜的游戏玩法 -  角色定制：不同的背景（科学顾问，国家安全等）与独特的能力     样本场景：当新闻临时即时，在新闻中遇到了agi agi，中国威胁性地征服和征服国会的要求。 You have 2 hours to recommend a response that could determine humanity&#39;s future. Three Phases of Gameplay  Crisis Management (Current day - 6 months): Handle immediate AI policy crises based on real current events Acceleration Period (6-18 months): Navigate rapid capability growth and economic disruption   超级智能阈值（18-24个月）：关于人类与AGI/超级智能的关系的最终决定    完整的提示     我已经创建了一个全面的提示，任何AI都可以使用AI来运行这款游戏。它包括： - 具有属性和背景的角色创建系统 - 资源跟踪（国家稳定性，AI安全准备等） - 适应玩家选择的动态时间表 - 通过Web搜索与当前事件相结合 - 现实的决策后果和多个结局    [完整的提示[完整的提示 - 在下面是很长的时间！  AI 2027场景不仅是科幻小说 - 这是一项认真的尝试来绘制现实的近期AI开发。通过赌博这些决策，我们可以： - 更好地了解AI治理的复杂性 - 探索AI安全性和发展的不同战略方法 - 为我们实际上可能面临的各种决策做准备 - 使AI政策讨论更易于访问   ，请尝试一下      迅速与claude，ChatGpt An chatgpt或其他功能相机。只需复制提示，开始对话，然后看看您如何处理人类向超级智能的过渡即可。  您将优先考虑什么？经济稳定？国际合作？技术安全？军事竞争力？没有简单的答案，这就是重点。&lt; /p&gt;   其他人是否在这样的AI场景计划中玩过？我很想听听其他方法通过互动经验来探索这些关键决策的方法。   链接到AI 2027方案：   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lyb8tf/i_created_an_interactive_interactive_textbased_game_game_based_on/&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lyb8tf/i_created_an_interactive_textbased_game_based_on/</guid>
      <pubDate>Sat, 12 Jul 2025 21:11:08 GMT</pubDate>
    </item>
    <item>
      <title>论文：基础模型可以真正学习深层结构吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ly8upg/paper_can_foundation_models_really_learn_deep/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  作者测试基础模型是否形成了现实世界的归纳偏见。使用合成的“归纳偏见探测”，“ quot”他们发现指甲轨道 - 区域训练仍然无法在新任务上应用牛顿力学。这些模型仅找到数据相关性，但无法找到一般说明。  https：//arxiv.org/abs/2507.06952    [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ly8upg/paper_can_foundation_models_really_learn_deep/</guid>
      <pubDate>Sat, 12 Jul 2025 19:26:55 GMT</pubDate>
    </item>
    <item>
      <title>为什么旨在为任何文本提供完美平均延续的软件能够帮助研究新想法？更不用说导致Agi了。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ly7ih1/why_would_software_that_is_designed_to_produce/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这是一个显而易见的点，以至于它很奇怪，以至于在reddit上从未发现。 Yann Lecun是我见过的唯一公众人物，即使这是每个人都知道的。 我知道他们可以为数学问题等产生潜在的解决方案，然后在获胜的解决方案上训练模型。那是每个人都在赌什么吗？如果您让某人说与解决特定问题的人相同的话，那么解决问题的能力就可以“擦掉”吗？  似乎很荒谬。想象一下告诉孩子重复与他们更聪明的同学相同的单词，并期望成绩会有所提高，而不是期望一个听起来像他在模仿别人的困惑的孩子。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/sad_run_9798     [link]    [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ly7ih1/why_would_software_that_is_designed_to_produce/</guid>
      <pubDate>Sat, 12 Jul 2025 18:30:13 GMT</pubDate>
    </item>
    <item>
      <title>AI的未来可能是本地</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lxz5z5/the_future_of_ai_might_be_local/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  到2027年，随着公司逐步淘汰免费级别并实施严格的用法上限，预计Premium AI订阅每月达到50-100美元。  我们时不时地被新的AI模型轰炸。在2023  -  24年期间，我认为尽管拥有大量资源，但Google仍落后于AI竞赛。现在，在2025年，他们似乎回到了游戏中。此外，诸如Claude Opus 4之类的最新功能模型的版本没有像以前模型相对于早期模型的差异而产生的炒作。实际上，我尚未发现到目前为止使用它的必要性，并且我对Claude 3.7或Windsurf上的Gemini 2.5 Pro感到非常满意。  OpenAi据报道，每天都会通过$ 700,000+每天燃烧，只是为了保持ChatGpt的运行，而他们的计算成本随着模型复杂性的增加而继续攀升。他们希望到2030年左右能够达到盈利能力，但我怀疑这一点。他们没有任何独特的优势，例如Google或Facebook曾经拥有的，这将证明对盈利能力图的巨大损失是合理的。在DeepSeek发行期间，这更清楚。包括我在内的大量人开始使用它，因为它便宜得多。  几天前，我遇到了一个X帖子，显示一个国家是如何使用Nvidia Jetson Orin作为其无人机的大脑的。这意味着随着时间的流逝，本地LLM的使用将增加，如果芯片技术取得突破，则它将加速。智能手机还可能带有可以处理足以用于编写文本，分析图像等基本任务的本地LLM的芯片。他们辛勤工作的果实将被其他人消耗。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/alvi_skyrocketbpo      [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lxz5z5/the_future_of_ai_might_be_local/</guid>
      <pubDate>Sat, 12 Jul 2025 12:23:28 GMT</pubDate>
    </item>
    <item>
      <title>如果中国首先到达AGI会发生什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lxz3cq/what_would_happen_if_china_did_reach_agi_first/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  美国公司的几乎教条言论是中国取得了成功或达到AGI（但是您可以定义这一点）绝对是最糟糕的事情。这种信念是驱动我们目前正在看到的所有危险中的所有危险的突破性速度实践。 ，但这实际上是真的吗？我们（西方世界）实际上并不了解中国除自己人民以外的真正意图。为什么有这样的假设是他们会使用AGI到什么 - 成为全球霸权？这不是确切的OpenAI，Google或XAI打算做什么？他们怎么会更好？ 这就是“没有人应该拥有那么多的力量。但是，如果我这样做了，那就可以了。”我似乎无法理解的傲慢。美国AI公司的财务支持者拥有巨大的财富，但在道德上显然是破产的。我并不确信，与中国领先的模型相比，ChatGpt具有快速起飞的未来或多或少具有反乌托邦的潜力。 ai 尽管美国基本上没有到位。 有人请解释说，公众应该担心中国赢得AI ARM RACE的恐惧是什么？人们是否认为他们想将世界其他地区征服到社会信用评分系统中？有什么证据吗？ 哪些场景处于危险之中，如果美国赢得胜利也不会有风险？当您考虑像Palantir这样的公司以及像Curtis Yarvin和Peter Thiel这样的人的意识形态时。 我读到的越多，我越认为未来，我实际上就越来越难以开放的公司。   &lt;！ -  sc_on--&gt;＆＃32;提交由＆＃32; /u/u/asovereignstory    href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lxz3cq/what_would_happen_china_china_china_did_reach_agi_first/  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lxz3cq/what_would_happen_china_china_china_china_did_reach_agi_first/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lxz3cq/what_would_happen_if_china_did_reach_agi_first/</guid>
      <pubDate>Sat, 12 Jul 2025 12:19:44 GMT</pubDate>
    </item>
    </channel>
</rss>