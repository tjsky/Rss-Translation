<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Fri, 05 Sep 2025 18:19:23 GMT</lastBuildDate>
    <item>
      <title>约翰尼5还活着！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n9ckex/johnny_5_is_alive/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在1985年经典短路中，由史蒂夫·古腾堡（Steve Guttenberg）和艾莉·希迪（Ally Sheedy）主演，机器人约翰尼5（Johnny 5  在整整整整整夜都无法解决我现在意识到的是一个复杂而备受争议的哲学问题之后，克罗斯比（Crosby）对使用幽默的想法进行了打击。只有感人或“活着”他的原因，众生会理解幽默，所以他告诉约翰尼5一个愚蠢的笑话。当Johnny 5考虑一下然后大笑时，Crosby得出结论，Johnny 5实际上还活着。  很好。我最近想到了这个场景，在我看来，像Gemini，Grok和Chatgpt这样的现代AI可以很容易地理解幽默。他们可以用令人难以置信的细节来描述一个给定的笑话有那么有趣的东西，甚至可以确定即使您不告诉他们，提示也是一个笑话。而且，如果您告诉他们以笑声对幽默做出回应，他们肯定会。  这是否意味着现代AI还活着？或者，就像其他很多时候一样，史蒂夫·古腾堡（Steve Guttenberg）充满了狗屎吗？ （这是这篇文章的错误sub？AI的哲学含义更好地留给了哲学上的subreddits吗？提交由＆＃32; /u/u/u/u/lostebetsred      [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n9ckex/johnny_5_is_alive/</guid>
      <pubDate>Fri, 05 Sep 2025 18:09:49 GMT</pubDate>
    </item>
    <item>
      <title>如何检测深层的假实时新闻广播。我只是密集还是使用我的软件想法发现了一个假新闻频道？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n9b4hn/how_to_detect_deep_fake_live_news_broadcasts_am_i/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n9b4hn/how_to_detect_deep_fake_live_news_broadcasts_am_i/</guid>
      <pubDate>Fri, 05 Sep 2025 17:14:49 GMT</pubDate>
    </item>
    <item>
      <title>UBI（通用基本收入）可能没有发生。什么是选择？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n9a3il/ubi_universal_basic_income_probably_isnt/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  所有关于UBI需求的谈话对我来说都是幽默的。至少在美国，我们并没有真正互相支持，除了征收税收以满足我们使用的社区需求或所有人所用的东西。工作裁员正在左右发生，有些人呼吁UBI。安德鲁·杨（Andrew Yang）竞选总统时提到了这个概念。我只是看不到它发生。您对另一种选择有何看法？ AI是否创造了丰富的商品和服务，降低了上述商品和服务的成本，以使其更实惠？我们使用AI的税务公司吗？税收收入将在哪里？想法？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/minuse injury3471     [link]       [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n9a3il/ubi_universal_basic_income_probably_isnt/</guid>
      <pubDate>Fri, 05 Sep 2025 16:36:00 GMT</pubDate>
    </item>
    <item>
      <title>开源我的设计以进行同行评审</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n99mhp/open_sourcing_my_design_for_peer_review/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n99mhp/open_sourcing_my_design_for_peer_review/</guid>
      <pubDate>Fri, 05 Sep 2025 16:17:56 GMT</pubDate>
    </item>
    <item>
      <title>为什么LLM听起来像中立和公正？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n965o2/why_do_llms_sound_as_neutral_and_unbiased_as_they/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  当互联网上有太多的伪科学内容时，LLM为什么不经常发出伪科学的想法？另外，为什么他们的观点并不经常宗教信仰，有很多基督教和穆斯林内容  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/feens-ateention664     [links]      &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/comments/1n965o2/why_do_do_do_llms_sound_as_neutral_andral_and_unbiased_as_as_they/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n965o2/why_do_llms_sound_as_neutral_and_unbiased_as_they/</guid>
      <pubDate>Fri, 05 Sep 2025 14:03:48 GMT</pubDate>
    </item>
    <item>
      <title>毫不奇怪，OpenAI启动了工作委员会和官方认证</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n950qd/unsurprisingly_openai_launch_a_job_board_and/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  因此，OpenAi刚刚启动了“认证”以进行AI流利。从表面上看，它看起来像是一件好事。训练人们，给他们一个徽章，将他们与工作联系起来。   链接到文章    ，但是...首先，它肯定是先发的声誉管理吗？他们知道自动化将消除很多角色，并且需要指出反弹何时出现的东西。 “我们摧毁了2000万个工作，但是，嘿，看，我们建立了一个工作委员会并签发了证书。”  其次，如果我愤世嫉俗，那是关于拥有生态系统。如果您想证明自己是“ AI准备就绪的”，并且重要的徽章经过Openai认证，那么您将投入他们的工具和工作流程。 Google与数字车库和云证书一起运行。如果他们定义了标准，其他所有人都在争先恐后地追赶。 第三，这对于监管机构和大公司来说是很棒的。沃尔玛，BCG，州政府……所有名字都掉了。这使得在议员们提出棘手问题的确切时间看起来主流和负责。 不要说认证是没有用的。它可能会成为雇用的默认凭据。但这与分销和市场捕获一样多，与帮助工人一样。 好奇别人的想法。您实际上会在简历上列出“ OpenAi认证”？还是感觉就像是将人们更深入产品融入产品的另一种方式？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/paddy-makk     [link]    [注释] ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n950qd/unsurprisingly_openai_launch_a_job_board_and/</guid>
      <pubDate>Fri, 05 Sep 2025 13:16:55 GMT</pubDate>
    </item>
    <item>
      <title>不受欢迎的意见：AI已经完成了指数改进阶段</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n94kgp/unpopular_opinion_ai_has_already_completed_its/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  你知道我的意思。从诺基亚到前几个iPhone版本，手机的指数改进。未来旅行十年的人将被新能力吹走。现在，最新的手机很漂亮，“ meh＆quot”，没有人真的很惊讶了。该阶段已经过去了。 对于电视，计算机游戏图形，甚至汽车，相同。有令人难以置信的飞跃，但是一旦将它们做出了，一切都变得更加渐进。 我的论点可能是AI已经发生了。令人印象深刻的东西已经在这里。 Generative AI无法获得比现在更大的内容 - 非常现实的视频，撰写文章等。当然，它可能会从短片段到整部电影，但这不一定是一个很大的飞跃。 这不是我无法动摇的观点，只是我最近想知道的一个概念。你怎么认为？如果这是错误的，那么下一个可以去哪里？ 已经编辑：所以我绝对是该领域的非专家。如果您不同意，您期望它如何呈指数级改进，以及什么结果？它将有什么能力，如何？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n94kgp/unpopular_opinion_ai_ai_ai_already_completed_its/”&gt; [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n94kgp/unpopular_opinion_ai_has_already_completed_its/</guid>
      <pubDate>Fri, 05 Sep 2025 12:57:41 GMT</pubDate>
    </item>
    <item>
      <title>项目帮助</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n94ces/project_help/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  有没有任何人“面试那是建造/建造了AI招聘人员吗？与聊天机器人类似，但在人类看到它之前恢复过滤。在接下来的几周中，我将为AI招聘和招聘算法编译信息，并可以使用该领域某人的一些利弊。 谢谢！   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/Illrepresentative209     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n94ces/project_help/</guid>
      <pubDate>Fri, 05 Sep 2025 12:47:31 GMT</pubDate>
    </item>
    <item>
      <title>我应该如何改变生活以为ASI/奇异性做准备？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n92w7p/how_should_i_change_my_life_to_prepare_for/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我在20多岁的时候，最近我一直在努力思考未来。如果人工超级智能即将到来，我应该这样做？ 感觉有点像接受后期诊断。就像我为自己想象的未来（职业，长期计划，个人目标）不再重要，因为一切都可能彻底改变。我什至应该打扰建立长期的职业吗？ 我的一部分觉得也许我应该专注于接下来的几年（旅行，人际关系，经验），因为一切都可能很快大不相同。但是我的另一部分担心我只是避免责任。 好奇别人如何看待这一点。您是否计划自己的生活，好像世界将保持相对“正常”，还是考虑了快速，改变世界的AI发展的可能性？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n92w7p/how_should_should_should_should_imy_my_my_my_life_to_to_prepare_for/&gt; [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n92w7p/how_should_i_change_my_life_to_prepare_for/</guid>
      <pubDate>Fri, 05 Sep 2025 11:39:30 GMT</pubDate>
    </item>
    <item>
      <title>集成到社交媒体平台中的AI聊天机器人非常奇怪。他们避免了“争议”，​​以至于无法得出基本道德事实</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n9073d/ai_chatbots_integrated_into_social_media/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这是来自Snapchat AI对话的屏幕截图，当时我的一个朋友指出，AI聊天机器人，尤其是在社交媒体平台上集成的AI聊天机器人，将拒绝避免争议的道德，其中包括对Genocide或谋杀是否不好的问题和干燥的问题。非常奇怪。   https://imgur.com/a/a/2h9v2ty      &lt;！ -  sc_on-&gt; 32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n9073d/ai_chatbots_integrated_into_into_social_media/”&gt; [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n9073d/ai_chatbots_integrated_into_social_media/</guid>
      <pubDate>Fri, 05 Sep 2025 09:03:59 GMT</pubDate>
    </item>
    <item>
      <title>英语能否使LLM训练更昂贵？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n8yky8/could_english_be_making_llms_more_expensive_to/</link>
      <description><![CDATA[What if part of the reason bilingual models like DeepSeek (trained on Chinese + English) are cheaper to train than English-heavy models like GPT is because English itself is just harder for models to learn efficiently? Here’s what I mean, and I’m curious if anyone has studied this directly: English is irregular.拼写/发音不排队（“虽然”，“硬”，“通过”）。诸如“溢出豆子”之类的成语仅是上下文。这增加了模型解码的噪声。 令牌效率低下。用英语，长话常常被分为多个子字代币（“难以置信的” un / believ / able），而汉字通常具有完整的语义含义并保持单一令牌。较少的令牌=较少的计算。 语义模棱两可。英语单词有很多含义； “设置”具有400多个定义。这可能会增加更多的培训开销 混乱的互联网数据。英语语料库（Reddit，Twitter，Forums）很大，但混乱。一些中国模型可能会接受更精心策划或统一的来源培训，LLM更容易消化？ ，也许不仅与硬件，模型架构或培训技巧有关，也许语言本身会影响昂贵的培训？ 不声称自己是专家，只是奇怪的。很想听听任何从事多语言LLM或令牌化的人的想法。 编辑：我认为解决方案是要求Chatgpt制作一种新的，更有效的语言  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/upzzled-ad-1939     [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n8yky8/could_english_be_making_llms_more_expensive_to/</guid>
      <pubDate>Fri, 05 Sep 2025 07:16:21 GMT</pubDate>
    </item>
    <item>
      <title>克劳德·奥普斯（Claude Opus）使我免于发送一封狂欢的工作电子邮件，我非常感谢。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n8sk6y/claude_opus_saved_me_from_sending_a_cringe_work/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  今天，我有一个我很少有的时刻之一。一个享有声望的组织给我写信告诉我，他们正在考虑我的项目，以获取一个排队的机会，而我使用Opus来解决我非常具体和技术的电子邮件对话的回答。几天没有收到他们的消息后，我要求Opus写一封后续电子邮件，其中包含无需任何人要求的信息和其他争论，而Opus直截了当地告诉我不要这样做，因为我看起来很拼命且不专业，并建议我等待。它阐明了我不应该发送电子邮件的原因，这是对的。我对此给我留下了深刻的印象，因为我没有向它寻求有关是否应该发送的建议；它只是告诉我不要写它。我已经使用Opus大约一个月了，但我认为它只是我最喜欢的LLM。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/jpirizarry   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n8sk6y/claude_opus_saved_me_from_sending_a_cringe_work/  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n8sk6y/claude_opus_saved_me_from_sending_sending_a_cringe_a_cringe_work/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n8sk6y/claude_opus_saved_me_from_sending_a_cringe_work/</guid>
      <pubDate>Fri, 05 Sep 2025 01:45:39 GMT</pubDate>
    </item>
    <item>
      <title>我读过100多个“企业AI安全评估”。他们都在问错误的问题。这是证明。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n8l0ej/ive_read_100_enterprise_ai_security_assessments/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   两年的AI公司自动化了合规性，教会我一些混乱的东西。 没人知道如何评估AI安全性。不是企业。不是供应商。不是安全团队。每个人都只是在翼。 2019年。这些都是从上周开始的。 ，但他们从不询问及时注射漏洞，训练数据中毒，模型窃取攻击，对抗性输入，后门触发器，数据谱系和amp;出处。跨越100多个问卷。没有一个问题真正质疑AI风险。 我有一个客户建造医学诊断AI。 500个问题安全审查。他们对访客徽章和干净的办公桌政策有疑问。  另一个可以误诊患者的对抗攻击。经过数周的记录密码策略，他们永远不必谈论如何处理可以投资的模型操作。 安全团队不了解AI架构。因此，他们使用2015年以来的SOC 2问卷。加上“ ai”。随机。运送它。 很少有AI团队不了解安全性。因此，他们组成了答案。每个人都点点头。  与之检查的框，同时，实际AI每天都有繁殖。 修复程序确实存在 - 尽管还没有很多公司要求它。 ISO 42001是了解AI和安全性的人编写的第一个框架。它询问模型风险，而不是服务器房间。数据谱系，而不是数据中心。算法偏见，而不是密码复杂性。 ，但大多数公司都没有听说过。仍在发送问卷调查，询问我们“身体上的安全”数学方程式。 当AI失败发生时，我害怕的是 - 这些公司将意识到他们的“全面安全评论”什么也没评估。他们正在所有错误的地方寻找风险。实际AI风险与我们评估的内容之间的差距是巨大的。老实说，在与这么多的AI本土公司合作时，这种情况正在迅速发展。 您采用了什么？企业实际上是正确评估AI，还是每个人都假装？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/rluna559     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n8l0ej/ive_read_100_enterprise_ai_security_assessments/</guid>
      <pubDate>Thu, 04 Sep 2025 20:19:29 GMT</pubDate>
    </item>
    <item>
      <title>ai>老师？呼唤废话。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n8kf7t/ai_teachers_call_bullshit/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   pew说，三分之一的专家认为AI会削减教学工作。 ，但教学不仅仅是内容交付；当然，它是信任，关怀和人类的存在。 可以帮助使用工具。但是，如果我们认为它可以取代老师，那么我们从大流行中学到什么都没有学到。 来源： https://abcnews.go.com/po..com/pol.com/amp/politics/politics/Artaver-Intelligence-intelligence-intelligence-redelligence-replace-teachers/steachers/steachers/steacher/store/store/story/story？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/calliope_kekule     [link]    32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n8kf7t/ai_teachers_call_bullshit/</guid>
      <pubDate>Thu, 04 Sep 2025 19:56:49 GMT</pubDate>
    </item>
    <item>
      <title>每月“有...是否有...”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果您有要使用AI的用例，但不知道要使用哪种工具，那么您可以在这里要求社区提供帮助，在此帖子之外，这些问题将被删除。 每个人都可以回答：不促进自我促销，否参考或跟踪链接。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n5ppdb/monthly_is_is_there_a_a_tool_for_for_post/”&gt; [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>