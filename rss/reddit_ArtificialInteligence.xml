<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Fri, 22 Aug 2025 06:23:13 GMT</lastBuildDate>
    <item>
      <title>哈维尔·米利（Javier Milei）的政府将监视与AI的社交媒体，以“预测未来犯罪”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mwyvjn/javier_mileis_government_will_monitor_social/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mwyvjn/javier_mileis_government_will_monitor_social/</guid>
      <pubDate>Fri, 22 Aug 2025 06:19:23 GMT</pubDate>
    </item>
    <item>
      <title>关于AI和人类的世界的想法？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mwye4u/thoughts_on_ai_and_human_based_world/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mwye4u/thoughts_on_ai_and_human_based_world/</guid>
      <pubDate>Fri, 22 Aug 2025 05:50:21 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻8/21/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mwxc48/oneminute_daily_ai_news_8212025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;      meta 将刹车放在其巨大的AI人才支出狂潮中。[1]  中文AI ai ai starp  deepseek  deepseek 以家用chip support升级的模型。宣布使用AI来增强游戏日分析的多年合作伙伴关系。[3]  有线和业务内部人士通过AI生成的“自由职业者”删除文章。[4]    源href =“ https://bushaicave.com/2025/08/21/oone-minute-daily-daily-daily-ai-news-8-21-2025/”&gt; https：//bushaicave.com/2025/08/08/21/one-news-daily-news-news-news-news-8-21-11-11-21-11-11-21-21-21-21-21-25/--  [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mwxc48/oneminute_daily_ai_news_8212025/</guid>
      <pubDate>Fri, 22 Aug 2025 04:49:46 GMT</pubDate>
    </item>
    <item>
      <title>AI编码不是实际编码更有用的技能</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mwwqu9/ai_coding_is_not_a_more_useful_skills_than_actual/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  似乎这些论坛完全是关于吹嘘自己的AI工作流程多么复杂的人。关于他们的上下文如何提出Claude代码的合法技能。我就像还好吗？这比在C ++中学习游戏开发或编写数据库或学习内存管理更为复杂吗？ 这等同于设置开发人员已经知道该怎么做的开发工作流程和环境。设置Claude代码是否比通过自定义配置和工作流程设置Neovim更复杂？可能不是。 那么，您知道克劳德代码是这项疯狂的新技能，从本质上讲，您只需在整个地方都有文本文件。归根结底，它只是以非确定性的方式生成了一堆代码。或者充其量只是成为一种花式的自动完成，因为您已经限制了模型如此之多，以至于无论如何您还是只要自己编码所有内容。 ，看来只有非编码器似乎只包含Vibe编码。同时，我去了与开发人员有关的论坛，并且有清理错误的恐怖故事。 这是关于LLM的事情，没人想承认： 它们是不可预测的，永远不会预测的。 这就是为什么我只能研究它们的原因。我没有用它们实际做实际的工作。因为工作需要上下文并试图使LLMS上下文意识到上游正在与上游进行战斗。 在短上下文中，窗口很难增加，因为 增加上下文窗口具有二次复杂性。它需要更多的矩阵乘法。 有优化，但它们具有稀疏注意的缺点。但是它的精度较小。  llms仅限于其数学。要通过上下文窗口绕过问题，您需要完全丢弃注意力机制 这对开发意味着什么？根据代码库的复杂性，LLM的性能越来越差。而且，您向LLM的外包代码越多，您对架构的介绍的黑匣子行为 因此，所有这些工作和“ AI技能”的范围比仅仅了解代码更糟糕。由于LLM的基本数学，情况将会变得更糟。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/golanglinuxguru1979       [links]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mwwqu9/ai_coding_is_not_a_more_useful_skills_than_actual/</guid>
      <pubDate>Fri, 22 Aug 2025 04:17:13 GMT</pubDate>
    </item>
    <item>
      <title>缩放作品</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mwv4dt/scaling_works/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  缩放作品。 RL起作用。不要让“边际收益”。在过去的几个月中，您认为AI不会继续显着发展。人们太不耐烦了。 什么是LLM？它们是预测下文下一步标记的模型。有了预测接下来的令牌的能力，您就可以从分布中采样响应。该分布是数据集的衍生物。LLM在上面训练了LLM。  llms（以及特别是变形金刚）已经可以代表以紧凑格式从复杂分布中采样的数据集。当前的“ ai slop”我们要经历的阶段是因为1）数据质量尚未存在，而2）我们还没有接近饱和那里的数据。 前几天，OpenAI CFO的数据显示，全球90％的数据都位于封闭的门后面（例如机构和企业）。 AI仅接受了全球10％的数据的培训，其中大多数是AI斜率。如果您在2000年代网站的数据集上训练AI，您认为它会产生什么？ 2000年代的网站。 现在，如果您在高质量的企业数据上训练AI，则它将从分布中进行采样代表相关的企业数据。 它很简单。我们当前的算法工作和规模。这只是提取正确的数据的问题。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/uphandered-copy332     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mwv4dt/scaling_works/</guid>
      <pubDate>Fri, 22 Aug 2025 02:53:53 GMT</pubDate>
    </item>
    <item>
      <title>社交媒体以AI形式的“社交摘要”的思想</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mwudgx/social_media_idea_of_social_summaries_in_ai_form/</link>
      <description><![CDATA[在想法在社交媒体的背景下起作用？关于您的社交生活，而不必滚动新闻提要。例如，它可能说“汤姆去了金门桥”。并在其旁边有一个数字，指示喜欢的数量和一个链接，以打开图像，如果您选择查看。  基本上与困惑的方式相同，我相信AI为“社交摘要”的Google搜索。工具可以与社交媒体巨头竞争。  现在，社交媒体公司要求您滚动浏览无尽的新闻供稿，其中包含可能很烦人的广告，因此我认为“社交摘要” AI动力的社交媒体应用将使保持社交和浪费更少的时间变得更加容易。  你们都对“社交总结”有何看法。想法？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mwudgx/social_media_idea_idea_social_summaries_in_ai_ai_form/”&gt; [link]   [注释]    ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mwudgx/social_media_idea_of_social_summaries_in_ai_form/</guid>
      <pubDate>Fri, 22 Aug 2025 02:17:36 GMT</pubDate>
    </item>
    <item>
      <title>还有其他人在工作中对SEO和AI的混合感打交道吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mws6f4/anyone_else_dealing_with_mixed_feelings_about_seo/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我一直在使用AI来帮助工作中的SEO写作。我不是像大学生那样只是要求它去做所有工作，而是让我的语气更加一致并充实某些领域。  在排名方面，它的效果非常好，但是当我的经理发现他们并不激动时。我们从来没有关于在工作场所使用AI使用的对话，而我所听到的只是关于我的内容的积极信息，所以我认为我没有错。  怪异的部分是我公司的其他部分正在启动全面的AI文章，而我的团队显然希望完全避免它。感觉就像行业的不同部分（甚至同一公司）正在以这些东西的速度完全不同。 好奇是否有人遇到了类似的紧张局势，以及他们如何在工作场所处理AI？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mws6f4/anyone_else_else_deal_with_mixed_mixed_feelings_feelings_about_seo/”&gt; [link]   [注释]     ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mws6f4/anyone_else_dealing_with_mixed_feelings_about_seo/</guid>
      <pubDate>Fri, 22 Aug 2025 00:35:09 GMT</pubDate>
    </item>
    <item>
      <title>编码LLMS应该是扩散模型，而不是自回归文本生成器</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mwpvhu/coding_llms_should_be_diffusion_models_not/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  最近使用claude/cursor/gpt来编码和神圣的狗屎，我必须提醒这些模型上有关上下文的次数使我发疯。   好吧，好的，您可以帮助我重构功能，很棒。但是哦，等等，现在读书人已经过时了。哦，有一个测试文件引用旧功能名称。哦，API文档需要更新。哦，还有一个配置文件...您会得到这个想法。 当前的llms基本上是在用代码库一致性播放whack-a摩尔。当它实际上是一个依赖关系的图表时，他们就像是线性对话一样。我们为什么不为代码执行此操作??  想象：您描述了一个更改，而模型只是...  diffuses     是代码库的整个正确状态。所有文件。所有依赖性。所有文档。一枪。不再＆quot oh btw，您还可以更新类型文件。或在3天后发现您的迁移脚本被打破了，因为模型忘记了它的存在。 当前的方法就像在蒙住眼睛时一次绘画Mona Lisa一个笔触，然后在鼻子不匹配脸部时会感到惊讶。同时，扩散就像“这是您的整个一致的代码库，先生”。 厨师的吻  我真的不明白为什么没有人认真对待这一点。仅仅是因为我们陷入了“代码”是文本，文本是顺序的。范例？还是我在这里缺少一些技术限制？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/aginext     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mwpvhu/coding_llms_should_be_diffusion_models_not/</guid>
      <pubDate>Thu, 21 Aug 2025 22:52:20 GMT</pubDate>
    </item>
    <item>
      <title>那些认为AI永远不会有意识的人，为什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mwlvp4/those_of_you_that_think_ai_can_never_be_conscious/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   关于无机物质与有机物是否有一些特殊意识？您甚至怎么知道无机事物是否知道？信息理论是否起作用？只是为那些更好地理解它的人，哲学上的基础对技术而感到好奇。抱歉，如果每个人都厌倦了这个问题，我还没有找到一个有道理的答案。  编辑：AI说神经元使用离子流，计算机使用电子流？计算机具有连续的电压，具有设置的离散解释，神经元具有单个尖峰阈值，并且专注于尖峰频率和时机（没有像电压这样的连续流）。我想知道只有一台具有某种特殊结构的离子计算机才能做到这一点。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mwlvp4/1mwlvp4/those_of_you_that_that_think_think_ai_ai_can_never_never_never_be_consifted/”&gt; [links]     32;  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mwlvp4/1mwlvp4/those_of_you_that_that_think_think_ai_ai_can_never_never_never_never_be_consiuct/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mwlvp4/those_of_you_that_think_ai_can_never_be_conscious/</guid>
      <pubDate>Thu, 21 Aug 2025 20:13:22 GMT</pubDate>
    </item>
    <item>
      <title>Microsoft AI负责人称意识研究为“危险”，而Anthropic，Openai，Google在现场积极雇用</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mwj5wu/microsoft_ai_chief_calls_consciousness_research/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  穆斯塔法·苏莱曼（Mustafa Suleyman）刚刚发表了一篇博客文章，认为研究AI福利是&#39;早产，而且坦率地说是危险的。&#39; 他的理由？它可能会使人们认为AI可能有意识，导致“不健康的依恋”。 同时：  拟人化发起了一项专门的AI福利研究计划  OpenAi研究人员公开地接受了意识     google  google  li&gt; google   google            li&gt; li&gt; li&gt; li&gt;有害的对话（行动中的字面AI福利）  我试图了解何时“不研究，这是危险的”成为有效的科学方法论吗？这感觉不像科学推理，而更像是公司定位。 关于研究新兴现象和宣布整个研究领域之间应有的界限的想法？  https://techcrunch.com/2025/08/21/microsoft-ai-chief-says-its-dangerous-to-study-ai-consciousness/  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/petermossack     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mwj5wu/microsoft_ai_chief_calls_consciousness_research/</guid>
      <pubDate>Thu, 21 Aug 2025 18:31:05 GMT</pubDate>
    </item>
    <item>
      <title>AI部门发生的裁员是没有意义的。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mwgupn/layoffs_happening_in_ai_departments_doesnt_make/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  公司正在介绍对AI研究的重点，但是从统计数据中，AI研究部门也正在发生许多裁员。为什么？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ajagajan_007     [link]     32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mwgupn/layoffs_happening_in_ai_departments_doesnt_make/</guid>
      <pubDate>Thu, 21 Aug 2025 17:05:38 GMT</pubDate>
    </item>
    <item>
      <title>人工智能繁荣面临障碍 - 这就是为什么我认为重大估值更正即将接近</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mwgpah/the_ai_boom_is_facing_obstacles_heres_why_i/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mwgpah/the_ai_boom_is_facing_obstacles_heres_why_i/</guid>
      <pubDate>Thu, 21 Aug 2025 17:00:17 GMT</pubDate>
    </item>
    <item>
      <title>95％的公司AI计划是毫无价值的。华尔街恐慌。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mw9onw/95_of_corporate_ai_initiatives_are_worthless_wall/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在gizmodo上找到了本文。 TL; dr -95％的AI计划由公司发起的任何福利都没有产生任何福利，这可能会引起资金：   https://gizmodo.com/-/gizmodo.com/the-report-port-report-port-thats-pook---thats-pooking-wall-s-pooking-wall-wall-s-wall-street-street-s-2000645518 提交由＆＃32; /u/u/vengeful_bunny     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mw9onw/95_of_corporate_ai_initiatives_are_worthless_wall/</guid>
      <pubDate>Thu, 21 Aug 2025 12:34:30 GMT</pubDate>
    </item>
    <item>
      <title>Zuckerberg冻结了AI在泡泡恐惧中招聘</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mw7i5e/zuckerberg_freezes_ai_hiring_amid_bubble_fears/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;      此举与梅塔报道的薪水急剧相反，最高可达最高10亿美元的顶级人才        马克·扎克伯格（Mark Zuckerberg泡沫。 这家技术巨头已经冻结了其“独特实验室”的招聘，只有AI首席Alexandr Wang必须批准的极少数例外。    阅读更多：   https://www.telegraph.co.uk/business/2025/08/21/zuckerberg-freezes-ai-hiring-amid-bubble-fears/      &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/thetelegraph   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mw7i5e/zuckerberg_freezes_ai_ai_ai_amid_amid_amid_mid_bubble_fears/  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mw7i5e/zuckerberg_freezes_ai_ai_hiring_amid_amid_amid_amid_amid_amid_amid_amid_mid_bubble_fears/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mw7i5e/zuckerberg_freezes_ai_hiring_amid_bubble_fears/</guid>
      <pubDate>Thu, 21 Aug 2025 10:47:53 GMT</pubDate>
    </item>
    <item>
      <title>没有“ AI技能”之类的东西</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mvukhb/there_is_no_such_thing_as_ai_skills/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我一直都听到它。 “那些不了解AI的人将被抛在后面。但是，这到底意味着什么？什么是AI技能？就在几年前，我们有首席执行官说“ knwoledge无关紧要”我将来。在AI中，您不需要技能。我注意到围绕AI的很多对话是“如果您还没有接受AI，请准备被抛在后面。这似乎暗示了某种障碍进入。然而，AI就是要消除障碍 现实是没有AI技能。人们可以指出的唯一技能是迅速的工程。这个标题听起来很荒谬，以至于模仿点。然后我们意识到提示只是一个功能，而不是标题或全新技能。现在，我们看到人工智能不会使某人对某事不好。而且我们认识到，在给定域中需要专家才能从AI中获得任何价值。因此，现在它变得“变得擅长AI或否则”。在。我可能可以向我92岁的阿姨展示如何在一个小时的顶部使用Chatgpt。我可以向她展示如何使用提示来构建她想要的东西。它不会是课堂上最好的，但是没有人使用AI来构建任何课堂上最好的。当“足够好”时，AI是平庸的理想工具。这就是您所需要的。 我已经说过无数次，当涉及AI时，知识有很深的知识。就像了解向量嵌入，推理，转化，注意机制和得分一样。了解数学。这些东西是对真正价值的深刻而艰难的知识。但是，没有人能利用这些技能。    ，只有建立模型或进行研究的人才能使用这些概念。但是，作为一名软件工程师，我没有任何新技能从AI中获得。是的，我可以建立和培训代理商，但这会很昂贵，而且我无法访问甚至可以使它值得的好数据。编码和工程部分很简单。它是“技能”的培训和数据集。进来。那只是我是AI工程师，这是我行业寄宿生范围的狭窄领域。 任何人告诉您AI需要技能的人都对您撒谎。我写了好的提示，这可能需要一天的时间才提示从AI那里得到我需要的东西。任何人都可以做到。因此，提示没有任何用处。喂养AI上下文？您可以复制文件并写英语吗？太好了，所需的所有技能都是获得的。是的，基本上，一堆非技能游行与模糊和神话般的演讲  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/golanglinuxguru1979       [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mvukhb/there_is_no_such_thing_as_ai_skills/</guid>
      <pubDate>Wed, 20 Aug 2025 23:13:58 GMT</pubDate>
    </item>
    </channel>
</rss>