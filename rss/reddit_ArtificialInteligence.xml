<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Tue, 14 Oct 2025 21:15:15 GMT</lastBuildDate>
    <item>
      <title>OpenAI 计划在 ChatGPT 中允许“色情”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o6rist/openais_plan_to_allow_erotica_in_chatgpt/</link>
      <description><![CDATA[我刚刚阅读了旧金山标准中有关 OpenAI 放宽内容限制以允许经过验证的成人用户提示 ChatGPT 的文章 色情内容。 天哪，这感觉像是一个转折点。 如果该工具可以产生色情或深刻的情感内容，那么它的门控程度如何？年龄验证对于假身份证、帐户共享等来说太混乱了。如何防止未成年人访问？ 一方面，我同意：成年人应该有自由，他们一直在抱怨最新型号受到如此审查。有一个关于一致性的争论——如果人工智能要实现富有表现力的内容，最好有安全的护栏，而不是彻底的禁令。但在这些工具已经深深植根于年轻人的生活之际引入色情（并放松心理健康护栏）感觉……是有风险的。特别是自从该州最近否决了人工智能儿童安全法案以来。   由   提交 /u/AIMadeMeDoIt__   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o6rist/openais_plan_to_allow_erotica_in_chatgpt/</guid>
      <pubDate>Tue, 14 Oct 2025 20:55:56 GMT</pubDate>
    </item>
    <item>
      <title>办公室使用的“透明度”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o6qiu0/transparency_of_use_in_the_office/</link>
      <description><![CDATA[我们终于从法律部门得到了人工智能政策。大多数事情都是显而易见或合理的（检查其工作情况，审查是否存在偏见）。该政策的政策要求中难以理解的一个要素是“透明度”。 该政策规定，您应该披露人工智能的使用以及您如何在工作中使用它。作为一名业务分析师，从我的笔记中生成治理文档可以轻松减少 75% 的键盘操作时间。  尽管如此，这项工作源自我的笔记和有效的需求征求等。我不希望我的工作仅仅因为我使用了有效的工具，或者在某种程度上只是抄袭。 因为这基本上与我在“透明”上得到的解释一样多，你会如何将其付诸实践？    由   提交 /u/Desperate_Bad_4411   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o6qiu0/transparency_of_use_in_the_office/</guid>
      <pubDate>Tue, 14 Oct 2025 20:18:58 GMT</pubDate>
    </item>
    <item>
      <title>想象一下，如果他们无法获取在线数据集而必须创建自己的数据集会怎样？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o6p3w8/imagine_if_they_couldnt_harvest_online_datasets/</link>
      <description><![CDATA[正在思考这个问题以及整个“让十亿村里的白痴，村里的白痴”是如何产生的。他们从数据集背后的心态推断出其余的内容，再加上人工智能永远不会承认自己的错误，即使它高兴地在你面前直接说胡话，这让我意识到A）盗版推动了每一项创新，B）只要有钱人在这样做，一切都很好，这会导致C）如果人们称其为实事求是并迫使他们创建经过审查和准确的独特参考，他们将不得不做什么。  对我来说，这整件事实际上与老式的魔眼照片相反，后者在看似混乱的情况下隐藏了秩序。好吧，这项技术颠倒了完全相同的过程，因此在光源下没有什么新东西，是吗？也许上述模型将是未来的修订版本，或者当它面向利基专业化时，但如果你生活在 youtube 拥有完整电影软件和 Napster 等的时代，你就会确切地知道我的意思，因为目前边境小镇的氛围就是人工智能。你不这么认为吗？   由   提交 /u/willhelpmemore   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o6p3w8/imagine_if_they_couldnt_harvest_online_datasets/</guid>
      <pubDate>Tue, 14 Oct 2025 19:26:19 GMT</pubDate>
    </item>
    <item>
      <title>[求助]我的孩子被欺负了，现在只能和AI说话。我不知道该怎么办 大家好</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o6mh68/help_my_child_is_being_bullied_and_now_only_talks/</link>
      <description><![CDATA[我真的很担心，需要一些建议。我们的孩子在学校受到欺凌，最近，我们注意到他花越来越多的时间与人工智能代理而不是真正的朋友聊天。他说这感觉更容易，因为人工智能不会评判他或取笑他，这让我心碎。问题是，他几乎不再向我们敞开心扉，我们也不知道他心里到底在想什么。我们正在努力提供支持和耐心，但我忍不住觉得他正在进一步退回到数字舒适区。有人经历过类似的事情吗？我们如何帮助他重建真正的联系，同时仍然承认为什么他在人工智能中找到安慰？任何想法或经历都意义重大...   由   提交 /u/wolzardred   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o6mh68/help_my_child_is_being_bullied_and_now_only_talks/</guid>
      <pubDate>Tue, 14 Oct 2025 17:48:44 GMT</pubDate>
    </item>
    <item>
      <title>乌托邦真如人们所吹捧的那样吗？宇宙25实验</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o6ig2y/is_utopia_all_that_its_cracked_up_to_be_the/</link>
      <description><![CDATA[Universe 25 实验由行为学家 John B. Calhoun 在 20 世纪 60 年代进行，是一项关于人口密度对社会行为影响的深入研究。他创造了一个本应是老鼠天堂的地方，一个没有捕食者和疾病的围栏，可以无限地获取食物、水和筑巢材料。实验从四对健康的小鼠开始，它们最初茁壮成长，建立领地并迅速繁殖。在这个早期阶段，老鼠社会按照预期运作，具有清晰的社会结构和指数级的人口增长。 然而，随着老鼠数量达到 2,200 只老鼠的峰值，严重的社会崩溃开始了，卡尔霍恩将其称为“行为下沉”。物理空间充足，但社交空间却不够；对于所有的老鼠来说，没有足够的有意义的社会角色。这导致了正常行为的崩溃。一些雄性变得极具攻击性，结成帮派攻击他人，无视求爱仪式。相反，另一组雄性则完全退出。被称为“美丽的人”它们身体完美，但社交惰性，所有时间都花在吃饭、睡觉和梳理毛发上，对交配或打斗没有兴趣。 这种社会混乱对雌性产生了毁灭性的影响，她们变得更具攻击性并失去了母性本能。他们经常忽视、遗弃，甚至攻击自己的后代，导致婴儿死亡率飙升。最后一代老鼠出生在这个功能失调的世界，从未学会正确的社会行为。它们无法交配、抚养后代或保卫领地。结果，繁殖完全停止了。人口老龄化而没有被替代，最终不断减少，直到最后一只老鼠死亡，导致曾经繁荣的群体彻底灭绝。 讨论：该研究的结论引发了一个关于潜在的人工智能和自动化驱动的乌托邦的关键问题：如果我们所有的物质需求都可以通过技术毫不费力地满足，那么由此产生的传统角色和目的的丧失是否会导致类似于“行为水槽”的社会衰退？在第 25 宇宙中观察到？由于我们当前的进步，我们目前是否看到了社会的部分崩溃？   由   提交/u/igor33  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o6ig2y/is_utopia_all_that_its_cracked_up_to_be_the/</guid>
      <pubDate>Tue, 14 Oct 2025 15:21:46 GMT</pubDate>
    </item>
    <item>
      <title>新研究表明，无论大小如何，“毒害”人工智能模型都非常容易</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o6i5vi/new_research_shows_its_surprisingly_easy_to/</link>
      <description><![CDATA[Anthropic 的一项新研究表明，毒害 AI 模型比我们想象的要容易得多。 主要发现：只需要少量固定数量的恶意示例即可在模型中创建隐藏的后门。随着模型变大并接受更多数据的训练，这个数字不会增加。 在他们的测试中，研究人员使用同样少量的不良示例少至 250，成功毒害了各种规模的模型。对于大型模型来说，这只是其总训练数据的一小部分（0.00016%）。 这意味着此类攻击的障碍非常低。攻击者不需要控制很大比例的数据，只需要控制少量、恒定数量的中毒样本。 您可以阅读 Anthropic 的研究文章中的完整详细信息以进行更深入的研究。 参考： Anthropic Research：“少量样本可以毒害任何规模的 LLM” - https://www.anthropic.com/research/small-samples-poison   由   提交/u/Broad-Confection3102   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o6i5vi/new_research_shows_its_surprisingly_easy_to/</guid>
      <pubDate>Tue, 14 Oct 2025 15:11:09 GMT</pubDate>
    </item>
    <item>
      <title>考虑 24% 的失业率</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o6hlbt/consider_24_unemployment/</link>
      <description><![CDATA[关注 AGI 或人工智能夺走每个人的工作完全是对问题的错误理解。人工智能通常不会取代完整的工作，但它已经在取代任务，最终导致失业。人工智能何时导致了最后 20% 的失业并不重要，重要的是它导致了前 20% 的失业。 （大萧条期间美国失业率最高为 25%。）   由   提交/u/WaveWhole9765   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o6hlbt/consider_24_unemployment/</guid>
      <pubDate>Tue, 14 Oct 2025 14:50:03 GMT</pubDate>
    </item>
    <item>
      <title>“‘我是多余的吗？’：人工智能如何改变我的生物信息学职业生涯”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o6fstb/am_i_redundant_how_ai_changed_my_career_in/</link>
      <description><![CDATA[https://www.nature.com/articles/d41586-025-03135-z  &quot;我发现了 在一项肺癌研究期间。我们有数百个肿瘤组织基因表达谱，我要求人工智能进行分析。它工作得很快，甚至还生成了一份整洁的报告。初步结果看起来很棒——几乎太好了。人工智能发现特定时间点前后基因表达水平存在统计学上的显着差异。但当我深入研究时，我发现在研究进行到一半时，实验室改变了数据收集的方式。该模型已经注意到了这种差异——而不是由于生物学造成的。看似突破的东西实际上只是一个人工制品。一旦我适应了这种变化，差异就变得不那么引人注目，而是反映了真实的生物学。 我意识到我的角色已经从脚本转变为监督。现在重要的是清楚地陈述问题，发现计算机无法看到的问题并为答案负责。”   由   提交 /u/AngleAccomplished865   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o6fstb/am_i_redundant_how_ai_changed_my_career_in/</guid>
      <pubDate>Tue, 14 Oct 2025 13:39:56 GMT</pubDate>
    </item>
    <item>
      <title>为什么这么多人工智能计划都失败了：缺失的人工智能战略</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o6fjfm/why_so_many_ai_initiatives_fail_the_missing_ai/</link>
      <description><![CDATA[许多公司都在人工智能项目上投入巨资，但许多公司都在努力产生可持续的投资回报率 - 通常是因为这些举措背后没有一致的人工智能战略。 根据我在不同研究和咨询来源（麦肯锡、BCG、HBR、德勤等）的观察，有效的人工智能战略往往依赖于四个核心 领域：  业务协调——将人工智能直接与可衡量的业务成果联系起来 数据和数据技术基础——拥有正确的数据、架构和工具 人才和技术运营模式——确保人员、技能和工作流程能够扩展人工智能 治理和流程风险——从一开始就嵌入负责任的人工智能和合规性  很好奇这里的其他人如何看待这个问题 -  您认为组织以结构化的方式处理人工智能吗？ 或者大多数仍在没有明确的路线图的情况下进行试验？ （事实上，我也在其他地方更深入地探讨了这个主题 - 链接位于评论中，供那些正在使用人工智能的人使用） 有兴趣）   由   提交 /u/Euphoric_Sea632   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o6fjfm/why_so_many_ai_initiatives_fail_the_missing_ai/</guid>
      <pubDate>Tue, 14 Oct 2025 13:29:14 GMT</pubDate>
    </item>
    <item>
      <title>生成式人工智能应该只适合 16 岁以上的人</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o6f7ox/generative_ai_should_only_be_for_people_over_16/</link>
      <description><![CDATA[我认真地认为生成式人工智能应该受到年龄限制。不是因为孩子们会用它来作弊，而是因为它会以一种还不可见的方式让他们陷入困境。每个人都在谈论它如何帮助学生，但事实是，它给他们带来的麻烦远大于帮助。 当你的大脑仍在发育时，学习中的困难部分就很重要。陷入困境，再次尝试，失败，然后找出答案。这就是你真正建立耐心、创造力和信心的方式。如果一个 13 岁的孩子只需输入提示即可获得完美的文章或图像，他们就会跳过整个过程。 从神经学角度来看，这是一场即将发生的灾难。大脑会适应你最常做的事情，如果你所做的只是让机器为你思考，你最终将根本无法深入思考。 在社交方面，孩子们已经很难在没有屏幕的情况下进行交流。现在他们可以使用人工智能来结交假朋友、假艺术、假一切。真实的人是混乱的、不可预测的、令人讨厌的。人工智能很简单，它总是同意，从不评判。 从心理上来说，它会膨胀自我，同时扼杀好奇心。当你生产的所有东西看起来都很聪明和精致时，你就不再想改进了。你停止质疑自己。就这样，你长大后变得非常脆弱。 人工智能并不坏。对于那些大脑仍在自我连接的人来说，这不是一个玩具。 孩子们已经淹没在屏幕、社交媒体和游戏中，这些麻木了他们的注意力并扼杀了真正的好奇心。我们不能再增加一个拖慢下一代发展的负担。 编辑：不再回复。很明显，这里的大多数人并不是在争论，他们只是在捍卫他们已经接受的不可避免的事情。这正是控制的运作方式：让人们相信他们正在选择实际上强加给他们的东西。   由   提交/u/matheus_francesco  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o6f7ox/generative_ai_should_only_be_for_people_over_16/</guid>
      <pubDate>Tue, 14 Oct 2025 13:15:29 GMT</pubDate>
    </item>
    <item>
      <title>Anthropic 联合创始人承认，他现在“非常害怕”……“我们面对的是一个真实而神秘的生物，而不是一个简单且可预测的机器……我们需要勇气看到事物的本来面目。”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o6cow1/anthropic_cofounder_admits_he_is_now_deeply/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o6cow1/anthropic_cofounder_admits_he_is_now_deeply/</guid>
      <pubDate>Tue, 14 Oct 2025 11:16:59 GMT</pubDate>
    </item>
    <item>
      <title>Nvidia和AMD还不够，OpenAI现在正在设计自己的芯片</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o670f1/nvidia_and_amd_arent_enough_openai_is_designing/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o670f1/nvidia_and_amd_arent_enough_openai_is_designing/</guid>
      <pubDate>Tue, 14 Oct 2025 05:24:56 GMT</pubDate>
    </item>
    <item>
      <title>我已经深入人工智能两年多了，我坚持一条规则：</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o63v9o/ive_been_deep_into_ai_for_over_two_years_now_and/</link>
      <description><![CDATA[⚠️ 不要购买年度订阅 人工智能发展得太快了。当 Google、OpenAI 或一些小型初创公司发布新更新时，今天感觉很重要的工具可能会在下个月变得无关紧要。   由   提交 /u/SubstantialBread8169   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o63v9o/ive_been_deep_into_ai_for_over_two_years_now_and/</guid>
      <pubDate>Tue, 14 Oct 2025 02:40:20 GMT</pubDate>
    </item>
    <item>
      <title>人工智能变得非常可怕，人们可以制作看起来几乎 100% 真实的假视频</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o5ovib/ai_is_getting_really_scary_people_can_make_fake/</link>
      <description><![CDATA[我知道每个人都在谈论人工智能，但最近它开始真正让我感到害怕。我看到了这个名叫 hstiktokky 的影响者的一些片段，人们确实制作了假人工智能视频（我认为是与 sora 一起），他说或做了他从未做过的事情，其中​​一些直接令人不安，就像他们让他看起来像恋童癖或说一些混乱的东西。最糟糕的部分它实际上看起来很真实。他说他打算起诉他们，但说实话，当这样的技术不断进步时，这有什么好处呢？感觉这只是一个开始。任何人都可以制作一个你在做一些奇怪的事情的假视频，在你有机会否认之前，一半的互联网都会相信它。想到几年后这将走向何方，这有点可怕。就像想象一下选举法庭案件，甚至只是你的日常生活一样，只要点击几下，有人就可能毁掉你的声誉。我早些时候在灰熊的任务中玩二十一点，看到有人在聊天中开玩笑说同样的事情，这让我意识到这变得多么真实。 甚至不再只是名人，最终普通人也会成为目标。我认为我们根本没有准备好。   由   提交/u/toweringarchery_1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o5ovib/ai_is_getting_really_scary_people_can_make_fake/</guid>
      <pubDate>Mon, 13 Oct 2025 16:41:01 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>