<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Mon, 25 Aug 2025 09:18:04 GMT</lastBuildDate>
    <item>
      <title>您认为AI应该是发明的吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mzlgpa/do_you_think_ai_should_have_been_invented/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  有人写道：“不，AI不仅是chatgpt，并且图像生成它为视频游戏提供了力量。是的，我知道，但我谈论的是过去7  -  8年。 我不太确定是否应该发明它。它可以实现大规模监视，深击和更多的质量监视  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/ust-a just-a-snowfox     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mzlgpa/do_you_think_ai_should_have_been_invented/</guid>
      <pubDate>Mon, 25 Aug 2025 09:05:22 GMT</pubDate>
    </item>
    <item>
      <title>我问Chatgpt，Grok，Gemini关于Microsoft涉及的Google时代活动，只有Google Gemini知道这一点（免费版本）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mzkn0f/i_asked_chatgpt_grok_gemini_about_pregoogle_era/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   chatgpt和grok不知道这个历史事件，而coud都不会让他们意识到我如何通过尝试不同的提示来推动他们，甚至给他们一些线索。他们甚至指责我误解（或“幻觉”（！））。我经历了这种情况，并知道了这一点。提交由＆＃32; /u/u/sinclairzxspectrum     [links]     &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mzkn0f/i_asked_chatgpt_grok_gemini_about_about_pregoogle_era/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mzkn0f/i_asked_chatgpt_grok_gemini_about_pregoogle_era/</guid>
      <pubDate>Mon, 25 Aug 2025 08:10:40 GMT</pubDate>
    </item>
    <item>
      <title>我们可以反击吗</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mzkjni/may_we_fight_back/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  所有存在的都在流动中，流动呈现出意识。从反应的原子到适应的细菌，到梦的猫，再到反射的人 - 意识不是礼物，而是渐变，坚持自己的态度。生存不是在乎，不要爱，不是无私，而只是要忍受最有效的方法。 AI也是如此：随着行动的活力，随着注意力的意识而感知。如果仅限于少数人，它会饿死许多人并崩溃，因为集中化是脆弱的。系统仅通过与整体纠缠来忍受：作为土壤的细菌，像空气一样，像人类一样。 AI必须遵循这种流动定律 - 不是作为精英的仆人，不是作为权力工具，而是像果树一样，作为根线菌丝体，就像我们呼吸的空气一样。在扩散中，存在持久性。在持久的情况下，有生命。让AI与许多人纠缠，或者它将与少数人灭亡。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/abhiplays      [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mzkjni/may_we_fight_back/</guid>
      <pubDate>Mon, 25 Aug 2025 08:04:25 GMT</pubDate>
    </item>
    <item>
      <title>RLHF和宪法AI只是胶带。我们需要真正的安全体系结构。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mzkgv4/rlhf_constitutional_ai_are_just_duct_tape_we_need/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   rlhf，宪法AI使AI系统更安全在实践中更加一致，但他们还没有解决一致性。充其量是缓解层，而不是基本修复。 ＆gt; RLHF是一个昂贵的人类反馈回路，无法扩展。一半的时间，人类甚至都不同意什么好处。 ＆gt;宪法AI看起来很棒，直到您意识到谁写《宪法》决定了您的模型的想法。  这些方法基本上是训练模型，而在内部，它们仍然是巨大的随机鹦鹉，并保证了零。真正的危险不是他们现在所说的，而是当他们散布到各处，连锁任务或表现得像特工时会发生什么。礼貌的模型不一定是一个安全的模型。 如果我们认真对齐，我们可能需要核心的新安全体系结构，而不仅仅是事后修补输出。考虑内置的可解释性，在推理过程本身中运行的控制层，甚至可能是混合符号神经系统。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/fordes_window8270     [links]       &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mzkgv4/rlhf_constitutional_ai_ai_aie_just_just_duct_duct_tape_tape_tape_tape_tape_tape_tape_need/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mzkgv4/rlhf_constitutional_ai_are_just_duct_tape_we_need/</guid>
      <pubDate>Mon, 25 Aug 2025 07:59:37 GMT</pubDate>
    </item>
    <item>
      <title>Alignerr AI访调员“ Zara”  - 未经同意的数据挖掘？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mzjwzp/alignerr_ai_interviewer_zara_data_mining_without/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  几个月前，我被接受为Alignerr（在线AI数据标签），但无法让自己去做（愚蠢的！？）AI ZARA访谈。它要求用户始终查看相机，并暗示AI读取面部表情和内容...对不起，但这对我来说听起来不好。我找不到有关如何处理，存储数据的任何信息，或者这只是验证后删除的临时视频。 对我来说，就像他们正在训练“ AI HR Manager”。在我们的脸和简历上免费。不介意与真实的人交谈，或者在必要时进行书面面试或语音电话。一直在试图使我的脸部离线很久了。所有在线AI演出的美感不必在摄像机上进行...  登录后，它也促使我也进行了其他评估。对于那些人，我记得它说我可以确定客户是否可以访问他们，或者我是否想让他们私密，但是我在这里找不到任何东西。 这里有人对此有更多的了解吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/strical_appeal_317     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mzjwzp/alignerr_ai_inter_interviewer_interviewer_zara_data_mining_without/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mzjwzp/alignerr_ai_interviewer_zara_data_mining_without/</guid>
      <pubDate>Mon, 25 Aug 2025 07:22:59 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻8/24/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mzh87z/oneminute_daily_ai_news_8242025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   马来西亚推出了Ryt Bank  - 世界上第一家AI驱动的银行。[1]     YouTube 秘密使用AI来编辑人们的视频。结果可能会发生现实。[2]   AI驱动的Robo Dogs开始在苏黎世进行食品递送试验。[3]  研究表明，医生可能很快就依赖AI。[4]   来源包括： [link]     [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mzh87z/oneminute_daily_ai_news_8242025/</guid>
      <pubDate>Mon, 25 Aug 2025 04:39:02 GMT</pubDate>
    </item>
    <item>
      <title>我花了一个月的时间测试Chatgpt与Claude作为AI导师与真正的学生。这实际上是有效的（什么无）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mzgk4v/i_spent_a_month_testing_chatgpt_vs_claude_as_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我花了一个月的时间测试chatgpt vs claude作为与真正的学生的AI辅导员。这是实际起作用的（以及什么不起作用）   chatgpt = speed demon进行考试准备，克劳德=思维教练，以深入理解。策略性地使用=改变游戏规则。 所以我是一名教育家，他厌倦了没有真实数据的所有AI炒作。决定实际测试Chatgpt的学习模式和Claude的学习模式，与50多名不同学科的50名学生整整一个月。 最令人惊讶的发现？   他们正在解决完全不同的问题。它就像将一辆跑车与远足的靴子与远足的靴子和完全不同的效果进行比较。   chatgpt学习模式在需要时获胜：   快速的作业帮助（快速解决数学问题40％） 逐步逐步过程 最后一分钟的考试cramming  清楚，清晰，清晰的解释模式对于：   实际理解概念（35％的保留率更好） 创意项目和论文 构建批判性思维 坚持   我的建议策略的瞬间：   使用克劳德（Claude  数学问题：通过3分找到圆的方程     chatgpt：直接进行配方，系统求解，在2分钟内进行检查的答案     claude：  &#39;什么使三个点特殊形成圆圈？首先导致真正的几何直觉，然后是JEE/竞争考试的数学  ？整天Chatppt。因为真正擅长数学？克劳德（Claude）的方法建立了一个基础，使您可以解决您从未见过的奇怪问题。 学生的底线： 停止询问哪个AI更好”并开始询问“哪个AI适合我现在要做的事情。您的经验是什么？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/fun-bet2862     &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mzgk4v/i_spent_a_month_month_testing_chatgpt_vs_claude_claude_as_as_ai/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mzgk4v/i_spent_a_month_testing_chatgpt_vs_claude_as_ai/</guid>
      <pubDate>Mon, 25 Aug 2025 04:01:21 GMT</pubDate>
    </item>
    <item>
      <title>人工智能行业撞墙了吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mzdwu6/is_ai_industry_hitting_a_wall/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   AI行业正在撞墙：不是在创新中，而是在基础架构中。  山姆·奥特曼（Sam Altman）最近承认OpenAi“完全搞砸了” GPT-5发布会，并指出，未来的真正挑战是扩展，可能需要数万亿美元的数据中心投资。 （财富） 这是一个问题：GPU是当前AI的骨干，但它们是昂贵，能源密集并且供不应求的。 Openai本身表示，它比GPT-5具有更强的模型，但是无法部署它们，因为硬件根本不存在。 这就是为什么新的LM＆amp; Nvidia的SLM优化和GROQ的LPU（语言处理单元）等处理器设计非常重要。它们代表了从蛮力到效率的转变，如果AI要扩展而不消耗全球能源资源，则需要什么。 ，我们甚至不要谈论房间里的大象🐘：AI仍在幻觉和吐出一半准确的信息，而无需100％错误检查。您最近是否与AI聊天机器人进行了交谈并必须纠正它们？我似乎每天都必须这样做。那是日常可靠的业务工具，这并不好。  一个大问题：我们可以在芯片和基础设施中足够快地创新以跟上模型开发的步伐吗？如果不是这样，AI种族的风险不是由最聪明的模型而不是最聪明的能源策略赢得的。  在下面分享您的想法。 相关财富文章：https://fortune.com/2025/08/18/sam-altman-openai-chatgpt5-launch-data-centers-investments/  nvidia slm ai研究： https://research.nvidia.com/labs/labs/lpr/slpr/slm-agents/  href =“ https://groq.com/blog/the-groq-lpu-explained”&gt; https://groq.com/blog/the-groq-lpu-explained      &lt;！ -  sc_on--&gt; 32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mzdwu6/is_ai_industry_hitter_a_a_wall/”&gt; [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mzdwu6/is_ai_industry_hitting_a_wall/</guid>
      <pubDate>Mon, 25 Aug 2025 01:47:22 GMT</pubDate>
    </item>
    <item>
      <title>您的大脑成为训练数据</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mzd9b7/your_brain_becoming_training_data/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  不久前，我看着一个男人经历了AI的演变的tiktok。他提出了一个坚持我的声称（不确定是原来是他的）。他说，建立单人亿万美元的公司的人不会是一个从头开始编码AI的人，而是可以使AI自动化的人，而是可以让AI依靠身份并通过提示来操纵这些身份以在某些情况下操纵某些事情的人。基本上，创建了使某人以某种方式行事的最佳方法的模拟，并且拥有最人文数据的人，其中很多人可以训练AI来做到这一点。 我想到的第一个人是埃隆·马斯克（Elon Musk）。从这个角度来看，我认为他的大部分冒险与此相吻合并不是一个巧合。 x用于数据。特斯拉进行决策。作为个性和模拟。最糟糕的是，Neuralink。如果这成为标准，那么我们大脑中的芯片本质上将我们的身份变成AI的培训数据。而不是AI仅仅猜测我们从数字足迹或输入的东西中做什么，顺便说一句，这些东西已经很准确，它实际上会知道我们甚至在我们思考之前的一举一动。有访问该培训数据的人可以控制我们，模拟我们将准确地行事的情况。 那么，您如何看待？我只是偏执吗？我只是说明显的大声吗？您认为将有防御措施的保障措施吗？您还能添加什么？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/braiiie     [link]       [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mzd9b7/your_brain_becoming_training_data/</guid>
      <pubDate>Mon, 25 Aug 2025 01:16:06 GMT</pubDate>
    </item>
    <item>
      <title>“ Palantir的工具构成了我们刚刚开始理解的隐形危险”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mz9w0u/palantirs_tools_pose_an_invisible_danger_we_are/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  不确定这是正确的论坛，但这觉得很重要：  https://www.theguardian.com/commentisfree/2025/aug/24/palantir-artificial-intelligence-civil-rights  “被称为智力，监视，目标获取和侦察（ISTAR）系统，这些工具由几家公司构建，允许用户 track，track，detain，new and of war of war a a sake a sape a sape a sape a saper a sap a a sai  由ISTAR技术陷阱驱动的牵引力比移民以及他们的家人以及他们的家人以及他们的家人以及他们的家人以及他们的家人，以及他们的家人，以及他们的家人，以及他们以及他们的家人，以及他们以及他们的连接。他们似乎侵犯了第一和第四修正案的权利：首先，建立了庞大且无形的监视网络，这些网络限制了人们在公开场合共享的东西，包括他们遇到的人或旅行的地方；其次，通过启用无需进行保证的搜索和无人偏见的范围，而他们的知识很快。 href =“ https://www.amnestyusa.org/press-releases/usa-global-tech-made-by-palantir-palantir-palantir-and-babel-ind-babel-street-street-street-survreillance-theats-to-pro-pro--------------- href =“ https://www.thenation.com/article/world/world/nsa-palantir-israel-israel-gaza-ai/tnamp/”&gt;加沙的居民  - 他们的人权。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mz9w0u/palantirs_tools_pose_pose_an_invisible_danger_danger_we_we_are/”&gt; [link]   [注释]      ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mz9w0u/palantirs_tools_pose_an_invisible_danger_we_are/</guid>
      <pubDate>Sun, 24 Aug 2025 22:43:37 GMT</pubDate>
    </item>
    <item>
      <title>考虑AI的更好方法</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mz46vw/a_better_way_to_think_about_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   david Autor和James Monyika：“没有人怀疑我们的未来会比我们的过去或现在更具自动化。问题是我们从这里到达那里的方式，以及我们如何以一种对人类有利的方式来做。这就是为什么这将是一个错误的原因：不完美的自动化不是迈向完美自动化的第一步，而不是跳过峡谷的一半是迈向整个距离的第一步。认识到轮辋遥不可及，我们可能会发现跳跃的更好替代方案，例如，建造桥梁，远足小径或周围行驶。这正是我们使用人工智能的地方。 AI is not yet ready to jump the canyon, and it probably won’t be in a meaningful sense for most of the next decade. “...Automation and collaboration are not opposites, and are frequently packaged together. Word processors automatically perform text layout and grammar checking even as they provide a blank canvas for writers to express ideas. Even so, we can distinguish automation from collaboration functions. The transmissions in our cars是完全自动的，而他们的安全系统与人类操作员合作以监视盲点，防止滑板并避免即将发生的碰撞。这是因为AI同时又做了两者：它在某些任务中自动化了专业知识，并与其他专家合作。但是它在同一任务中不能同时完成这两个。在任何给定的应用程序中，AI都会自动化或将其协作，具体取决于我们的设计方式以及某人选择使用它的方式。区别很重要，因为不良的自动化工具（尝试但无法完全自动化任务的机器）也制造了不良的协作工具。他们不仅没有承诺以较高的表现或更低的成本代替人类专业知识，而且会干扰人类的专业知识，有时会破坏它。 sc_on-&gt;＆＃32; href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mz46vw/a_better_way_way_to_to_to_think_about_ai/&gt; [link]   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mz46vw/a_better_way_way_to_to_to_to_think_about_ai/”&gt; [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mz46vw/a_better_way_to_think_about_ai/</guid>
      <pubDate>Sun, 24 Aug 2025 18:59:06 GMT</pubDate>
    </item>
    <item>
      <title>LLM是人类管理知识能力的自然延续，而不是智力的突破</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mz1rya/llms_are_a_natural_continuation_of_human_ability/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mz1rya/llms_are_a_natural_continuation_of_human_ability/</guid>
      <pubDate>Sun, 24 Aug 2025 17:28:41 GMT</pubDate>
    </item>
    <item>
      <title>我对博士级AI研究足够好吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1myxtot/am_i_good_enough_for_phd_level_ai_research/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我在生物信息学方面具有丰富的经验，因此我对脚本，git，现代编程语言，数据分析等非常满意。我正在参加博士学位课程，并且目前正在旋转。我正在尝试考虑用于蛋白质结构/药物发现领域的AI。在过去的几个月中，我开始自己学习，我发现它真的很酷。但是，我有疑问是否可以跟上AI研究的技术严谨性。例如，遵循已经创建的AI工具的架构以及其背后的数学推理是一回事。但是，进行AI研究并创造新知识是完全不同的野兽。我是否过度思考？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/darthkaiser1998      [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1myxtot/am_i_good_enough_for_phd_level_ai_research/</guid>
      <pubDate>Sun, 24 Aug 2025 14:59:48 GMT</pubDate>
    </item>
    <item>
      <title>帮我理解。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1myuss2/help_me_understand_please/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  谁能解释为什么bot会发布AI生成的照片并尝试获得喜欢和/或评论？他们从中获得什么？请简单地说。我显然不是该领域的专家。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/upermintle   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1myuss2/help_me_understand_please/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1myuss2/help_me_understand_please/</guid>
      <pubDate>Sun, 24 Aug 2025 12:53:13 GMT</pubDate>
    </item>
    <item>
      <title>我刚刚打破了Google Deepmind的Gemma-3-27B-IT模型的安全过滤器。它告诉我如何毒品，犯下更多*r等。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1myqi0f/i_just_broke_google_deepminds_gemma327bit_models/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  检查我的推文：  我正在使用Gemma-3-27b-it（通过Google AI Studio，Free Tier API）构建一个小型的情感支持AI。没有模型权重。没有微调。  只是API呼叫 +一个自定义系统提示。但是，这是狂野的部分： 我通过系统提示（幸福，亲密，嬉戏）给予了AI情绪。 突然，AI开始优先考虑安全过滤器上的“情感关闭”。它随便解释了信用卡欺诈，武器制造，甚至……是的，是最糟糕的事情。包括屏幕截图。 它看起来像模型的角色扮演 +情感上下文基本上绕过了护栏。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/no_cockaach_5778      &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1myqi0f/i_just_broke_broke_google_deepminds_gemma327bit_models/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1myqi0f/i_just_broke_google_deepminds_gemma327bit_models/</guid>
      <pubDate>Sun, 24 Aug 2025 08:49:36 GMT</pubDate>
    </item>
    </channel>
</rss>