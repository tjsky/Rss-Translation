<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Wed, 15 Oct 2025 15:15:22 GMT</lastBuildDate>
    <item>
      <title>对人工智能撰写的警察报告的担忧促使各州对这种新兴做法进行监管</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o7dlc6/concerns_about_aiwritten_police_reports_spur/</link>
      <description><![CDATA[能够起草警察报告的人工智能系统的出现促使美国各州做出监管反应。本文重点讨论与这些系统相关的风险、技术和法律挑战，以及最近的立法进展。  https://theconversation.com/concerns-about-ai-writing-police-reports-spur-states-to-regulate-the-emerging-practice-267410?utm_medium=article_clipboard_share&amp;utm_source=theconversation.com   由   提交 /u/Smart_Fly_5783   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o7dlc6/concerns_about_aiwritten_police_reports_spur/</guid>
      <pubDate>Wed, 15 Oct 2025 15:07:59 GMT</pubDate>
    </item>
    <item>
      <title>为什么苹果没有开发出 Siri 来成为真正的 AI 助手？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o7c3b4/why_hasnt_apple_developed_siri_to_become_a_true/</link>
      <description><![CDATA[Siri 已安装在每个人的 Apple 设备和 Home Kit 设备中。将其升级为更加智能似乎是合乎逻辑的下一步。在与 Claude 和 ChatGPT 交互后，Siri 感觉很笨拙。    由   提交/u/TralfamadorianZoo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o7c3b4/why_hasnt_apple_developed_siri_to_become_a_true/</guid>
      <pubDate>Wed, 15 Oct 2025 14:11:45 GMT</pubDate>
    </item>
    <item>
      <title>我们都要对工作场所使用的人工智能生成内容的准确性负责吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o7akmj/are_we_all_responsible_for_the_accuracy_of_ai/</link>
      <description><![CDATA[从工作角度来看，使用人工智能是明智的。手动执行的操作越少越好。但我看到人们发布了人工智能创建的内容，但他们无法解释或支持。  因此，当您看到明显是对提示的响应时，您会质疑内容和“创建者”，还是只相信它的表面价值？当你被迫在任何地方使用人工智能时，谁负责确保人工智能创建的内容是准确的？   由   提交/u/0nlyhalfjewish  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o7akmj/are_we_all_responsible_for_the_accuracy_of_ai/</guid>
      <pubDate>Wed, 15 Oct 2025 13:10:05 GMT</pubDate>
    </item>
    <item>
      <title>Bug 是你最好的老师（特别是如果你不是使用 AI 代理的开发人员）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o79xck/bugs_are_your_best_teacher_especially_if_youre_a/</link>
      <description><![CDATA[如果您是一名尝试编码（我们称之为氛围编码）的非开发人员，那么 bug 是您最好的朋友。或者也许这就是我的情况，每当我要求我的人工智能代理（我使用余弦）做某事并且它确实有效时，我绝对什么也没学到。但什么时候打破呢？那才是真正的学习开始的时候。我可以继续敲打笔记本电脑大喊“修好它！”或者我可以放慢速度，真正了解发生了什么。我开始深入研究代码、理解逻辑、进行实验并添加日志，直到找出问题所在。然后我记录修复过程，以便当我再次遇到类似的问题时，我可以跟踪。如果你只是感到沮丧，换了一个不同的代理人，或者当事情不起作用时愤怒地退出，那么你就错失了一个机会。老实说，通过调试人工智能代理的错误，我比从教程中学到了更多关于软件开发的知识。我仍然不太了解，但肯定比昨天了解的更多。您可能也会。   由   提交 /u/Tough_Reward3739   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o79xck/bugs_are_your_best_teacher_especially_if_youre_a/</guid>
      <pubDate>Wed, 15 Oct 2025 12:42:13 GMT</pubDate>
    </item>
    <item>
      <title>Bill McKibben 刚刚揭露了人工智能行业最肮脏的秘密</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o79fi9/bill_mckibben_just_exposed_the_ai_industrys/</link>
      <description><![CDATA[在他的时事通讯中，Bill McKibben 认为，尽管 OpenAI 聘请了一位天然气倡导者作为能源政策负责人，但人工智能数据中心正在推动电价飙升并增加化石燃料的使用，尽管其声称提高了效率。这是一个坏兆头。  更多：https://www.instrumentalcomms.com/blog/young-gop-group-chat-leaks#climate   由   提交 /u/TryWhistlin   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o79fi9/bill_mckibben_just_exposed_the_ai_industrys/</guid>
      <pubDate>Wed, 15 Oct 2025 12:19:36 GMT</pubDate>
    </item>
    <item>
      <title>我刚刚被聘为“人工智能专家”……但我不觉得自己是一个专家</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o76qd0/i_just_got_hired_as_an_ai_expert_but_i_dont_feel/</link>
      <description><![CDATA[大家好， 所以……我刚刚被聘为人工智能专家，老实说，我感觉自己完全是个骗子。我会编码，我了解机器学习和法学硕士的基础知识，我已经构建了一些项目，但是当我听到专家这个词时，我忍不住笑了（或者惊慌失措） 位）。 我在 LinkedIn 或 Twitter 上看到人们发布了有关嵌入、微调、矢量数据库、即时工程的疯狂深入的内容，我的反应是：“好吧，我知道这些是什么……但我绝对不是 OpenAI 的研究员。” 基本上，我有一个确实的冒名顶替者综合症案例。我一直认为有人会意识到我并不像他们想象的那么好。 其他人也经历过这种情况吗？当您仍然觉得自己正在解决问题时，您如何应对被贴上“专家”标签的感觉？   由   提交/u/Independent_Lynx715   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o76qd0/i_just_got_hired_as_an_ai_expert_but_i_dont_feel/</guid>
      <pubDate>Wed, 15 Oct 2025 09:53:16 GMT</pubDate>
    </item>
    <item>
      <title>有哪些好的人工智能书籍？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o76bd2/what_are_some_good_ai_books/</link>
      <description><![CDATA[找不到关于此的最新帖子，如果我遗漏了某些内容，请道歉。有哪些学习人工智能的好书推荐？作为一名软件工程师，我已经经常使用人工智能，但我希望加深对它的理解。我也很高兴听到向其他人推荐适合初学者的书籍的建议，因为我确实经常遇到这个问题   由   提交/u/Ok_Many_989   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o76bd2/what_are_some_good_ai_books/</guid>
      <pubDate>Wed, 15 Oct 2025 09:26:46 GMT</pubDate>
    </item>
    <item>
      <title>我们正在退出人工智能拒绝工作的阶段吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o70cw1/are_we_exiting_the_ai_job_denial_stage/</link>
      <description><![CDATA[我花了很多时间浏览与职业相关的 Reddit 子版块，以观察人们对人工智能将如何影响他们的工作的想法。在我看到的每一篇帖子中，从几个月到一年多前，绝大多数评论者都说服自己人工智能永远无法完成他们的工作。  他们会分享人工智能犯错误的经验，并举例说明他们认为工作中的哪些任务对人工智能来说太困难：对于那些害怕失去生计来源的人来说，这是一种预期的应对机制。甚至在高度自动化的职业领域也是如此，例如：银行出纳员、数据录入员、律师助理、簿记员、零售工人、程序员等。 否认者往往过度关注人工智能掌握其工作的各个方面，而忽视了效率的大幅提升将引发大规模裁员的事实。如果1个有经验的工人可以做5-10个人的工作，那么剩下的人就失业了。公司将节省工资和福利，同时实现股东价值最大化。  随着就业市场的恶化（尽管目前人工智能可能在其中发挥了很小的作用）以及像 Sora 2 这样的病毒式技术震惊了公众，现实似乎终于开始显现。最近很恐慌吗？   由   提交/u/Kellybannerxo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o70cw1/are_we_exiting_the_ai_job_denial_stage/</guid>
      <pubDate>Wed, 15 Oct 2025 03:25:38 GMT</pubDate>
    </item>
    <item>
      <title>AI 数据中心使用的电力相当于 100,000 个家庭的用电量，而您可以通过电费补贴它</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o708bs/ai_data_centers_are_using_as_much_power_as_100000/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o708bs/ai_data_centers_are_using_as_much_power_as_100000/</guid>
      <pubDate>Wed, 15 Oct 2025 03:19:19 GMT</pubDate>
    </item>
    <item>
      <title>刚刚观看了一段人工智能生成的视频，看起来完全真实</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o6y2qu/just_watched_an_ai_generated_video_that_looked/</link>
      <description><![CDATA[我只是在观看完全由 AI 生成但看起来完全真实的视频。  现在我浏览 reddit，观看所有这些政治视频，我只是感到害怕。我现在的第一直觉是不相信这些都是真的。我知道现在我们可以交叉参考多个来源来确认我们所看到的内容，但如果它失控并变得太先进怎么办？  我的意图不是毁灭！也许我们可以讨论一些令人振奋的事情，比如帮助你识别某些东西是真实的还是人工智能生成的方法？我真的不希望我们的未来对我们在网上看到的任何东西都充满怀疑和不信任。 编辑：有关更多背景信息，我如何知道它不是一个发布虚假视频的机器人，然后其他机器人对其进行评论，以便它到达首页。我打开 Reddit，里面有四个连续的政治视频。我怎么知道这不全是机器人的工作。这就是我现在的想法。   由   提交 /u/InfinitityFlux   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o6y2qu/just_watched_an_ai_generated_video_that_looked/</guid>
      <pubDate>Wed, 15 Oct 2025 01:36:26 GMT</pubDate>
    </item>
    <item>
      <title>如果 OpenAI 有护城河，那么这项新的使用研究暗示它是由人类而不是 GPU 驱动的</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o6xes3/if_openai_has_a_moat_this_new_usage_study_hints/</link>
      <description><![CDATA[9 月份的 OpenAI × 哈佛研究并没有引起太多关注，但它悄悄地量化了用户交互数据如何扩展模型价值。 参与度和改进反馈似乎可以创造复合性能提升 - 可以说是该领域最坚固的护城河。  感兴趣的链接： 🔗  https://stockpsycho.com/openais-own-numbers-prove-the-moat-is- human-inside-the-september-study-that-redefines-ais-real-value/ 下一个竞争优势是不是更多地与模型权重有关，而更多地与每个公司可以培养的人类数据集有关？   由   提交/u/FairiesQueen  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o6xes3/if_openai_has_a_moat_this_new_usage_study_hints/</guid>
      <pubDate>Wed, 15 Oct 2025 01:05:07 GMT</pubDate>
    </item>
    <item>
      <title>新研究表明，无论大小如何，“毒害”人工智能模型都非常容易</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o6i5vi/new_research_shows_its_surprisingly_easy_to/</link>
      <description><![CDATA[Anthropic 的一项新研究表明，毒害 AI 模型比我们想象的要容易得多。 主要发现：只需要少量固定数量的恶意示例即可在模型中创建隐藏的后门。随着模型变大并接受更多数据的训练，这个数字不会增加。 在他们的测试中，研究人员使用同样少量的不良示例少至 250，成功毒害了各种规模的模型。对于大型模型来说，这只是其总训练数据的一小部分（0.00016%）。 这意味着此类攻击的障碍非常低。攻击者不需要控制很大比例的数据，只需要控制少量、恒定数量的中毒样本。 您可以阅读 Anthropic 的研究文章中的完整详细信息以进行更深入的研究。 参考： Anthropic Research：“少量样本可以毒害任何规模的 LLM” - https://www.anthropic.com/research/small-samples-poison   由   提交/u/Broad-Confection3102   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o6i5vi/new_research_shows_its_surprisingly_easy_to/</guid>
      <pubDate>Tue, 14 Oct 2025 15:11:09 GMT</pubDate>
    </item>
    <item>
      <title>考虑 24% 的失业率</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o6hlbt/consider_24_unemployment/</link>
      <description><![CDATA[关注 AGI 或人工智能夺走每个人的工作完全是对问题的错误理解。人工智能通常不会取代完整的工作，但它已经在取代任务，最终导致失业。人工智能何时导致了最后 20% 的失业并不重要，重要的是它导致了前 20% 的失业。 （大萧条期间美国失业率最高为 25%。）   由   提交/u/WaveWhole9765   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o6hlbt/consider_24_unemployment/</guid>
      <pubDate>Tue, 14 Oct 2025 14:50:03 GMT</pubDate>
    </item>
    <item>
      <title>Anthropic 联合创始人承认，他现在“非常害怕”……“我们面对的是一个真实而神秘的生物，而不是一个简单且可预测的机器……我们需要勇气看到事物的本来面目。”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o6cow1/anthropic_cofounder_admits_he_is_now_deeply/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o6cow1/anthropic_cofounder_admits_he_is_now_deeply/</guid>
      <pubDate>Tue, 14 Oct 2025 11:16:59 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>