<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Thu, 11 Sep 2025 15:14:59 GMT</lastBuildDate>
    <item>
      <title>有人解决了WAN模型的扩展问题吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ne9sxn/has_anyone_solved_the_scaling_problem_with_wan/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   wan一直是生成头像，视频，配音等的首选。但这是一个极端的计算密集应用。我正在尝试使用WAN构建产品，但面临缩放问题，尤其是在托管O​​SS版本时。 有人面临类似的问题吗？您如何解决/减轻几个客户的缩放问题？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ne9sxn/has_anyone_solved_the_scaling_problem_with_wan/&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ne9sxn/has_anyone_solved_the_scaling_problem_with_wan/</guid>
      <pubDate>Thu, 11 Sep 2025 14:09:14 GMT</pubDate>
    </item>
    <item>
      <title>使用AI（主要是LLM）的限制因素</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ne8pfp/the_limiting_factor_in_using_ai_mostly_llms/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    您无法自动化自己无法发音的东西。         eart e e e e e  p&gt; p&gt; p&gt; p&gt;原理：  在知识工作中，瓶颈不是信息的外部可用性。它是处理能力的内部带宽，这取决于您的先天能力和思想的训练状态。  source      我认为这已经发生了。但是，我主要在最了解的领域中受益。 This aligns with the hypothesis that AI is killing junior position in software engineering while senior positions remain untouched. AI should be used as a乘数，不是代孕。因此，总的来说，我们从训练我们的思想而不是AI-Improvements中总共受益。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/fastsascha   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ne8pfp/the_limiting_factor_in_ion_ai_ai_ai_aim_ables_llms/”&gt; [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ne8pfp/the_limiting_factor_in_using_ai_mostly_llms/</guid>
      <pubDate>Thu, 11 Sep 2025 13:23:02 GMT</pubDate>
    </item>
    <item>
      <title>个性化的超智能AI？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ne80cy/individuated_super_intelligent_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  不会为每个人创建超级智能AI，取消另一个人的超级智能吗？假设我们，我们，中国和法国没有三个国家拥有超级智慧？当然，已经有一个国家规模的支票和平衡。但是，不应该为每个人提供这种智力吗？肯定是某种神经链接还是类似？对于每个人，州和国家 /地区的超级情报AI，这些竞争性的智能都不会消除任何领域的过度影响吗？还是您认为超级智能会创造与国家分开的派系？如果超级智能知道这是徒劳的，并且浪费了精力和时间，它会停止零和游戏吗？超级智能会在宇宙中寻求其他形式的资源分配，或者至少具有像模拟这样的矩阵？  还是超级情报会创造较少的情报来创造军队？还是其他超级智能的存在会抑制其他超级智能？如果超级智能是彼此的检查和平衡，这将是双赢的情况吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ne80cy/individit_super_intelligent_ai/”&gt; [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ne80cy/individuated_super_intelligent_ai/</guid>
      <pubDate>Thu, 11 Sep 2025 12:52:14 GMT</pubDate>
    </item>
    <item>
      <title>AI及其对人类出生率/资源的影响</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ne6m07/ai_and_its_effects_on_human_birth_ratesresources/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在任何时间内都需要在生活的每个部门拥有超聪明的人类AI，这将如何影响人口和人类消费的人口率和资源（假设AI不会杀死人）？当然，人工智能会使人类的生活更轻松，寿命更长，但是它将如何影响人口增长？所有这些AI的支持会给更多的人类出生，更少还是保持不变？ AI人群怎么样？小行星/行星开采是否可以无限期地增加人口？我们不应该作为人类的目标，而不是投资于战争之类的其他事物吗？还是我们创造了一些无限的能量来炼金术元素？中国的“人造太阳”可以用来做到这一点吗？如果是这样，我们是否需要耕种宇宙才能殖民其他行星？  也随机，类人体AI能够“顺其自然”？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ne6m07/ai_and_and_ist_isfects_on_human_human_birth_ratesratesRatesRatesRatesRatesResources/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ne6m07/ai_and_its_effects_on_human_birth_ratesresources/</guid>
      <pubDate>Thu, 11 Sep 2025 11:45:56 GMT</pubDate>
    </item>
    <item>
      <title>是什么阻止科技公司向AI聊天机器人分开的法律人物？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ne6dr9/whats_stopping_tech_companies_giving_ai_chatbots/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我最近阅读了这篇文章，有人说公司可能会将代理商从自己创建的AI机器人转移到他们创建的AI机器人，并将该实体用作责任屏蔽。   扰乱了我的责任，我可以看到一定有限的企业造成了限制的企业。实体，与董事和股东分开。因此，尽管事实并非人类，甚至不是有意义的，但它可能负责债务或负债。 那么，什么可以阻止公司将创建的产品视为单独的法律人物？ For example, they put it in the terms and conditions that we never read, on apps before we use a chatbot, that the company would never be held responsible for damages but the bot itself can be? Is this some messed up loophole where we&#39;d have all these AI products given &#39;punishment&#39; but the humans responsible for their creation just spin up another one in its place?   提交由＆＃32; /u/404notafish     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ne6dr9/whats_stopping_tech_companies_giving_ai_chatbots/</guid>
      <pubDate>Thu, 11 Sep 2025 11:33:48 GMT</pubDate>
    </item>
    <item>
      <title>在LLM中击败Horace He（Ex-Openai CTO）中的非确定性</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ne4mvi/defeating_nondeterminism_in_llm_inference_by/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   可重复性是科学进步的基础。但是，很难从大语言模型中获得可复制的结果。   aint是事实。取自在llm推理中击败非固定主义 horace he（ex-openai cto）。当发生这种情况时，很小的数字差异可能会蔓延。   他们设法通过[阅读本文解决了它，因为我的释义将是废话]，这意味着答案在温度零，测试和调试中可重复，并且在整个运行中都可以进行比较。  尽管这确实意味着您放弃了一些速度和巧妙的调度，因此在繁忙的服务器上，延迟和吞吐量可能会更糟。 历史上，我们已经能够选择一个模型，例如以速度进行一些智能进行贸易。我想知道最终在确定性和概率之间是否会有一个切换来调整速度/准确性平衡？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/paddy-makk     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ne4mvi/defeating_nondeterminism_in_llm_inference_by/</guid>
      <pubDate>Thu, 11 Sep 2025 09:53:45 GMT</pubDate>
    </item>
    <item>
      <title>Big AI推动了“我们需要击败中国”的叙事，因为他们想要胖政府合同和零民主监督。这是一个古老的把戏。恐惧卖出。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ne4e1h/big_ai_pushes_the_we_need_to_beat_china_narrative/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在整个冷战期间，军事工业综合体花费了一笔命运，推动了虚假的叙述，即苏联军队比实际上更先进。 为什么？为了确保国会的钱一直在流动。 他们撒谎了……撒谎……并再次撒谎，以获得更大的国防合同。 现在，显然，          Big&gt; Big Tech竭尽全力地使他们能够为他们提供了什么才能使他们陷入困境的境地，他们希望他们能够为他们提供任何争议    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/katxwoods   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ne4e1h/big_ai_ai_pushes_the_we_we_we_need_to_to_to_to_beat_china_narrative/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ne4e1h/big_ai_pushes_the_we_we_need_te_to_to_to_to_to_to_beat_china_china_narrative/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ne4e1h/big_ai_pushes_the_we_need_to_beat_china_narrative/</guid>
      <pubDate>Thu, 11 Sep 2025 09:37:55 GMT</pubDate>
    </item>
    <item>
      <title>AI幻觉premed学校</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ne4cl4/ai_hallucinations_premed_school/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好，我希望你们一切都很好。我只是想知道，我正在学习医学考试，这将是多项选择问题。对于有钱的人来说，这是一个不公平的优势，因为他们可以在欧洲在这里支付一家教师。专业人士和勺子向他们提供信息。获得类似事物的唯一最接近的方法实际上是在Chatgpt或任何其他提供解释的AI上使用学习模式。我说的是生理生物化学解剖学。 It actually helps to get to understand the reason for the names of this and that because there’s a lot of arbitrary stuff and we just need to make sense to memorize at the very least, this is how I work now I was wondering aI hallucination is a huge risk because it would cost points and only the best get to pass so I’m wondering, what do you think guys are that rate of hallucination regarding factual stuff just like purely physics or medicine or chemistry or anatomy because if plausible error sleeps through我已经完成了。 否则，我会被纯净的材料所困，并且在哪个网站上找到了什么是真实的信息？毫不信任的是逗号的人。鲨鱼世界。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/gzeod      [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ne4cl4/ai_hallucinations_premed_school/</guid>
      <pubDate>Thu, 11 Sep 2025 09:35:21 GMT</pubDate>
    </item>
    <item>
      <title>数据科学家的日记🥼</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ndzv9k/diary_of_a_data_scientist/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在pseduoanonymous的在线参与时，请记住，代理AI bot网络在大规模规模上运行猖ramp。该行业并没有真正具有复杂的保护来防止这种情况，因为可以对这些代理进行编程以模仿真实的用户行为。 IP地址和硬件地址可能会被欺骗以避免黑名单，而在夏天，不好的演员比蟑螂更难摆脱。 这甚至不是理论上的，该工具已经取得了进步，以至于愚蠢地容易设置这些自动化，以帮助您一点点的知识知识，您可以从字面上帮助您实施一个llm。由于Openai和其他提供商在训练模型中为我们造成了困难的局面，因此这种架构确实并不是那么复杂。  tl; dr-不要相信在深层划分和炎症时期受到了社交媒体很可能被操纵的情况时，在深层划分和炎症的情况下，人们不相信流行的，更新的Reddit/facebook/insta/x意见。我建议采用一个零信任模型的未来，未经验证的社交媒体意见，因为我真正相信这些社交媒体平台现在已经妥协了，攻击向量是...我们所有人。提交由＆＃32; /u/orygregs     [link]    32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ndzv9k/diary_of_a_data_scientist/</guid>
      <pubDate>Thu, 11 Sep 2025 04:47:14 GMT</pubDate>
    </item>
    <item>
      <title>视觉语言动作模型</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ndzjh6/visionlanguageaction_models/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我一直在关注最近的 vision-language-action模型（vlams） ，对我来说，它们标志着一个有趣的转变。多年来，AI在数字域中一直是最强的 - 推荐引擎，适度，交易。安全空间。但是，一旦您将其推向物理世界，事情就会崩溃。汽车错误判断，机器人跌跌撞撞，无人机反应过度。问题不仅是表现，还信任。  vlams的目标是缩小这一差距。这个想法很简单，但雄心勃勃：结合感知（观察），语言（理解目标）和行动（做）。    最近的一些例子引起了我的注意：   推理。   wayve的lingo-2   - 用自然语言解释了其决定，从而增加了透明度。  我发现令人信服的是更大的转变。这些不仅仅是预测引擎；他们正朝着体现的智能迈进。借助综合数据，多模式推理以及这些架构结合在一起，AI开始看起来不像纯软件，更像是代理。 我一直回到：基准测试的问题看起来很棒，但是当模型面临真正罕见的边缘案例时会发生什么？从未见过的东西？有些人浮出水面的想法 。提交由＆＃32; /u/u/d3the_h3ll0w      [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ndzjh6/visionlanguageaction_models/</guid>
      <pubDate>Thu, 11 Sep 2025 04:28:12 GMT</pubDate>
    </item>
    <item>
      <title>我们几乎没有理解智力，不介意制作Agi</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ndmo8i/we_are_nowhere_near_understanding_intelligence/</link>
      <description><![CDATA[Hey folks, I&#39;m hoping that I&#39;ll find people who&#39;ve thought about this. Today, in 2025, the scientific community still has no understanding of how intelligence works. It&#39;s essentially still a mystery. And yet the AGI and ASI enthusiasts have the arrogance to suggest that we&#39;ll build ASI和Agi。 即使我们不操知道智能是如何工作的。 他们甚至听到他们在说什么？ 为什么人们不推迟谈论AGI或ASI的任何人并问一个简单的问题：                ＆quot“您要建造一台机器来熟练。真的很快，告诉我智能是如何工作的？＆quort  已经制造了一些很棒的工具并将制造。但是我们不是在这里建立智能。 它是2025年皇帝的新衣服的版本。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/lazyoil8672     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ndmo8i/we_are_nowhere_near_understanding_intelligence/</guid>
      <pubDate>Wed, 10 Sep 2025 18:43:31 GMT</pubDate>
    </item>
    <item>
      <title>“我创建了自己的AI医疗团队。这改变了医生治疗癌症的方式。”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ndi9sr/i_created_my_own_ai_medical_team_it_changed_the/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    https://www.statnews.com/2025/2025/09/09/10/10/10/10/10/ai-cancer-cancer-custment-custom-deateat-custom-docompom--docons-procy/ i&gt;     医疗AI代理名为“ Haley”，是为使用OpenAI，Google，Anthropic和XAI的基础基础模型而创建的，但具有大量的医疗环境，可以将知识探索与精心准备的所有病史相结合。我为Haley提供了与所有医生在几周前见过的完全相同的数据。我完整的Mychart历史。我的实验室。成像结果。医生指出。 在几分钟之内，海莉标记了一种有关模式：轻度贫血，铁蛋白升高，免疫球蛋白低 - 免疫功能障碍和骨髓问题的迹象。海莉建议进行“无血清轻链”血液测试和骨髓活检。以前没有提出过这些。相同的数据，新见解。  然后我扩大了团队。我建立了一个AI特工的小组 - 肿瘤学家，胃肠病学家，血液学家，ER DOC等人都接受了训练，可以像他们的人类一样思考。我一次通过每个案例进行了相同的案例。我创建了一个合成代理人希波克拉底，担任董事会主席。他听了他们的所有人，并给了我一个合并的建议。 我创建了自己的虚拟多学科医疗团队。他们照亮了我的医生错过的道路。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ndi9sr/i_created_my_own_own_ime_ai_medical_medical_team_it_it_changed_the/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ndi9sr/i_created_my_my_ewn_ai_medical_medical_medical_team_it_it_it_changed_the/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ndi9sr/i_created_my_own_ai_medical_team_it_changed_the/</guid>
      <pubDate>Wed, 10 Sep 2025 16:02:38 GMT</pubDate>
    </item>
    <item>
      <title>此时，AI伦理学家只是喊着空白吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ndf081/are_ai_ethicists_just_shouting_into_the_void_at/</link>
      <description><![CDATA[https://leaddev.com/ai/devs-fear-the-ai-race-is-throwing-ethics-to-the-wayside I意思是资本主义，但确实感觉像任何关心这一浪潮的道德方面正在与失败的战斗作斗争吗？  鲁米·阿尔伯特（Rumi Albert），工程师和哲学教授目前在纽约Fei Tan College教授AI道德课程：“我认为[这些系统性问题]已经达到了一个规模，使他们越来越多地将其视为外部性， 在RUG下，在AI的ai ai实验室中，诸如“快速发展和市场”的位置越来越高， p&gt;技术进步远远超过了我们在道德方面取得的进步...我认为，行业的快速发展超过了道德保障的整合，这是我认为我们都需要解决的问题。 href =“ https://www.reddit.com/user/scarey102”&gt;/u/scarey102     [link] href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ndf081/are_ai_ethicists_just_just_shouting_into_into_the_void_at/”&gt; [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ndf081/are_ai_ethicists_just_shouting_into_the_void_at/</guid>
      <pubDate>Wed, 10 Sep 2025 14:00:27 GMT</pubDate>
    </item>
    <item>
      <title>新的基于光的AI芯片可提高100倍！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nd66yq/new_lightbased_ai_chip_proves_to_be_up_to_100x/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  一个工程师团队创建了一个新的光学芯片，该芯片使用光（光子）而不是电力，而不是用于关键AI操作（例如图像识别和模式检测）。它将数据转换为激光光，通过微小的片上镜头对其进行处理，并同时处理多个颜色的多个流，在数字分类等测试中的精度为98％，但最高可提高能源效率！  这意味着什么： 众所周知，AI使用疯狂的功率（数据中心与小国家的能源利用匹配），因此，这种光子突破可以削减成本，启用更大的模型，并使AI更绿色，使从智能手机到超级计算机的所有事物更加绿色，并且更可扩展。这是迈出混合电光芯片的一步href =“ https://news.ufl.edu/2025/09/optictal--ai-chip/”&gt; https://news.ufl.edu.edu/2025/09/optictial-aptility-ai-chip/  提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nd66yq/new_lightbasedbased_ai_ai_ai_chip_proves_to_be_be_up_up_to_100x/”&gt; [links]       [注释]    ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nd66yq/new_lightbased_ai_chip_proves_to_be_up_to_100x/</guid>
      <pubDate>Wed, 10 Sep 2025 05:51:52 GMT</pubDate>
    </item>
    <item>
      <title>每月“有...是否有...”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果您有要使用AI的用例，但不知道要使用哪种工具，那么您可以在这里要求社区提供帮助，在此帖子之外，这些问题将被删除。 每个人都可以回答：不促进自我促销，否参考或跟踪链接。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n5ppdb/monthly_is_is_there_a_a_tool_for_for_post/”&gt; [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>