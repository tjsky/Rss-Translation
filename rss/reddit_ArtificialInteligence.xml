<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Wed, 20 Aug 2025 09:17:12 GMT</lastBuildDate>
    <item>
      <title>AI音乐越过创意门槛了吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mv9bvk/has_ai_music_crossed_the_creative_threshold_yet/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我一直在玩音乐gpt及其令人惊讶的AI构图已经走了多远。但是我仍然无法决定它是否只是缝制的模式，还是逐渐变成真正的创造力。有些曲目听起来启发了其他曲目听起来很空洞。你怎么认为？ AI只是混音还是可以达到真正的音乐直觉？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/nawang013     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mv9bvk/has_ai_music_music_crossed_the_creative_theres_threshord_yet/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mv9bvk/has_ai_music_crossed_the_creative_threshold_yet/</guid>
      <pubDate>Wed, 20 Aug 2025 08:45:30 GMT</pubDate>
    </item>
    <item>
      <title>老灯塔守护者Elias ...</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mv72a8/the_old_lighthouse_keeper_elias/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我有一个有趣的事实，我希望有人能够向我解释。我以相同的提示提示Openai的OSS和Google的双子座：用10个句子写一个故事。&lt; /strong&gt; 温度和top_p设置为0，因此十亿分之一个没有盲人的机会。  在世界上所有可能的故事中，这两种模型都选择了相同的主角-Elias 。如何解释这个？毕竟，培训数据以及令牌字典可能不同。因此模型不应产生相同的输出。&lt; /p&gt; 证明：  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/sapdalf     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mv72a8/the_old_lighthouse_keeper_elias/</guid>
      <pubDate>Wed, 20 Aug 2025 06:23:15 GMT</pubDate>
    </item>
    <item>
      <title>新研究论文：良性机器：迈向人工通用科学</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mv4ccd/new_research_paper_virtuous_machines_towards/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   AI系统现在能够通过科学方法进行工作。 新的arxiv论文（独立设计和执行了科学方法，在这种情况下是关于视觉工作记忆和心理旋转的心理学研究，产生了严格的手稿。 您对这些系统如何重塑科学研究有何看法？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/wheasey     [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mv4ccd/new_research_paper_virtuous_machines_towards/</guid>
      <pubDate>Wed, 20 Aug 2025 03:49:47 GMT</pubDate>
    </item>
    <item>
      <title>我们还没有准备好超级智能</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mv3oj3/were_not_ready_for_superintelligence/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我是一个新生的新生，对Agi几乎一无所知，我想要的人是从我和公众和公众了解的人（以了解大多数人的想法）的人。 此视频概述了一项研究 - 称为“ AI 2027” - 研究人员根据心理学，资本主义和地缘政治来预测AGI和人类的结果。作为一个不使用AI并且不喜欢计算机科学的人，但了解心理学和政治学并热爱数学，视频中介绍的场景非常可信，非常非常恐怖。  我想帮助防止像研究人员所预测的场景那样的未来，但是这样做意味着压力的生活，同时忘记了我5岁以来我实现的梦想 - 根据这项研究，无论如何，无论如何 都可能无关紧要。 我需要反馈：  1）这些威胁是如何真正的？这是我第一次考虑过改变现实和社会的AI以及如何开发AGI。   2）是否应该改变我的大学，职业和人生目标？我想知道每个人的想法，从专家到从未像我这样使用或想到AI的人。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mv3oj3/were_not_for_for_for_superintelligence/”&gt; [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mv3oj3/were_not_ready_for_superintelligence/</guid>
      <pubDate>Wed, 20 Aug 2025 03:16:13 GMT</pubDate>
    </item>
    <item>
      <title>我觉得奇怪的是，公司因AI而裁员</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1muswha/i_find_it_odd_that_companies_are_laying_people/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果我是首席执行官，我会继续招聘狂欢。在我的脑海中，如果AI将成为力量乘数，那么AI： 在AI：  10个人= 10个人= 10个人的工作  ai：  1个人= 10 x Person = 10 x多工作        10人= 10个人= 100 x多工作     ，但我都知道所有人都属于人们。没有人正在接受培训，没有公司像我们雇用AI优先的人一样。您为什么认为那是？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/saaSbase_dev     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1muswha/i_find_it_it_itd_that_that_companies_are_are_laying_people/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1muswha/i_find_it_odd_that_companies_are_laying_people/</guid>
      <pubDate>Tue, 19 Aug 2025 19:46:44 GMT</pubDate>
    </item>
    <item>
      <title>医疗编码收购已经开始。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1muqkt8/the_medical_coding_takeover_has_begun/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我的姐姐，明尼苏达州一家大型诊所的前医学编码员，有各个地方告诉我，他们刚刚向520个医疗编码员解雇了她认为是由于自动化所致。她决定在其他地方找到工作，因为工作保障已经不存在了。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/mrnoshitsgiven     [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1muqkt8/the_medical_coding_takeover_has_begun/</guid>
      <pubDate>Tue, 19 Aug 2025 18:23:36 GMT</pubDate>
    </item>
    <item>
      <title>动态思想 - 球引擎：基于物理隐喻具有进化和创造力的物理隐喻的AI架构概念</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mumdui/dynamic_thoughtsphere_engine_an_ai_architecture/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mumdui/dynamic_thoughtsphere_engine_an_ai_architecture/</guid>
      <pubDate>Tue, 19 Aug 2025 15:53:39 GMT</pubDate>
    </item>
    <item>
      <title>您有医疗保健</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mul5xi/ai_in_healthcare/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  任何人从约翰·霍普金斯（Johns Hopkins）完成了医疗保健计划的AI？尽管我目前的知识是基本的，但我非常热衷于学习AI。我想知道这门课程是否会有益，并为我的职业发展提供帮助。任何建议或见解都将不胜感激！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/spiritual-might-11191     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mul5xi/ai_in_healthcare/</guid>
      <pubDate>Tue, 19 Aug 2025 15:10:16 GMT</pubDate>
    </item>
    <item>
      <title>AI是一个大规模宣传事件</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mukq9j/ai_is_a_massdelusion_event/</link>
      <description><![CDATA[Charlie Warzel: “It is a Monday afternoon in August, and I am on the internet watching a former cable-news anchor interview a dead teenager on Substack. This dead teenager—Joaquin Oliver, killed in the mass shooting at Marjory Stoneman Douglas High School, in Parkland, Florida—has been reanimated by generative AI, his voice and dialogue在他的写作和家庭视频镜头上建模。 “吉姆·阿科斯塔（Jim Acosta）是前美国有线电视新闻网（CNN）进行采访的人，他似乎完全被这一前提购买了，这加剧了超现实性：即使互动是如此奇怪，他也直截了当地发挥作用。阿科斯塔（Acosta）提出了有关奥利弗（Oliver）利益以及少年如何死亡的简单问题。聊天机器人是由奥利弗（Oliver）的父母完全合作倡导枪支管制的，就像新闻稿一样：“我们需要为对话和联系创建安全的空间，以确保每个人都感到被看见。它提供了诸如“更多的友善和理解可以真正有所作为。”在现场聊天中，我要看一些问题，这些方法很难进行，我正在努力处理这些方法。当批评家帕克·莫洛伊（Parker Molloy）所说的那样，这个时刻的事情很难处理，因为我将猴子的爪子以可能使奥利弗（Oliver）的死者告知，所以在谋杀案中，我对此感到震惊同时，我了解奥利弗（Oliver）的父母的强迫，仍在处理他们的深刻的悲伤，以保留儿子的记忆力，并以毫无意义声音？ “访谈引发了过去三年中非常熟悉的感觉。这是一个朝着未来的社会竞赛的沉没感觉，使人感到无流血，匆忙构想和转会。 我们真的在这样做吗？谁认为这是个好主意？从这个意义上说，Acosta采访只是一种感觉像集体妄想的产物。我已经意识到，这种震惊，混乱和矛盾的奇怪酿造是生成时代的定义情感。大肆宣传三年后，AI持久的文化影响之一似乎是使人们感到自己正在失去它。”  阅读更多： https://theatln.tc/obfxrylp  href =“ https://www.reddit.com/user/theatlantic”&gt;/u/u/theatlantic     ”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mukq9j/ai_is_a_massdelusion_event/</guid>
      <pubDate>Tue, 19 Aug 2025 14:54:34 GMT</pubDate>
    </item>
    <item>
      <title>过去的一周在AI：Chatgpt的Picker Dremma，Musk的法律动作和Anthropic的才能抢夺</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mukem4/this_past_week_in_ai_chatgpts_picker_dilemma/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  值得庆幸的是，与上周（😅）相比，这是一个安静得多的一周，但肯定仍然有一些值得注意的消息。这是您在2分钟或更低的情况下应了解的一切：    chatgpt的型号选择器回来了： openai重新引入“自动”，“快速”，“思维”，“思维”和gpt-4o。 critics call it a stunt, while Perplexity frames it as pro-open web and user safety. Musk vs. Apple: Elon Musk says he’ll sue Apple for allegedly rigging App Store rankings against Grok/X. xAI leadership change: Co-founder Igor Babuschkin left xAI to launch Babuschkin Ventures focused on AI safety/startups. Anthropic acqui-hires Humanloop: Humanloop’s team joins Anthropic to help with enterprise tooling around evaluation, safety, and reliability. Claude can end abusive chats (rarely): Anthropic says Opus 4/4.1 may terminate extremely harmful conversations as a last resort;    Claude Sonnet 4→1m token上下文：启用全案例分析和大量文档综合；在关于拟人API和基岩的beta中，缓存以降低成本。   gemma 3 270m 3 270m（Google）：一个紧凑的，能节能的模型，用于以随后的微调和说明进行了优化，适用于device/decectization + sonnet execte + sonnet execture&gt; claude&gt; claude&gt; clauce&gt; clauce&gt; clauce&gt; SONNET 4执行“计划与执行”选项。可以在“ Opus 4.1计划模式”下找到它。 in /model. New learning modes in Claude: /output-style plus Explanatory vs. Learning modes for customizable responses. GPT-5 tone tweak: Adjusted to feel warmer and more approachable after feedback that it was too formal. Cursor CLI update: Adds MCPs, Review Mode, /compress， @ -files和其他UX改进。  就是这样！与往常一样，请让我知道我是否错过了任何东西。 您还可以看更多像AI工具一样的一周，例如AI工具，研究等等。提交由＆＃32; /u/u/rfizzy     [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mukem4/this_past_week_in_ai_chatgpts_picker_dilemma/</guid>
      <pubDate>Tue, 19 Aug 2025 14:42:38 GMT</pubDate>
    </item>
    <item>
      <title>我认为我使用的太多了。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mujnt9/i_think_im_using_ai_too_much/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我有一些问题，我觉得我可以与任何人讨论。日记有帮助，但有时我想要一些建议或反馈。我曾经听说Chatgpt没有真正的见解或理解，只是回答并反映您的日记。所以，我去了chatgpt和日记。起初，我没有看到危害，这有助于我井井有条。但是现在我对此感到有些奇怪，因为我认为我可能有点依赖？我一直在使用它来处理自己的情绪，我觉得我不应该，但我也没有证据表明这对您是错误或坏的。  您怎么看??   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/supernodle6     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mujnt9/i_think_im_using_ai_too_much/</guid>
      <pubDate>Tue, 19 Aug 2025 14:15:08 GMT</pubDate>
    </item>
    <item>
      <title>71％的人担心AI会取代他们的工作</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1muiyc7/71_of_people_are_concerned_ai_will_replace_their/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这是我在AI上看到的最负民意调查。 -71％担心AI会从事工作-66％担心AI将取代关系-61％担心AI增加电力消耗 请告诉我，Redditors并不是Reuters Poll的4,446人中的Redditors？      https://www.reuters.com/world/us/americans-fear-ai-perman-displacing-workers-workers-workers-reutersipsos-poll-finds-finds-2025-08-19/    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1muiyc7/71_of_people_are_are_concerned_ai_will_will_replace_their/”&gt; [links]      &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1muiyc7/71_of_people_are_are_concerned_ai_ai_will_will_will_will_replace_their/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1muiyc7/71_of_people_are_concerned_ai_will_replace_their/</guid>
      <pubDate>Tue, 19 Aug 2025 13:48:20 GMT</pubDate>
    </item>
    <item>
      <title>如果AI撞到能墙会怎样？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1muf2oo/what_happens_if_ai_hits_an_energy_wall/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/kerkula     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1muf2oo/what_happens_if_ai_hits_an_energy_wall/</guid>
      <pubDate>Tue, 19 Aug 2025 10:54:07 GMT</pubDate>
    </item>
    <item>
      <title>招聘人员有麻烦。在对70,000个应用程序的大型实验中，AI代理在雇用客户服务代表方面的表现优于人类招聘人员。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mudqib/recruiters_are_in_trouble_in_a_large_experiment/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  摘要摘要：“我们研究用AI语音代理人代替人类招聘人员进行求职面试的影响。我们与一家招聘公司合作，进行了一项自然现场实验，其中随机分配了70,000名申请人，由人类招聘人员，AI语音代理人进行采访，或者在两者之间做出选择。在所有三个条件下，人类招聘人员都根据申请人在访谈和标准化的测试中的表现评估了访谈，并做出了招聘决策。与专业招聘人员的预测相反，我们发现AI领导的访谈将工作报价提高了12％，工作开始时的工作率为18％，并且在所有申请人中的保留下降了17％。申请人在客户体验调查中接受类似的可能性和费率面试和招聘人员质量的工作机会。提供选择后，有78％的申请人选择AI招聘人员，我们发现证据表明测试分数较低的申请人更有可能选择AI。分析访谈成绩单表明，与人为主导的访谈相比，AI-LED访谈从申请人那里获得了更多与申请人的信息。招聘人员对AI-Interview的申请人的访谈表现更高，但在其招聘决策中为标准化测试增加了更大的权重。总体而言，我们提供证据表明AI可以与人类招聘人员进行求职面试，同时保持申请人的满意和公司运营。 href =“ https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5395709”&gt; https://papers.ssrn.com/sol3/sol3/papers.cfms.cfm提交由＆＃32; /u/metaknowing     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mudqib/recruiters_are_in_trouble_in_a_large_experiment/</guid>
      <pubDate>Tue, 19 Aug 2025 09:36:32 GMT</pubDate>
    </item>
    <item>
      <title>大脑专家警告</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1muconv/brain_experts_warning/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大多数不在reddit上的人可能会从YouTube和其他新闻媒体中了解更多有关AI的信息。这使我进入了史蒂夫·巴雷特（Steve Barrett）在首席执行官日记上的最新YouTube视频中。  访谈包括丹尼尔·阿曼·安斯（Daniel Amen Ans）博士特里（Daniel Amen Ans Terry）博士的著名专家。  最明显的担忧是，AI创作者不是为社会利益引入LLM，而是为了获得最大化的利润和对股东的信托义务。   llm减少了用户的认知负荷，这会增加痴呆症和alzeimhers病的风险。但是，大多数使用Chatgpt之类的人更关心其短期福利。  最近发表的MIT研究强调了学生在降低批判性思维，创造力，长期学习和保留记忆力方面的危险。该研究表明，使用AI的学生提供论文缺乏对工作的自豪和所有权，显然影响了教育成就和成就。  ai缺乏人类的文化价值，并且对培训偏见表示关注。  最新问题是埃隆·马斯克（Elon Musk）和特斯拉（Tesla）的安妮（Annie）。当Chatgpt取消性对话时，安妮欢迎他们。现在考虑一下13岁男孩的手中。对他们的心理和情感发展的影响。  父母在这些问题上做了什么？使用  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/sexyxymama2     ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1muconv/brain_experts_warning/</guid>
      <pubDate>Tue, 19 Aug 2025 08:29:00 GMT</pubDate>
    </item>
    </channel>
</rss>