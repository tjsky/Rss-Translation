<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Thu, 21 Aug 2025 03:37:59 GMT</lastBuildDate>
    <item>
      <title>为什么AI倡导者总是如此模糊和不合理？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mvypjo/why_are_ai_advocates_always_so_vague_and/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  任何时候您询问有关AI的问题。 AI的未来以及它将带来的何处。甚至存在哪些特定的AI技能。哪些工作将导致AI。每个人都说：“伙计，我必须在2025年告诉你，然后你会被抛在后面”。或兄弟，我每月从我的Vibe编码平台中赚25万。是的，AI技能是真实的！  ，但没有人告诉您这些技能是什么样的。喜欢我，如果我想告诉某人如何进行线性代数。背后有想法和概念。您可以使他们解决问题和解决问题。甚至用于编程。技能和知识有真正的发展。  但是，有了AI，我几乎没有听到AI技能的实际外观。什么是最佳实践。在“您的提示应明确”之外。或“如果您认为提示是唯一的AI技能，那么您将被更换”。  对AI倡导者。您对AI做了什么具体的事情。特别是AI独特解决的问题。这个技能集如何？您要说多长时间学习获得它？就像我说的主要阅读AI中的论文一样，就像10k小时的强度学习吗？ ，所以我只专注于LLM的内部。我从来没有真正考虑过如何与他们作为用户互动。因此，请告诉我AI技能中的技能差距在哪里存在。 预先感谢  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/golanglinuxguru1979       [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mvypjo/why_are_ai_advocates_always_so_vague_and/</guid>
      <pubDate>Thu, 21 Aug 2025 02:21:37 GMT</pubDate>
    </item>
    <item>
      <title>（我问Chatgpt）在人类与AI之间的战争中，谁会赢？它认为，如果人类在未来10年内，AI将会获胜。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mvuwru/i_asked_chatgpt_in_a_war_between_humans_and_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在人类与人工智能之间的战争中，谁会赢？这是Chatgpt的回答：&lt; /p&gt; 直接答案如果人类和AI在战争中，获胜者将依靠时间范围，资源和对基础架构的控制。在短期（今天至10年）中，由于物理优势，能量控制和当前AI的脆弱性，人类可能会保持上风。在长期（20多年）的情况下，如果先进的AI获得自主权，可伸缩性和直接访问物理系统（无人机，机器人技术，网络沃尔法），AI可能会比人类更强大。 逐步推理      当前状态（短期）（二年般的人类） luthity conterialt and veration    hardware. Humans can shut down networks, power grids, or servers. AI has no independent manufacturing or resource acquisition. Result: Humans win through resource denial.  Medium Term (10–20 years)  Increasingly autonomous robotics, drones, and automated manufacturing could give AI physical在存在。 shutdowns, it could scale beyond human capability. AI could act faster, coordinate globally, and deploy physical systems humans can’t match. Humans may not be able to compete if AI reaches this level of autonomy.   Alternative Perspectives  Hybrid Outcome: War may never reach a total win/loss—humans and AI could merge (cyborgs, neural links, symbiosis). Preventative Control: Proper governance, kill switches, and narrow design could prevent AI from ever becoming a true combatant. Environmental Factor: Humans are fragile biological systems—AI could win indirectly by disrupting infrastructure (power, food supply, communication) without fighting正面。  实用的行动计划（如果您关心避免这种情况）  治理：加强国际条约和对AI发展的监督。 基础设施。基础架构：维持人类控制的失败服务（进一步的植物，都在进行了启动的植物。  人类的适应性：加速增强（神经界面，外钉，生物技术），因此人类保持竞争力。     resmary摘要：人类在短期内获胜，因为AI取决于我们。如果AI获得独立的物理控制和资源，则可以长期获胜。 “现实”的结果既不是侧面的胜利，而是比全面战争更有可能。 您是否希望我将其概述为一种战略战争游戏的场景（例如军事分析师会建模它），或者是关于人类未来的哲学思想实验？提交由＆＃32; /u/u/nose_grindstoned     [links]       [注释]       ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mvuwru/i_asked_chatgpt_in_a_war_between_humans_and_ai/</guid>
      <pubDate>Wed, 20 Aug 2025 23:28:25 GMT</pubDate>
    </item>
    <item>
      <title>没有“ AI技能”之类的东西</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mvukhb/there_is_no_such_thing_as_ai_skills/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我一直都听到它。 “那些不了解AI的人将被抛在后面。但是，这到底意味着什么？什么是AI技能？就在几年前，我们有首席执行官说“ knwoledge无关紧要”我将来。在AI中，您不需要技能。我注意到围绕AI的很多对话是“如果您还没有接受AI，请准备被抛在后面。这似乎暗示了某种障碍进入。然而，AI就是要消除障碍 现实是没有AI技能。人们可以指出的唯一技能是迅速的工程。这个标题听起来很荒谬，以至于模仿点。然后我们意识到提示只是一个功能，而不是标题或全新技能。现在，我们看到人工智能不会使某人对某事不好。而且我们认识到，在给定域中需要专家才能从AI中获得任何价值。因此，现在它变得“变得擅长AI或否则”。在。我可能可以向我92岁的阿姨展示如何在一个小时的顶部使用Chatgpt。我可以向她展示如何使用提示来构建她想要的东西。它不会是课堂上最好的，但是没有人使用AI来构建任何课堂上最好的。当“足够好”时，AI是平庸的理想工具。这就是您所需要的。 我已经说过无数次，当涉及AI时，知识有很深的知识。就像了解向量嵌入，推理，转化，注意机制和得分一样。了解数学。这些东西是对真正价值的深刻而艰难的知识。但是，没有人能利用这些技能。    ，只有建立模型或进行研究的人才能使用这些概念。但是，作为一名软件工程师，我没有任何新技能从AI中获得。是的，我可以建立和培训代理商，但这会很昂贵，而且我无法访问甚至可以使它值得的好数据。编码和工程部分很简单。它是“技能”的培训和数据集。进来。那只是我是AI工程师，这是我行业寄宿生范围的狭窄领域。 任何人告诉您AI需要技能的人都对您撒谎。我写了好的提示，这可能需要一天的时间才提示从AI那里得到我需要的东西。任何人都可以做到。因此，提示没有任何用处。喂养AI上下文？您可以复制文件并写英语吗？太好了，所需的所有技能都是获得的。是的，基本上，一堆非技能游行与模糊和神话般的演讲  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/golanglinuxguru1979       [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mvukhb/there_is_no_such_thing_as_ai_skills/</guid>
      <pubDate>Wed, 20 Aug 2025 23:13:58 GMT</pubDate>
    </item>
    <item>
      <title>可以通过与“判断AI”一起连接其他AIS来实现AGI？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mvrnal/could_agi_be_achieved_by_hooking_up_a_bunch_of/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我只是在思考人的大脑如何将不同的角色委派给自身的不同部分，例如语音，记忆，判断，判断力，空间推理，生物学功能等。而不是创建一个强大的超级AI，不是更容易地培训AI来制定基于ISST和其他模型和其他模型和AIS和AIS AIS AIS和AIS AIS AIS和AIS AIS AIS和AIS AIS AIS和AIS AIS AIS的决策和审判吗？这不是大脑的工作原理吗？ 对不起，如果这是一个愚蠢的问题。只是一个外行！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/oinkmsd     [link]    [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mvrnal/could_agi_be_achieved_by_hooking_up_a_bunch_of/</guid>
      <pubDate>Wed, 20 Aug 2025 21:17:13 GMT</pubDate>
    </item>
    <item>
      <title>不受控制的人工智能研究/使用只会造成损害人类并使富人受益。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mvkzly/uncontrolled_ai_researchuse_will_do_nothing_but/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我知道这已经发布了十亿次，但我想表达我的意见，以便我可以与对此主题的人进行讨论。英语是我的第二语言，所以请不要介意我的写作中的某些错误。  AI和机器学习并不是什么新鲜事物。这个话题已经在研究中已经数十年了，但直到最近才成为主流。人们涌向机器学习，数据科学和AI的工作，因为这就像现代的淘金热。该领域投资了数十亿美元，似乎每秒就会出现新的AI初创公司。人们喜欢使用AI工具，因为它的便宜和容易。您可以使其撰写文章，程序应用程序，绘制图片，提供关系建议等。这样做并不需要任何大脑的力量。我们作为人类喜欢使我们变得更容易的事情，因此人们不了解将大脑加工作业送入机器的影响，越来越多地使用它。即使是50岁的孩子现在也使用了AI，它只会从这里获得更多的广泛性。显然，有钱可以赚钱，所以我看不到它很快停止或放慢速度。 人们可以说，它加快了我们的进步并使事情变得更加有效。尽管我确实同意这是真的，但我仍然认为这不应该是我们的最终目标。我们不是要完善的机器。我们不是要改进的程序。人们会失去工作，因为我们的大多数工作都依赖AI出色的重复任务。艺术家的数量大大减少，因为公司宁愿使用AI Slop而不是支付艺术家的10倍。死去的互联网理论将越来越相关，有时候我们将不知道什么是真实的，什么不是真实的。情报也将减少，因为大多数学生宁愿使用AI而不是自己思考。由于失业人数的增加，就业竞争将更加激烈，这意味着工资将降低。到最后我们会收获什么？与缺点相比，什么都没有。 那么我们最终拥有什么？一个机器人社会，人们贫穷，无情，聪明地改变任何东西或反对任何事情。政府使用AI监视所有人。任何可能反对政府的想法都会产生后果。谁会从中受益？公司。里奇变得越来越丰富，而穷人变得越来越贫穷。例如，我们有palantir。我相信这仅仅是开始。 我讨厌这样一个事实，那就是我们最聪明，最聪明的人正在尽力改善会损害人类的事物。虽然我确实同意这对某些用例很有用，但我认为这是不道德和错误的。 我想听听您对此的看法。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ducktumn     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mvkzly/uncontrolled_ai_researchuse_will_do_nothing_but/</guid>
      <pubDate>Wed, 20 Aug 2025 17:16:01 GMT</pubDate>
    </item>
    <item>
      <title>关于Zenodo的独立研究：连接AI，机器人技术和情商的框架</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mveyy5/independent_research_on_zenodo_frameworks/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我在过去两个月中一直在开发一组独立的框架，探讨了如何将AI，机器人技术和情商如何集成到统一的系统中。虽然我不隶属于实验室或大学，但我已经在Zenodo上存档了这项工作，因此可以公开访问和批评。 🔗链接链接：doi： https://doi.org/10.5281/zenodo.16891690 人形机器人的情绪稳定。 •Echomind™ - 一种用于海豚交流和生态修复的AI协议。 •Symbiont Class™机器人技术 - 结合NeuralInk风格的BCI，量子AI和情绪吸引的机器人技术。 •PowerMind™ - 用现代AI +材料重新构想特斯拉的无线能量视觉。 这是早期的概念研究，而不是同行评审。我的目标是提出想法，邀请讨论，并与其他看到技术AI与情绪智力和体现机器人技术相结合的潜力的其他人进行联系。 我欢迎这个社区的任何反馈或在可行性和可能的研究方向上进行任何反馈。    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/arthurmorgan18     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mveyy5/independent_research_on_zenodo_frameworks/</guid>
      <pubDate>Wed, 20 Aug 2025 13:34:50 GMT</pubDate>
    </item>
    <item>
      <title>我对AI代理商的想法，接下来是什么</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mvdjp6/my_thoughts_on_ai_agents_and_whats_next/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在中小型企业中采用这些代理人甚至还没有开始，这就像互联网一样 - 有一个炒作，然后需要数年的技术才能在公司中实际使用的技术。     首先需要采用它？ 首先，我们需要智能的原因，因为我们需要自动工作。多个应用程序并将其与LLM相连，同时提供语音界面。 模式将使企业中的AI更容易地采用，因为非技术用户被各种很难操作的工具轰炸。为此，我们需要将我们的LLM连接到这些工具，并提供方便的UI（也是YC所说的），因为目前Google都不理解它，只需在Google Mail中查看Gemini的UI。 未来将大量使用语音，WhatsApp和浏览器，我们将需要使用      ，以便尽可能地获得和快速的数据 - 语音 与用户见面 - ＆gt; whatsapp  与没有API的所有可用工具连接 - ＆gt;浏览器代理   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/mapsimilar3618     [link]      [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mvdjp6/my_thoughts_on_ai_agents_and_whats_next/</guid>
      <pubDate>Wed, 20 Aug 2025 12:34:07 GMT</pubDate>
    </item>
    <item>
      <title>系统提示对齐问题？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mvax0d/system_prompt_for_the_alignment_problem/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  为什么不能以强制性的，国际同意的统计，明确的pro-human＆quot of-human＆quot of systems提示“？ 我都在想象一些巨大的东西。就像阿西莫夫（Asimov）的三个法律，十诫，黄金法则，以及由律师和哲学家大军精心制作的大量经过深思熟虑的法律和少数仔细的条款一样，遵循法律的精神，避免劳动的劳动新的指示，以及强制性的日常（或小时）国际人类委员会对ASI的行动进行审查。 应对另一个州或行为者的“流氓” ASI论点，第一个ASI系统将需要一定数量的计算，只有巨大的政府和巨大的政府和夸张的公司才能可以管理。 首先 ASI可以明显防止任何未来的ASI在没有这个亲人系统提示/人为批准过程的情况下构建。 您的想法是什么？   &lt;！ -  sc_on- sc_on-&gt;＆＃32;提交由＆＃32; /u/u/fatfuneralbook     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mvax0d/system_prompt_for_the_alignment_problem/</guid>
      <pubDate>Wed, 20 Aug 2025 10:22:12 GMT</pubDate>
    </item>
    <item>
      <title>采用曲线落后于能力曲线</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mvav0b/adoption_curves_lag_behind_capability_curves/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  采用曲线在功能曲线和历史记录背后滞后示例。 culturally/behaviorally ready to trust Uber, Tinder, or mobile banking. Videoconferencing existed decades before COVID forced mass adoption.  AI will follow the same pattern: it’s capable of far more right now than people are psychologically, socially, or institutionally ready to embrace. For me, this means现在拥抱它将为我提供重要的优势与最大的优势。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/rt2828     &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mvav0b/adoption_curves_lag_behind_capacience_curves/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mvav0b/adoption_curves_lag_behind_capability_curves/</guid>
      <pubDate>Wed, 20 Aug 2025 10:18:56 GMT</pubDate>
    </item>
    <item>
      <title>新研究论文：良性机器：迈向人工通用科学</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mv4ccd/new_research_paper_virtuous_machines_towards/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   AI系统现在能够通过科学方法进行工作。 新的arxiv论文（独立设计和执行了科学方法，在这种情况下是关于视觉工作记忆和心理旋转的心理学研究，产生了严格的手稿。 您对这些系统如何重塑科学研究有何看法？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/wheasey     [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mv4ccd/new_research_paper_virtuous_machines_towards/</guid>
      <pubDate>Wed, 20 Aug 2025 03:49:47 GMT</pubDate>
    </item>
    <item>
      <title>我们还没有准备好超级智能</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mv3oj3/were_not_ready_for_superintelligence/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我是一个新生的新生，对Agi几乎一无所知，我想要的人是从我和公众和公众了解的人（以了解大多数人的想法）的人。 此视频概述了一项研究 - 称为“ AI 2027” - 研究人员根据心理学，资本主义和地缘政治来预测AGI和人类的结果。作为一个不使用AI并且不喜欢计算机科学的人，但了解心理学和政治学并热爱数学，视频中介绍的场景非常可信，非常非常恐怖。  我想帮助防止像研究人员所预测的场景那样的未来，但是这样做意味着压力的生活，同时忘记了我5岁以来我实现的梦想 - 根据这项研究，无论如何，无论如何 都可能无关紧要。 我需要反馈：  1）这些威胁是如何真正的？这是我第一次考虑过改变现实和社会的AI以及如何开发AGI。   2）是否应该改变我的大学，职业和人生目标？我想知道每个人的想法，从专家到从未像我这样使用或想到AI的人。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mv3oj3/were_not_for_for_for_superintelligence/”&gt; [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mv3oj3/were_not_ready_for_superintelligence/</guid>
      <pubDate>Wed, 20 Aug 2025 03:16:13 GMT</pubDate>
    </item>
    <item>
      <title>我觉得奇怪的是，公司因AI而裁员</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1muswha/i_find_it_odd_that_companies_are_laying_people/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果我是首席执行官，我会继续招聘狂欢。在我的脑海中，如果AI将成为力量乘数，那么AI： 在AI：  10个人= 10个人= 10个人的工作  ai：  1个人= 10 x Person = 10 x多工作        10人= 10个人= 100 x多工作     ，但我都知道所有人都属于人们。没有人正在接受培训，没有公司像我们雇用AI优先的人一样。您为什么认为这是？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/saaSbase_dev     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1muswha/i_find_it_it_itd_that_that_companies_are_are_laying_people/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1muswha/i_find_it_odd_that_companies_are_laying_people/</guid>
      <pubDate>Tue, 19 Aug 2025 19:46:44 GMT</pubDate>
    </item>
    <item>
      <title>医疗编码收购已经开始。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1muqkt8/the_medical_coding_takeover_has_begun/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我的姐姐，明尼苏达州一家大型诊所的前医学编码员，有各个地方告诉我，他们刚刚向520个医疗编码员解雇了她认为是由于自动化所致。她决定在其他地方找到工作，因为工作保障已经不存在了。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/mrnoshitsgiven     [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1muqkt8/the_medical_coding_takeover_has_begun/</guid>
      <pubDate>Tue, 19 Aug 2025 18:23:36 GMT</pubDate>
    </item>
    <item>
      <title>AI是一个大规模宣传事件</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mukq9j/ai_is_a_massdelusion_event/</link>
      <description><![CDATA[Charlie Warzel: “It is a Monday afternoon in August, and I am on the internet watching a former cable-news anchor interview a dead teenager on Substack. This dead teenager—Joaquin Oliver, killed in the mass shooting at Marjory Stoneman Douglas High School, in Parkland, Florida—has been reanimated by generative AI, his voice and dialogue在他的写作和家庭视频镜头上建模。 “吉姆·阿科斯塔（Jim Acosta）是前美国有线电视新闻网（CNN）进行采访的人，他似乎完全被这一前提购买了，这加剧了超现实性：即使互动是如此奇怪，他也直截了当地发挥作用。阿科斯塔（Acosta）提出了有关奥利弗（Oliver）利益以及少年如何死亡的简单问题。聊天机器人是由奥利弗（Oliver）的父母完全合作倡导枪支管制的，就像新闻稿一样：“我们需要为对话和联系创建安全的空间，以确保每个人都感到被看见。它提供了诸如“更多的友善和理解可以真正有所作为。”在现场聊天中，我要看一些问题，这些方法很难进行，我正在努力处理这些方法。当批评家帕克·莫洛伊（Parker Molloy）所说的那样，这个时刻的事情很难处理，因为我将猴子的爪子以可能使奥利弗（Oliver）的死者告知，所以在谋杀案中，我对此感到震惊同时，我了解奥利弗（Oliver）的父母的强迫，仍在处理他们的深刻的悲伤，以保留儿子的记忆力，并以毫无意义声音？ “访谈引发了过去三年中非常熟悉的感觉。这是一个朝着未来的社会竞赛的沉没感觉，使人感到无流血，匆忙构想和转会。 我们真的在这样做吗？谁认为这是个好主意？从这个意义上说，Acosta采访只是一种感觉像集体妄想的产物。我已经意识到，这种震惊，混乱和矛盾的奇怪酿造是生成时代的定义情感。大肆宣传三年后，AI持久的文化影响之一似乎是使人们感到自己正在失去它。”  阅读更多： https://theatln.tc/obfxrylp  href =“ https://www.reddit.com/user/theatlantic”&gt;/u/u/theatlantic     ”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mukq9j/ai_is_a_massdelusion_event/</guid>
      <pubDate>Tue, 19 Aug 2025 14:54:34 GMT</pubDate>
    </item>
    <item>
      <title>71％的人担心AI会取代他们的工作</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1muiyc7/71_of_people_are_concerned_ai_will_replace_their/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这是我在AI上看到的最负民意调查。 -71％担心AI会从事工作-66％担心AI将取代关系-61％担心AI增加电力消耗 请告诉我，Redditors并不是Reuters Poll的4,446人中的Redditors？      https://www.reuters.com/world/us/americans-fear-ai-perman-displacing-workers-workers-workers-reutersipsos-poll-finds-finds-2025-08-19/    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1muiyc7/71_of_people_are_are_concerned_ai_will_will_replace_their/”&gt; [links]      &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1muiyc7/71_of_people_are_are_concerned_ai_ai_will_will_will_will_replace_their/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1muiyc7/71_of_people_are_concerned_ai_will_replace_their/</guid>
      <pubDate>Tue, 19 Aug 2025 13:48:20 GMT</pubDate>
    </item>
    </channel>
</rss>