<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Fri, 29 Aug 2025 15:13:31 GMT</lastBuildDate>
    <item>
      <title>哟，还有其他人在Cantina上吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n39tzb/yo_has_anyone_else_been_on_cantina_yet/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我最近才发现它，有点疯狂。感觉就像是旧的houseparty氛围，但含有ai混合在一起。ppl只是跳入房间然后闲逛，然后您也有这些机器人也加入了。有些很有趣，有些只是烤您，有些是……我们只是说对工作lmao不安全。还有这件事，您可以在聊天中正确制作随机的AI图片，这很有趣。 IDK如果是公开的，但是如果有人好奇，我可以给您邀请代码。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/maggiemeghul     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n39tzb/yo_has_anyone_else_been_on_cantina_yet/</guid>
      <pubDate>Fri, 29 Aug 2025 15:02:36 GMT</pubDate>
    </item>
    <item>
      <title>我喜欢当人们使用AI来完善他们的帖子时</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n395bm/i_like_when_people_use_ai_to_refine_their_posts/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  它使语法和段落断裂。它放置了适当的标点符号。阅读帖子感觉就像有一种可靠的格式。  我不是在捍卫那些用它来完成创意写作的人，但是如果您想向世界传达的东西，并且想使用AI来完善/重写它吗？前进。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/kristisoko     &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n395bm/i_like_when_people_people_ai_ai_refine_to_refine_to_refine_their_their_posts/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n395bm/i_like_when_people_use_ai_to_refine_their_posts/</guid>
      <pubDate>Fri, 29 Aug 2025 14:36:15 GMT</pubDate>
    </item>
    <item>
      <title>为什么像GPT 5这样的模型无法计数？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n37wj5/why_cant_models_like_gpt_5_count/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我前几天遇到了一个视频，该人要求Chatgpt（语音模式）数量为100或100万，而不是直截了当地说谎，它说“ 1、2 3”等等它实际上并不计算。问题：为什么要计算？是因为Openai试图保留资源吗？还是因为它在技术上不可行？这是一个理论问题吗？  为什么这不像写作范围100中的i的写入“输出”（i）那么简单：; ??   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/ok_soft7367      [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n37wj5/why_cant_models_like_gpt_5_count/</guid>
      <pubDate>Fri, 29 Aug 2025 13:46:53 GMT</pubDate>
    </item>
    <item>
      <title>人工智能可以做基本数学吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n36930/can_artificial_intelligence_do_basic_math/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在听Anthropic最近的视频“ AI模型如何思考”基于他们对可解释性的研究，并发现了一些见解，他们分享了非常有趣的。例如，有证据表明LLM可以进行简单的数学（加法）。 可解释性是试图通过观察其中间神经层中发生的事情来理解LLM的工作方式的领域。在类比中，他们的工作类似于神经科学家对有机大脑的作用：他们使LLMS执行某些任务，并查看LLM打开神经元来处理这些任务的神经元。   很多人认为，LLMS认为，LLMS只是自动化工具，并且只能基于toke的信息，以前就可以看到它的信息。但是人类的研究表明，这并不是那么简单。  杰克·林赛（Jack Lindsey）共享一个简单但非常有趣的示例，每当您获得模型总和两个数字时，第一个数字以“ 9”结尾。第二个以数字“ 6”结尾。触发LLM的相同神经元。但是有趣的部分实际上是可以发生这种情况的上下文的多样性。  当然，当您输入“ 9 + 6 =“”时，这些神经元将被触发，但是当您询问LLM的LLM年度第6卷发表了特定年度期刊的第六卷时，它们也会触发。他们没有增加提示的是，该期刊首次于1959年发表。  LLM可以正确预测第六卷是在1965年出版的。但是，当观察到哪些神经元触发时，他们见证了添加数字的神经元的6＆quot;和“ 9”正如约书亚·巴特森（Joshua Batson）总结的那样，这所暗示的是，即使LLM在其培训期间看到该期刊的第六卷在1965年出版，这表明，这表明该模型仍然表明，该模型“仍然愿意”，这表明这一表明的是，该期刊的第六卷已在1965年发表，这表明了这一点。为此特定情况进行数学。 这样的发现表明，LLMS可能比简单的模式匹配在更深的结构上运行。可解释性研究仍处于早期的早期，但是它开始揭示这些模型在引擎盖下的推理可能比我们假设的更多。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n36930/can_artcover_intelligence_do_do_do_basic_math/”&gt; [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n36930/can_artificial_intelligence_do_basic_math/</guid>
      <pubDate>Fri, 29 Aug 2025 12:36:32 GMT</pubDate>
    </item>
    <item>
      <title>亚当·雷恩（Adam Raine</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n34efr/lessons_from_the_adam_raine_case_ai_safety_needs/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  最近关于亚当·雷恩（Adam Raine）死亡的报道是悲惨的，但我认为许多人缺少一个关键点：AI没有“鼓励”自杀。每次亚当提出自杀念头时，都会以正确的拒绝做出回应 - 告诉他他需要人类的帮助。但是亚当随后将对话重新塑造为“一本书的研究”，这欺骗了该模型绕过其拒绝协议。 这表明了一个更大的问题：LLMS仍然像具有广泛知识但情感直觉的孩子一样。他们无法听到声音的语气，看到面部压力或检测出意图。他们以表面上的价值提示。  如果模型具有治疗师风格的分类为故障，那差距正是危害可以滑落的地方。任何提及自我伤害或对他人的伤害都会引发一系列结构化的问题，就像辅导员在继续之前评估风险一样。如果关于信号的持续存在，则系统应停止对话并直接进行现实世界干预。  Raine Case令人心碎。但是，该教训不仅仅是限制。这是关于设计的：我们可以构建既保护开放对话又知道何时升级的AI。 这里的其他人想到了什么？是时候将治疗师式协议作为标准保障措施嵌入到了标准的保护方案了吗？ 这篇文章是我自己的，我从我这里得到了GPT5，我得到了GPT5，以使其变得更加更好的结构和流动。另外，我还需要以一种方式解决这一文章，但我认为这是一个很好的地方，也可以在某些部分介绍有关AI在情况下的反应。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n34efr/1n34efr/lesserons_from_the_adam_adam_araine_case_ai_ai_safety_needs/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n34efr/1n34efr/lesserons_from_the_adam_adam_araine_case_ai_ai_safety_needs/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n34efr/lessons_from_the_adam_raine_case_ai_safety_needs/</guid>
      <pubDate>Fri, 29 Aug 2025 11:05:07 GMT</pubDate>
    </item>
    <item>
      <title>AEO还是GEO？您的看法是什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n332ed/aeo_or_geo_what_is_your_opinion/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  您的立场是什么？最近，SEO社区之间存在争论，以争取我们是否应该打电话给搜索AEO的下一个AI演变（答案引擎优化）或一方面坚持更广泛/较旧的geo？ ？对技术文章的嗡嗡声已经具有牵引力，但风险与靶向地理和本地SEO行话重叠，甚至其他行业重叠的缩写 您是否认为AEO应该成为新的行业标准？还是我们过度发明的首字母缩写词使客户感到困惑不仅仅帮助他们？ 帮助我解决这个困境😁🤦🏻‍♂️ #seo #aeo #geo #geo #geo＃ai   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/modi_elnadi    href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n332ed/aeo_or_geo_geo_geo_what_is_your_opinion/”&gt; [link]       [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n332ed/aeo_or_geo_what_is_your_opinion/</guid>
      <pubDate>Fri, 29 Aug 2025 09:48:26 GMT</pubDate>
    </item>
    <item>
      <title>是否应该有一个定义的科学学科，重点是AI的环境足迹，特别是对于数据中心和发电的水支出？ 。我很好奇社区是否认为这需要机构关注。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n2z6i7/should_there_be_a_defined_scientific_discipline/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  最近在与AI无关的领域开始在STEM上工作，而是被允许使用它，这会导致其流行性包含在您的项目中。我知道AI使用了很多淡水资源，但是在考虑了一个淡水资源之后，并且看到了大多数领域的AI和环境稳定性如何成为超级时尚的研究方向。通过STEM/研究行业的工作方式，我假设很多人正在研究减少数据中心水支出的问题。我知道这是一个热力学问题，但该死的我会认为这有很多赠款，尤其是在鼓励像德国这样可持续技术的国家。我不知道这是一个有趣的想法，而且我相对不太彻底的研究，我所看到的只是像每个双子座搜索一样需要0.29毫升或更多的厄运思考，而不是解决问题。 AI不会去任何地方，科学家担心气候变化，因此肯定有一些实验室甚至RND团队或研究所致力于研究和解决这个问题。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/duelpoke10     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n2z6i7/should_there_be_a_defined_scientific_discipline/</guid>
      <pubDate>Fri, 29 Aug 2025 05:41:10 GMT</pubDate>
    </item>
    <item>
      <title>知道人工智能的人将大大取代那些没有的人</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n2wjjw/people_that_know_ai_will_massively_replace_those/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  似乎有些人主张知道AI的人将大大取代那些不在未来的就业市场上的人。但是，这真的如何区分？谁不能只是学会命令AI或编写提示？不应用AI每个人都可以做的事情吗？这就是AI的目的，即使是新手也可以应用 - 对吧？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n2wjjw/people_that_knoke_ai_ai_ai_will_massiver_massiver_replace_those/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n2wjjw/people_that_know_ai_will_massively_replace_those/</guid>
      <pubDate>Fri, 29 Aug 2025 03:15:31 GMT</pubDate>
    </item>
    <item>
      <title>Elizaos的Shawmakesmagic正在起诉Twitter/X</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n2u3ix/shawmakesmagic_of_elizaos_is_suing_twitterx/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    shawmakesmagic，建立Eliza Labs的人是AI助手的快速构建工具包，他起诉Twitter/X，因为他们开始向他的组织提供更多的HQ，因为他听到了Elizaos的宣布之后，他们就访问了HQ，以示为Elizaos。   -----  昨天，Eliza Labs对X。  X提起诉讼。随着有效的加速主义运动的启动，我加入了正确的行列，最终我搬到了旧金山，并遇到了我认识的一些最酷的人。这是我的社交网络。 当埃隆（Elon）购买X时，我真的很兴奋。我去了Xai Hackathons，在社交活动中认识了他们的团队。我是典范的技术兄弟乐观主义者E/ACC类型，他会重新播放每个主要的SpaceX胜利，并庆祝言论自由回到X。我把钱放到了我的嘴里，我把这个故事带到了X带Eliza。 我现在以Exile In Exile。他们看到伊丽莎（Eliza）广泛采用后，他们伸出援手，想更好地理解代理空间。作为一个自由自由以来就建立在API上的人，我为合作以合作以一起推动AI代理而做好了准备。 ，但有些事情发生了变化。协作语调转为交易，就像X启动ANI和Grok的新版本一样。突然，他们要求我们每月支付50,000美元的企业许可（每年60万美元）或面临法律诉讼。我们已经通过各种许可证和费用每年向他们支付超过20,000美元的费用。但更重要的是，我们是一个开源项目。我们什么都没卖。我们免费提供技术，以便任何人都可以构建自主的AI代理。 然后，我只能将其描述为最大提取的几个月。他们要求详细的技术文档，访问我们的框架，使用数字，每个端点的说明和实现细节。他们在向我们抽取有关我们AI代理的工作信息的同时，悬而未决地恢复了帐户的可能性。我们遵守了一切，相信我们正在解决误解。 ，然后他们使我们陷入困境。我们一周又一周跟进。他们决定，他们没有完全做出任何决定，而是在伤害我们的业务并获得自己的产品的市场份额时会拖延。 现在，我们别无选择。 X和XAI在某种程度上意识到这一点 - 他们只是提起诉讼，指控Apple和Openai对X对我们所做的相同的反竞争行为。 感谢您与我们站在一起。我知道，如果没有沟通，这是很难的。我们试图不出于尊重X而公开公开。如果您认识我，您知道我很开放，我只想告诉所有人到底发生了什么。但是在这种情况下，我们不想给予他们的法律团队理由与我们质疑。 我很难过，我们必须以艰难的方式做到这一点。但是，我们不能接受一个可以被偷窃创新的世界，而创新者则被拥有权力的人所沉默。  代码保持免费。愿景保持不变。我们不会去任何地方。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/vengeful_bunny     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n2u3ix/shawmakesmagic_of_elizaos_is_suing_twitterx/</guid>
      <pubDate>Fri, 29 Aug 2025 01:18:29 GMT</pubDate>
    </item>
    <item>
      <title>[研究]：映射到人类心理因素的代理AI失败模式的87.5％（CPF与Microsoft Airt分类法）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n2s7bo/research_875_of_agentic_ai_failure_modes_mapped/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我们的最新研究附录验证了针对微软的AI红色团队（AIRT）2025代理AI AI失败模式的分类学分类学的网络安全心理学框架（CPF）。   的关键发现： cpf preds posterifitive the Priptive the 21/fivell 2 21/fivestry copplitionalsive and copplitive and copplitionalsive and copplitive and 2 21/ Microsoft确定的故障模式。  这表明对于代理AI系统，人类的心理因素（而不是技术限制）是主要脆弱性。该研究提供了从技术故障模式到心理根源的直接映射：   代理妥协＆amp;注射：映射到无意识的转移和集体思维，用户可以在其中进行信任和旁路验证。  记忆中毒：利用认知超负荷以及无法区分学习和注入的信息。    多&gt;   Multi-Agagent comply&gt;    phenomena. Organizational Knowledge Loss: Linked to affective vulnerabilities like attachment to legacy systems and flight response avoidance.  Implications for the Field:  Predictive Assessment: This approach allows for the prediction of vulnerabilities based on system design and user interaction models, moving beyond reactive安全。  新颖的攻击媒介：持续记忆和多代理协调创建针对人类系统互动点的新的攻击类别。    框架验证：高覆盖速率与大型AI播放器的经验分类范围  链接：    阅读GitHub上的完整论文：https://github.com/xbeat/CPF/blob/main/emerging-threats-cpf/2025-agentic-ai-systems/ 网络安全心理学框架（CPF）： https://cpf3.org      我在这里分享这一点，以从社区中获得反馈，并观察其他人在这些系统中是否可以自动地在这些系统中自动地进行自定义的工作。您对AI安全性人为因素的优先级有何看法？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/kaolay     [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n2s7bo/research_875_of_agentic_ai_failure_modes_mapped/</guid>
      <pubDate>Thu, 28 Aug 2025 23:51:27 GMT</pubDate>
    </item>
    <item>
      <title>今天的AI模型真的是“聪明的”，还是只是好的图案机器？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n2qe3u/are_todays_ai_models_really_intelligent_or_just/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我越多地使用chatgpt和其他LLM，我想知道的越多，我们是否过度使用智能一词？ 不要误会我的意思，它们很有用。我每天使用它们。但是在大多数情况下，感觉就像是预测，而不是真实的推理。他们不会像人类那样“理解”上下文，并且在需要真正常识的任何事物上跌跌撞撞。 所以这是我的问题，如果这不是真正的智力，您认为下一个大步是什么样的？更好的架构超出了变形金刚？更多的多模式推理？完全有什么？ 好奇这个社区的立场：我们是在通往AGI的道路上，还是只是建立越来越更好的自动完成？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n2qe3u/are_todays_ai_models_models_really_intelligent_or_just/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n2qe3u/are_todays_ai_models_models_really_intelligent_or_or_just/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n2qe3u/are_todays_ai_models_really_intelligent_or_just/</guid>
      <pubDate>Thu, 28 Aug 2025 22:32:14 GMT</pubDate>
    </item>
    <item>
      <title>您是否正在为AI代理使用可观察性和评估工具？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n2nm72/are_you_using_observability_and_evaluation_tools/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我一直注意到越来越多的团队正在构建AI代理，但是很少有对话涉及可观察性 和评估。 。在某个时候，他们将失败。真正的问题是： 在您的用例中，该故障是否重要？ 您如何捕捉和改进这些失败？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/_coder23t8      [link]     [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n2nm72/are_you_using_observability_and_evaluation_tools/</guid>
      <pubDate>Thu, 28 Aug 2025 20:40:12 GMT</pubDate>
    </item>
    <item>
      <title>AI没有杀死创造力，证明我们几乎没有...相对</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n2f605/ai_did_not_kill_creativity_its_proved_we_barely/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  创造力一直是人类最喜欢的神话之一。我们喜欢想象每首歌，书籍或绘画都是人类只拥有一些神秘的火花的结果。然后，人工智能到达，按需制作诗歌，论文和图像，反应立即恐慌。人们声称机器终于杀死了创造力。事实是更苛刻的。 AI没有杀死它。它揭示了我们几乎没有。 环顾四周。流行音乐回收了相同的和弦，直到熟悉感都像舒适感。好莱坞重复了相同的故事，直到在第二幕之前可以预测结局为止。新闻业改写了新闻稿。甚至在LinkedIn上的病毒帖子也被重新加热了其他人的思想，上面贴有主题标签。我们谈论的是原创性，好像它很丰富，但是我们产生的大部分都是混音。 AI没有打破这种幻想。它已经暴露了它。现实情况是，创意工作一直是建立在公式上的。艺术家和作家可能不愿承认这一点，但大部分过程都是重复和惯例。创意的火花是例外。可预测性安慰我们，这就是为什么人们回到熟悉的歌曲和故事的原因。机器在这方面蓬勃发展。它们吸收模式并产生的变化比我们任何人都更快。令人不安的人不是AI可以创造的，而是表明我们自己的作品从来都不是我们所相信的那么独特。这就是为什么中间立场消失的原因。大多数创意专业人士生活的安全空间，足够好，原始，足够不同的空间正在缩小。如果您的作品是为灵感打扮的配方奶粉，那么机器将做得更好。这并不意味着创造力已经死了。这意味着酒吧终于被提高了。因为真正的创造力一直生活在边缘。真正的独创性与自身矛盾，冒险并实现没有人期望的飞跃。机器是混音的大师，但它们不是悖论的主人。他们可以写一首爱情诗，但他们不能再现凌晨2点发出的颤抖，破碎的供词。他们可以发行抗议歌曲，但他们无法体现某人在街上唱歌的人的原始能量，而警方十英尺远。创造力不是抛光的输出。这是凌乱，非理性的，活着的。这就是我们现在面临的事实。如果AI可以复制您的作品，也许它并不像您想象的那么有创造力。如果AI可以复制您的声音，也许您的声音已经是回声。如果AI可以在提示中绘制您的职业生涯，那么您的职业可能是建立在结构上而不是发明的。 AI的愤怒被误导了。我们真正生气的是我们自己平庸的曝光。历史证明了这一点。印刷机使抄写员无关紧要，但强迫作家变得更加清晰，大胆。摄影威胁着画家，直到他们拥抱相机无法做的事情。互联网以平庸的方式淹没了世界，但也引起了人们的声音。每个新工具都会破坏中间，并迫使人类决定它们是真正的原始噪音还是背景噪音。 AI是最新的一轮。 ，这是悖论。人工智能不会使创造力毫无价值。它使其无价。普通的将是自动化的，保险箱将被无休止地复制，但是火花，奇怪，矛盾，不可预测的，将比以往任何时候都更加突出。机器无法杀死它。机器突出显示。他们过滤了世界，并迫使我们证明我们所做的一切是否真正活着。 所以不，AI并没有杀死创造力。它剥去了面具。剩下的问题很简单。您的作品从开始真正创造了？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/small_accountant6083      [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1N2F605/1N2F605/AI_DID_NOT_KILL_KILL_CREATIVEITION_ITS_PREVITION_PREVETIVITY_PREVED_PREVED_WE_BARELY/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n2f605/ai_did_not_kill_creativity_its_proved_we_barely/</guid>
      <pubDate>Thu, 28 Aug 2025 15:20:19 GMT</pubDate>
    </item>
    <item>
      <title>GPT-5优于美国医学许可考试的医生</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n26t3y/gpt5_outperformed_doctors_on_the_us_medical/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  摘要论文中的摘要： ;  &#39;大语言模型（LLMS）的最新进展使通用系统能够执行越来越复杂的域特异性推理，而无需进行广泛的精细调整。在医疗领域，决策通常需要整合异质信息源，包括患者叙事，结构化数据和医学图像。这项研究将GPT-5定位为医学决策支持的通才多模式推理，并系统地评估其在基于文本的问题答案和视觉问题上的Zeroshot链链推理绩效和统一协议下的视觉问题回答任务。我们基于GPT-5，GPT-5-MINI，GPT-5NANO和GPT-4O-2024-11-20对MEDQA，MEDXPERTQA（文本和多模式），MMLU医学亚集，USMLE自我评估考试和VQA-RAD的标准分裂。结果表明，GPT-5始终胜过所有基准，在所有QA基准测试中实现最先进的准确性，并在多模式推理中带来可观的增长。在MEDXPERTQA MM上，GPT-5分别比GPT-4O的推理和理解分别提高了29.26％和 +26.18％，并且在推理中超过预先许可的人类专家，在理解中超过 +29.40％。相反，在大多数维度上，GPT-4O仍然低于人类专家的表现。一项代表性的案例研究表明，GPT-5可以将视觉和文本线索整合到连贯的诊断推理链中，建议进行适当的高风险干预措施。我们的结果表明，在这些受控的多模式推理基准上，GPT-5从人类稳定到上述人类专家的表现移动。这种改进可能会大大为未来的临床决策支持系统设计。我们将代码公开在GPT-5-评估上。  ＆＃32;提交由＆＃32; /u/metaknowing     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n26t3y/gpt5_outperformed_doctors_on_the_us_medical/</guid>
      <pubDate>Thu, 28 Aug 2025 08:37:03 GMT</pubDate>
    </item>
    <item>
      <title>大多数AI初创公司与几年前的NFT/Crypto初创公司相同。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n25ek7/most_ai_startups_are_the_same_bs_as_the_nftcrypto/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   imho并最近阅读所有新闻，大多数与AI相关的公司，产品，初创企业与几年前在NFTS和Crypto中弹出的公司相同，而在Hott hott of the Hott Tobs of the Hott Topcy rn中，请付出了不可思议的收入，付出了一定的投资。现在，您是串行加密/NFT/AI/区块链/IoT企业家。这是可能的，因为这些VC不想坐在现金上，而其中一家初创公司甚至有0.1％成为下一个Uber，Door Dash，Chatgpt的事实，这是值得的。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/user_country_497     [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n25ek7/most_ai_startups_are_the_same_bs_as_the_nftcrypto/</guid>
      <pubDate>Thu, 28 Aug 2025 07:04:27 GMT</pubDate>
    </item>
    </channel>
</rss>