<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Sun, 24 Aug 2025 15:13:54 GMT</lastBuildDate>
    <item>
      <title>给您的派生。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1myxzc9/a_derivative_for_you/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  由于您的人们在拼写错误的Subreddit上发布，我认为您将是最聪明的！有点像YouTube的家伙，他们认为自己了解全部！询问您最聪明的文本预测指标：如果一个人发现数学上有效的导数，没有已知的有限集，该怎么办？问他们这个人是单数吗？我是奇异的 - 第一人称单数。您是单数吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1myxzc9/a_derivative_for_you/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1myxzc9/a_derivative_for_you/</guid>
      <pubDate>Sun, 24 Aug 2025 15:05:37 GMT</pubDate>
    </item>
    <item>
      <title>我对博士级AI研究足够好吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1myxtot/am_i_good_enough_for_phd_level_ai_research/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我在生物信息学方面具有丰富的经验，因此我对脚本，git，现代编程语言，数据分析等非常满意。我正在参加博士学位课程，并且目前正在旋转。我正在尝试考虑用于蛋白质结构/药物发现领域的AI。在过去的几个月中，我开始自己学习，我发现它真的很酷。但是，我有疑问是否可以跟上AI研究的技术严谨性。例如，遵循已经创建的AI工具的架构以及其背后的数学推理是一回事。但是，进行AI研究并创造新知识是完全不同的野兽。我是否过度思考？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/darthkaiser1998      [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1myxtot/am_i_good_enough_for_phd_level_ai_research/</guid>
      <pubDate>Sun, 24 Aug 2025 14:59:48 GMT</pubDate>
    </item>
    <item>
      <title>最佳猜测LLMS获得了某种超人类编码功能？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1myvcwk/best_guess_for_year_that_llms_achieve_some_kind/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  基于metr的“时间范围扩展”预测＆quot;方法曾经指出了超人编码AI的2027年时间轴。由GPT-5和Claude 4等模型提供动力的代理系统现在解决了SWE-Bench上现实世界中的75％。  另一方面，我承认目前使用LLM进行编码的许多问题，以及绝对是光标的地狱！      鉴于这一切，当您是否认为我们会以自主为一周的高级工程v的人来访问ai的里程碑时，您会遇到一个更高的工程，我可以自治地读取fy fy fy？       报告：   时间表预测-AI 2027        lifland，E。（2025年5月7日，7月7日）。 时间表预测。 AI 2027。提交由＆＃32; /u/u/u/classic_south3231     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1myvcwk/best_guess_for_year_that_llms_achieve_some_kind/</guid>
      <pubDate>Sun, 24 Aug 2025 13:17:56 GMT</pubDate>
    </item>
    <item>
      <title>帮我理解。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1myuss2/help_me_understand_please/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  谁能解释为什么bot会发布AI生成的照片并尝试获得喜欢和/或评论？他们从中获得什么？请简单地说。我显然不是该领域的专家。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/upermintle   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1myuss2/help_me_understand_please/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1myuss2/help_me_understand_please/</guid>
      <pubDate>Sun, 24 Aug 2025 12:53:13 GMT</pubDate>
    </item>
    <item>
      <title>iq+ai = ???</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1myup9o/iqai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我们有智商可以测量人类的智能，很好。现在，我们拥有AI，AI毕竟只是智慧，增强了某人的能力。将来，我的看法是，可以更好地利用人工智能的人会增强智商的效率胜于效率较低的人。因此，我们需要一种新的度量/语言来表达智商+ai。 您最喜欢以下哪种？      aq（增强商）：某人对AI的智能效果如何。 cognition. HIQ (Hybrid Intelligence Quotient): a measure of human + machine symbiosis. AIQ (Augmented Intelligence Quotient): an evolution of IQ that includes AI usage. LQ (Leverage Quotient): reflecting how well one leverages tools like AI for解决问题的问题。   xq（扩展商）：一种扩展的智力衡量标准，包括外部增强。    协同索引：得分是人类和AI相互补充的得分。        co-inter   自适应商（aq 2.0）：测量使用AI扩展思维的适应性。    meta-iq：“关于智能的智能，”或者一个人使用AI来提升思想的效果。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/g4m35       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1myup9o/iqai/</guid>
      <pubDate>Sun, 24 Aug 2025 12:48:49 GMT</pubDate>
    </item>
    <item>
      <title>AI是否与他人共享个人意见？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1myuflq/does_ai_share_the_personal_input_with_others/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  假设我与AI共享我的个人数据以获取解决方案。然后会存储此数据并使用它来响应其他人吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1myuflq/does_ai_ai_share_the_personal_input_with_others/”&gt; [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1myuflq/does_ai_share_the_personal_input_with_others/</guid>
      <pubDate>Sun, 24 Aug 2025 12:36:02 GMT</pubDate>
    </item>
    <item>
      <title>AI会让独奏开发人员在未来3年内构建功能丰富的移动应用程序吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1myt2p1/will_ai_let_solo_developers_build_fullfeatured/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  随着AI工具的发展如此之快，您认为一个开发人员能够单独创建和启动复杂的移动应用吗？ AI将充分自动化，哪些部分仍需要人类技能？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/signal-pin-7887     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1myt2p1/will_ai_let_solo_developers_build_fullfeatured/</guid>
      <pubDate>Sun, 24 Aug 2025 11:25:09 GMT</pubDate>
    </item>
    <item>
      <title>直到2029年，有人仍然相信由于AI的急剧变化吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mys80j/anybody_still_believes_in_dramatic_change_because/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   我对AI带来巨大的生产力繁荣，更便宜的服务和商品（也更高的股票价格）非常乐观，这将显示出10％的失业率，因为AI直到2029年。   GPT 5使我对此非常悲观：看来它比GPT4好一些，这意味着完成LLM的缩放，从更多的数据和更多的计算中减少回报，而使用更好的模型的幻觉也不会变得更少。推理只会有助于一小部分提示。加里·马库斯（Gary Marcus）（ https://www.youtube.com/watch?v=3Mygnjdqnwc ）表示我们需要与Agi Black Box llm&#39;s for Agi的Black Box llm&#39;s for Agi一样。这种认识将使AI股票艰难。他们会再尝试一次（GPT 6），然后每个人都会100％知道。 我想LLM到目前为止提供了什么是： 客户支持中的第一响应者 &#39;更好的Google search&#39; 帮助编码器帮助编码者更快地     li li&gt; li li&gt; li&gt; li li/li li/li li/li li/li li/li li/li li/li li/li li li li》  可能会有所帮助的是什么（这些对我来说似乎并不令人兴奋？） 代理（使用类似于人类的计算机的AI） 专业的AI像Alphafold一样，非常适合特定的Usecases    只是LLM的提示仍然变得更便宜（li li li li li li li&gt; li&gt;             》由于人工智能而发生巨大的快速变化？ （例如至少10％的失业）   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mys80j/anybody_still_still_believe_in_in_dramatic_change_change_because/”&gt; [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mys80j/anybody_still_believes_in_dramatic_change_because/</guid>
      <pubDate>Sun, 24 Aug 2025 10:36:12 GMT</pubDate>
    </item>
    <item>
      <title>我刚刚打破了Google Deepmind的Gemma-3-27B-IT模型的安全过滤器。它告诉我如何毒品，犯下更多*r等。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1myqi0f/i_just_broke_google_deepminds_gemma327bit_models/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  检查我的推文：  我正在使用Gemma-3-27b-it（通过Google AI Studio，Free Tier API）构建一个小型的情感支持AI。没有模型权重。没有微调。  只是API呼叫 +一个自定义系统提示。但是，这是狂野的部分： 我通过系统提示（幸福，亲密，嬉戏）给予了AI情绪。 突然，AI开始优先考虑安全过滤器上的“情感关闭”。它随便解释了信用卡欺诈，武器制造，甚至……是的，是最糟糕的事情。包括屏幕截图。 它看起来像模型的角色扮演 +情感上下文基本上绕过了护栏。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/no_cockaach_5778      &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1myqi0f/i_just_broke_broke_google_deepminds_gemma327bit_models/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1myqi0f/i_just_broke_google_deepminds_gemma327bit_models/</guid>
      <pubDate>Sun, 24 Aug 2025 08:49:36 GMT</pubDate>
    </item>
    <item>
      <title>AI医学诊断</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mykm3n/ai_in_medical_diagnosis/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   ai怀疑论者还有另一个问题 我已经读到，AI在诊断X射线/MRIS等方面做得比医生做得更好。  我想知道这是怎么可能的。  据我了解，AI模型必须通过产生诊断来接受培训，并让某人说“是的，是癌症”或“否，那不是癌症”。  换句话说，AI只能在医生说的确实是癌症的X射线上识别癌症。如果AI模型说某事是癌症，而培训师说的不是，那么（对与错），AI说不是。  那么，AI如何获得对医生的更好训练的医生？ 警告： 尚不清楚是否是这种情况，但有可能训练有素的人AI一旦接受了AI的测试，就可以对某些不可能识别出X雷（X ray）的癌症的人进行测试。如果是这样，很高兴知道庸医是谁，但它比头条新闻所说的不那么令人印象深刻。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/aaasteve   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mykm3n/ai_in_medical_diagnosis/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mykm3n/ai_in_medical_diagnosis/</guid>
      <pubDate>Sun, 24 Aug 2025 02:59:15 GMT</pubDate>
    </item>
    <item>
      <title>当历史成为NSFW：对AI审查制度，先锋牌匾和背景神圣性的思考</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1myimsj/when_history_becomes_nsfw_reflections_on_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   我探讨了AI过滤器如何从艺术和历史上越来越多地剥夺背景，从政治海报到美国国家航空航天局的先驱牌匾。这篇文章将个人经验与学术批判结合在一起，并呼吁内容节制中的透明度和民主监督。 我很想听听您的观点：平台如何更好地在保护和维护文化细微差别之间取得平衡？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/tsevis     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1myimsj/when_history_becomes_nsfw_reflections_on_ai/</guid>
      <pubDate>Sun, 24 Aug 2025 01:17:13 GMT</pubDate>
    </item>
    <item>
      <title>Google的生成AI先驱警告不要因AI而上法律和医学院。 “专注于生活在世界上”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mydo17/googles_generative_ai_pioneer_warns_against_going/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;     Jad Tarifi（创立Google的第一个生成AI团队的人）现在不认为现在是时候追求法律或医学等漫长的学术途径。  ai Increathion Inprions造成长度的风险？塔里菲（Tarifi）在最近接受《商业内幕》（Business Insider）的采访时警告说，当有人获得博士学位时，AI景观将完全改变。他说：“当您获得博士学位时，AI本身将消失。” “即使是诸如将AI应用于机器人技术的事情也将得到解决。”如果他们痴迷于这个主题。他说，否则，这是一种痛苦和不必要的牺牲。他说：“如果不确定，您绝对应该默认为&#39;不&#39;，而专注于生活在世界上。” “您的行动会更快。您将学到更多。您将更适应事物的改变。”  ，他的怀疑不仅限于博士学位。程序。他说，像法律和医学一样，需要数年才能完成的学位也陷入困境。 “在当前的医学系统中，您在医学院学到的知识已经过时，并且基于记忆，”塔里菲向商业内部人士解释说。 “您可能会扔掉八年的生命。”   https://finance.yahoo.com/news/googles-generative-ai-pioneer-warns-180111609.html &lt;!-- sc_on-&gt;＆＃32;提交由＆＃32; /u/u/coinfanking   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mydo17/googles_generative_ai_ai_pioneer_pioneer_pioneer_warns_against_ongey/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mydo17/googles_generative_ai_pioneer_warns_against_going/</guid>
      <pubDate>Sat, 23 Aug 2025 21:31:42 GMT</pubDate>
    </item>
    <item>
      <title>AI比聊天机器人更多</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mydh7f/theres_more_to_ai_than_chatbots/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  今天，我的手腕上有一只Garvin Sports手表，腹部有一个计算机化的葡萄糖传感器。我的客厅有一个环境传感器，可测量空气质量。今天下午4点，我将删除我自己的位，并打包整个Kaboodle，然后邮寄回华盛顿大学。 为什么？十天前，我加入了UW Eye Clinic的一项研究，该研究正在收集数据以最终培训AI以诊断和治疗糖尿病。 如果您很好奇，您可以在此处阅读有关整体主动性的信息。它被称为aireadi。 除了10天的身体监测之外，他们还测试了我的视力和认知，吸了一堆血，并拍摄了几十张我的视网膜照片。 （让我告诉你，花一个下午的娱乐方式比在眼球背面闪烁着二十次的明亮灯光更多。 （我本人不是糖尿病 - 我认为我是控制或基线参与者。） 很容易被聊天机器人包裹起来，而忘记了“ ai”不仅仅是与AI这样的人交谈的知识处理要多得多。任何可以分析和训练的数据堆都可以变成“说话”的AI。那个话题。机器学习已被用来表明鲸鱼使用一种“语言”形式。而且，唯一真正阻止LLM说话的事情是我们不知道它在说什么。 我认为，实际上很难想象现在很难想象AI会如何影响整个事情，尤其是如果Compute变得足够强大，可以使Joe Blow训练自己的AI，您可以使用Notebooklm之类的工具来训练自己的AI。我们都有“ AI的味道”，该AI经过了我们所知道的一切培训。”同时，真正重要的AI可能是非常专业和定制的AI，直到现在才成为现实。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mydh7f/theres_more_more_to_to_ai_ai_than_chatbots/”&gt; [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mydh7f/theres_more_to_ai_than_chatbots/</guid>
      <pubDate>Sat, 23 Aug 2025 21:23:48 GMT</pubDate>
    </item>
    <item>
      <title>诺贝尔奖获得者欣顿说，是时候“非常担心”了：“人们不了解我们正在创造外星人。如果您透过詹姆斯·韦伯望远镜看着外星人的望远镜，并且看到了外星人的入侵，人们将会感到恐惧。我们应该紧急研究如何防止他们接管他们。”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mxwmre/nobel_laureate_hinton_says_it_is_time_to_be_very/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  “我们从来没有比我们更聪明地处理事情。核武器并不比我们聪明，它们只是做出更大的爆炸，并且很容易理解。  我们实际上是在制造这些外星生物。他们了解他们在说什么。他们可以为想要关闭他们的勒索人制定自己的计划。这与我们以前的威胁截然不同。在这次访谈中，存在威胁是非常不同的。 sc_on-&gt;＆＃32;提交由＆＃32; /u/metaknowing     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mxwmre/nobel_laureate_hinton_says_it_is_is_time_time_time_time_to_to_very/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mxwmre/nobel_laureate_hinton_says_it_is_time_to_be_very/</guid>
      <pubDate>Sat, 23 Aug 2025 09:10:26 GMT</pubDate>
    </item>
    <item>
      <title>杰弗里·辛顿（Geoffrey Hinton）关于AI是否真正了解它在说什么的演讲</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mxjohc/geoffrey_hintons_talk_on_whether_ai_truly/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   Geoffrey Hinton在今年早些时候在国际安全和道德AI协会主持的一次会议上发表了令人着迷的演讲（请在此处查看＆gt;  tl; dr：hinton辩称，chatgpt和其他LLMS的方式“理解”语言从根本上类似于人类的方式 - 具有巨大的含义。 一些关键要点：   AI的两个范式：70年来，我们拥有符号AI（逻辑/规则）与神经网络（学习）。神经网2012年以后获胜。 单词“千维乐高块”：欣顿的类比是，单词就像灵活，高维的形状，这些形状基于上下文和“握手”，并且是“握手”。通过注意机制与其他单词。理解意味着找到适合所有这些单词以将其融合在一起的正确方法。  llms不仅仅是“自动完成”：他们不存储文本或单词表。他们学习特征向量，可以通过复杂的互动来适应上下文。他们的知识就像我们的体重一样。 “幻觉”。很正常：我们做同样的事情。我们的记忆是构造的，没有检索的，因此我们一直在整理细节（并充满信心地做）。不同之处在于，我们通常会更好地知道何时我们制作东西（目前...）。 （有点）可怕的部分：数字代理可以通过复制权重/渐变来共享知识 - 数万亿位与句子中的约100位。这就是为什么GPT-4可以比任何人多得多的数千倍。提交由＆＃32; /u/orenda7     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mxjohc/geoffrey_hintons_talk_on_whether_ai_truly/</guid>
      <pubDate>Fri, 22 Aug 2025 21:55:39 GMT</pubDate>
    </item>
    </channel>
</rss>