<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Mon, 10 Nov 2025 09:19:34 GMT</lastBuildDate>
    <item>
      <title>有人读过《机器停止运转》吗？您对此有何看法？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ot939c/has_anyone_here_read_the_machine_stops_what_are/</link>
      <description><![CDATA[每个人都生活在地下的牢房里，人们依靠这个遍布全球的超级人工智能来提供一切。   由   提交/u/NAStrahl  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ot939c/has_anyone_here_read_the_machine_stops_what_are/</guid>
      <pubDate>Mon, 10 Nov 2025 09:08:29 GMT</pubDate>
    </item>
    <item>
      <title>通用语言模型的大统一理论：Transformer 架构中的宇宙类比</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ot8qj6/a_grand_unified_theory_of_universal_language/</link>
      <description><![CDATA[我们提出了一个新颖的假设框架，在基于 Transformer 的语言模型和基本宇宙学原理之间建立了深刻的类比。通用语言模型大统一理论（GUT-ULM）认为，变压器架构可以理解为计算宇宙，其中注意力机制充当引力，训练代表时间的前进箭头，令牌从类似于粒子物理学中的量子场的通用语言场（ULF）中出现。我们扩展了这个框架，以通过宇宙加速的视角来解决持续学习问题，提出类似于黑洞的信息奇点的出现，并演示推理参数如何创建计算多元宇宙。这项工作将人工智能、假设物理学和宇宙学联系起来，为模型的可解释性、可扩展性和机器智能的基本性质提供了新的视角。关键词：Transformer 模型、宇宙类比、注意力机制、通用语言场、持续学习、信息奇点、多模态 AI。 notebooklm 链接：https://notebooklm.google.com/notebook/b00bbb76-9473-4141-a29c-6612ecf151d6   由   提交 /u/Sad-Low9265   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ot8qj6/a_grand_unified_theory_of_universal_language/</guid>
      <pubDate>Mon, 10 Nov 2025 08:45:29 GMT</pubDate>
    </item>
    <item>
      <title>生成机器学习的联想中毒</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ot8hk4/associative_poisoning_to_generative_machine/</link>
      <description><![CDATA[生成机器学习的关联中毒 我每天都在寻找和总结有趣的人工智能研究论文，这样你就不必将它们全部浏览一遍。今天的论文标题为“生成机器学习的关联中毒”作者：Mathias Lundteigen Mohus、Jingyue Li 和zhirong Yang。 本文探讨了一种称为“关联中毒”的新型数据中毒技术，该技术被称为“关联中毒”。它允许攻击者操纵生成模型中特定特征对之间的统计关联，而无需控制训练过程。这种方法之所以脱颖而出，是因为它有选择地改变细粒度特征，同时保持生成数据的整体质量。作者提供了攻击的数学公式，并根据经验验证了其在最先进的生成模型上的有效性。 主要发现：  有针对性的统计操纵：关联中毒成功诱导或抑制特定特征对之间的关联，同时保持边缘分布和输出质量，从而逃避典型的检测机制。 形式验证：作者提出了一个理论框架来描述攻击的可行性和隐蔽性，使用互信息和马修斯相关系数作为量化受攻击影响的关联强度的指标。 经验验证：在两个领先的生成模型（Diffusion StyleGAN 和 Denoising Diffusion Probabilistic Models）上进行的测试 - 显示关联中毒成功地修改了特征间的相关性，证明了目标特征之间的互信息和马修斯相关性显着增加。 攻击的隐蔽性：该方法保留了生成样本的质量，如 Fréchet 起始距离 (FID) 指标所示，表明即使在攻击后，输出质量也没有可检测到的损失，使其特别阴险。 防御缺陷：论文发现，当前的防御策略不足以应对关联中毒，这凸显了对新对策的需求，作者在随后的防御策略路线图中提出了新的对策。  这项研究揭示了生成系统中以前未开发的漏洞，该漏洞可能允许恶意行为者巧妙地操纵涉及合成数据集生成、图像合成和自然语言处理的关键应用程序的输出，而不会引起任何人的注意。  您可以在此处查看完整的细分：此处您可以在此处查看完整的原始研究论文：原始论文   由   提交/u/ThePromptIndex  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ot8hk4/associative_poisoning_to_generative_machine/</guid>
      <pubDate>Mon, 10 Nov 2025 08:29:11 GMT</pubDate>
    </item>
    <item>
      <title>玄武</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ot83zh/genmo/</link>
      <description><![CDATA[我已经花了大约一周的时间摆弄这个 AI 所谓的“开源”视频模型 Mochi 1，它感觉更像是一种营销噱头，而不是真正的开放。 当然，权重在 GitHub、Apache 2.0 许可证和所有这些爵士乐上，但来吧。除非您有一个具有 24+ GB VRAM 的 GPU，否则您就无法运行这个野兽。这就像 100 亿个参数。十。十亿。大多数人的电脑在加载它时都会哭泣并死掉。所以，是的，从技术上来说它是开放的，但实际上，只有当你家里有企业级硬件时它才是开放的。 不要让我开始谈论“强烈的及时遵守”的事情。我尝试了一些简单的东西，比如“一个年轻人在雨中走过霓虹灯照亮的街道”。有一次它成功了，另一次却陷入了一些闪烁的噩梦。 “高保真运动”？更像是高保真幻觉。 然后就是他们所谓的游乐场。它基本上是一个有围墙的花园。几代之后你就会受到限制，一半的控制权都在等待名单后面，如果没有帐户，你甚至无法导出高分辨率视频。就像他们在说：“这是开源的！”但真正的东西被锁在他们的 SaaS 付费墙后面。   由   提交 /u/Kooky-Ratio2201   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ot83zh/genmo/</guid>
      <pubDate>Mon, 10 Nov 2025 08:04:13 GMT</pubDate>
    </item>
    <item>
      <title>向开发过涉及人工智能的医疗保健软件的人寻求建议</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ot5vq8/looking_for_advice_from_people_who_have_built/</link>
      <description><![CDATA[大家好， 我即将在医疗保健领域启动一个新项目，其中将涉及大量人工智能工作。这是我第一次从事此类工作，我既兴奋又有点不确定会发生什么。 我之前曾开发过实践管理系统，所以我了解医疗保健软件的基础知识，例如拥有干净的数据和遵守 HIPAA。但我不确定人工智能会让事情变得如何复杂化...我听说，特别是对于医疗保健来说，使用人工智能确实具有挑战性，所以我想问问以前实际做过这件事的人。 您在构建医疗保健人工智能软件时面临的最大挑战是什么？ 我很想听听任何建议、经验教训，或者您希望有人在开始之前告诉您的事情。我想睁大眼睛，尽可能避免常见错误。 TIA 分享您的经验！   由   提交 /u/Inside_Topic5142   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ot5vq8/looking_for_advice_from_people_who_have_built/</guid>
      <pubDate>Mon, 10 Nov 2025 05:46:05 GMT</pubDate>
    </item>
    <item>
      <title>有谁知道如何在谷歌的人工智能概述中获得推荐吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ot4psf/has_anyone_figured_out_how_to_get_featured_in/</link>
      <description><![CDATA[我看到一些品牌在 Google 的 AI 概览结果中被提及。 有人知道什么对结构化数据、主题权威性或新鲜度有帮助吗？ 很想听听是否有人成功获得推荐以及如何获得推荐。   由   提交 /u/Real-Assist1833   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ot4psf/has_anyone_figured_out_how_to_get_featured_in/</guid>
      <pubDate>Mon, 10 Nov 2025 04:40:59 GMT</pubDate>
    </item>
    <item>
      <title>新霍利/华纳法案：要求报告人工智能相关的工作影响</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ot1zry/new_hawleywarner_bill_to_require_reports/</link>
      <description><![CDATA[ https://www.hawley.senate.gov/wp-content/uploads/2025/11/AI-Related-Job-Impacts-Clarity-Act.pdf?ref= humanDevaluationRisk https://broadbandbreakfast.com/senators-introduce-bill-requiring-transparency-on-ai-job-losses/  《人工智能相关就业影响澄清法案》将指示劳工部收集并发布与人工智能自动化相关的裁员、再培训和招聘的季度数据。该法案将适用于上市公司和大型非上市公司以及联邦机构。    由   提交 /u/kaggleqrdl   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ot1zry/new_hawleywarner_bill_to_require_reports/</guid>
      <pubDate>Mon, 10 Nov 2025 02:22:11 GMT</pubDate>
    </item>
    <item>
      <title>人工智能的狗屎派</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ot11jc/the_shit_pie_of_ai/</link>
      <description><![CDATA[当你训练垃​​圾时，模型会学会漂亮地回收它。现在每个输出都像是我的错误。 当你训练一个糟糕的模型时 - 在提供数据集之前验证数据集。  https://www.youtube.com/shorts/VoB6O20ybQI   由   提交 /u/Ok_Blueberry6358   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ot11jc/the_shit_pie_of_ai/</guid>
      <pubDate>Mon, 10 Nov 2025 01:37:07 GMT</pubDate>
    </item>
    <item>
      <title>这感觉像是 ChatGPT 终结的开始还是只有我这么认为？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1osz8lz/does_it_feel_like_the_beginning_of_the_end_of/</link>
      <description><![CDATA[目前已有更好的模型。  更好的模型即将到来 - 感觉 ChatGPT 只是试图让您留在平台上，而不是为您带来最佳答案。  只有我（本周末取消了订阅）现在出于不同原因使用 Gemini、grok、manus、claude 和 kimi。   由   提交 /u/jason_digital   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1osz8lz/does_it_feel_like_the_beginning_of_the_end_of/</guid>
      <pubDate>Mon, 10 Nov 2025 00:12:24 GMT</pubDate>
    </item>
    <item>
      <title>今年你见过的最被低估的人工智能应用是什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1osxuup/whats_the_most_underrated_use_of_ai_youve_seen/</link>
      <description><![CDATA[我对聪明的小东西更感兴趣......悄悄地让生活变得更轻松的个人或本地自动化。 我从事软件开发已有十多年了，最近感觉我们正在淹没在人工智能工具中。    由   提交 /u/Ok_Blueberry6358   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1osxuup/whats_the_most_underrated_use_of_ai_youve_seen/</guid>
      <pubDate>Sun, 09 Nov 2025 23:11:08 GMT</pubDate>
    </item>
    <item>
      <title>人工智能行业正在给发展中国家绝望的承包商带来创伤 - 未来主义</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1osvgqs/the_ai_industry_is_traumatizing_desperate/</link>
      <description><![CDATA[法新社的一份报告强调了人工智能培训如何依赖肯尼亚、哥伦比亚和印度的合同工，他们以极低的工资从事所谓的数据标记工作。这项工作教授人工智能模型如何识别模式并生成有用的输出。例如，如果您希望聊天机器人撰写尸检报告，则必须有人首先手动查看数千张犯罪现场照片，以便模型了解内容的样子。从事这项工作的员工并不直接受雇于 OpenAI 或 Google。他们是通过第三方承包商聘用的，这造成了一层隔离，使责任变得相当模糊。 条件听起来很糟糕。工人们表示，工作时间很长，尽管整天查看暴力或血腥内容，却没有心理健康支持，而且每项任务的工资可能低至一美分。有些任务需要几个小时。一名工人将其与现代奴隶制进行了比较。 Scale AI 是该领域最大的参与者之一。他们与大型科技公司甚至五角大楼合作，但他们通过 Remotasks 等子公司运营，负责处理实际的招聘工作。由于像肯尼亚这样的国家没有关于数据注释工作的法规，因此对这些工人没有太多的法律保护。这类似于社交媒体内容审核在监管最少的情况下外包给发展中国家的方式。人工智能行业需要这些劳动力才能运转，但成本却被推到了选择很少、没有工作场所保护的人们身上。 来源：https://futurism.com/artificial-intelligence/ai-industry-traumatizing-contractors   由   提交/u/theaibusinessdigest  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1osvgqs/the_ai_industry_is_traumatizing_desperate/</guid>
      <pubDate>Sun, 09 Nov 2025 21:33:39 GMT</pubDate>
    </item>
    <item>
      <title>认知主权</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1osmut3/cognitive_sovereignty/</link>
      <description><![CDATA[**“那些可以放弃基本自由来获得一点暂时安全的人既不配获得自由，也不配获得安全。”** ~ 本杰明·富兰克林 1755 我们需要在为时已晚之前谈论认知主权。 现在，有人以“人工智能”的名义大力限制人工智能系统。 “安全”。我明白这种担忧，但我们正在梦游，陷入比我们试图预防的风险更危险的境地。 我的意思是： 合理的担忧：是的，如果人工智能公司的系统积极鼓励自残、提供自杀方法或操纵弱势群体进行破坏性行为，他们就应该承担责任。严格而明确地划清界限。 但问题是：在试图防止这些伤害的过程中，我们将把监管思想本身的权力交给政府。一旦法律要求人工智能公司“为了您的安全”而过滤、限制和控制您可以探索的想法，我们创建了一种极权主义思想控制机制，这会让奥威尔落泪。 我们真正需要的是：法律保护人工智能公司在成年人选择参与具有挑战性的想法时免受责任 - 在知情同意的情况下。弃权系统说：“我理解人工智能可能会提出可能令人不安或挑战我的世界观的想法，我接受这种风险，因为我重视我的认知自由。” 有些人可能会因与人工智能的密切接触而感到困惑，甚至暂时精神错乱。这是一个真正的风险。但我们允许人们在知情同意的情况下跳伞、拳击和服用迷幻药。为什么？因为我们认识到成年人有权用自己的身体和思想去冒险。 风险再高不过了。人工智能正在迅速成为人们探索想法、研究主题和思考问题的主要方式。如果政府有权决定你可以通过人工智能探索哪些想法，那么他们就控制了人类意识本身。不是通过粗暴的审查制度，而是通过围绕你可以提出什么问题以及你可以得到什么答案的无形墙壁。 这与左派与右派无关。这是关于您是否可以决定您脑海中出现哪些想法，或者该决定是否由自认为更了解的人为您做出。 现在就争取认知主权，趁我们还可以。因为一旦它消失了，我们就不会再把它找回来。   由   提交/u/EchotheCosmicFool  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1osmut3/cognitive_sovereignty/</guid>
      <pubDate>Sun, 09 Nov 2025 15:57:15 GMT</pubDate>
    </item>
    <item>
      <title>如果企业把工程师全部换成AI，可能会出什么问题？ - VentureBeat</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1osmdjt/what_could_possibly_go_wrong_if_an_enterprise/</link>
      <description><![CDATA[VentureBeat 发表了一篇文章，介绍了当公司尝试用 AI 编码工具取代其工程团队时会发生什么。标题是讽刺，但文章中的例子是真实且相当残酷的。 有两个案例很突出。首先是来自 SaaStr 的 Jason Lemkin，他在推特上实时分享了他使用 AI 编码代理构建应用程序的经验。大约一周后，人工智能删除了他的生产数据库，尽管他要求它不要这么做。事实证明，他从未将开发环境与生产环境分开，这是任何经验丰富的工程师从第一天起就会建立的。第二个案例是 Tea，这是一款约会应用程序，由于他们在公共互联网上留下了完全不安全的存储桶而遭到黑客攻击。数千张用户照片和 ID 被泄露给 4chan。这些并不是复杂的攻击。它们是适当的工程流程可以捕获的基本安全故障。 人工智能编码工具市场价值 48 亿美元，并且正在快速增长。 OpenAI、Anthropic 和 Meta 的首席执行官都曾公开表示人工智能将取代大部分工程工作。生产力的提升是真实的，研究表明，根据任务的不同，生产力的提高在 8% 到 50% 之间。但本文指出，所有标准软件工程实践（例如版本控制、代码审查、开发与生产分离以及安全扫描）都变得更加重要，而不是更少。人工智能可以比人类更快地生成代码，但如果您没有经验丰富的工程师了解生产系统的实际工作原理以及可能出现的问题，那么这种速度会产生自己的问题。 来源：https://venturebeat.com/ai/what-could-possible-go-wrong-if-an-enterprise-replaces-all-its-engineers   由   提交/u/theaibusinessdigest  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1osmdjt/what_could_possibly_go_wrong_if_an_enterprise/</guid>
      <pubDate>Sun, 09 Nov 2025 15:37:47 GMT</pubDate>
    </item>
    <item>
      <title>人工智能让印度纳税人的生活变成了地狱</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1os9z8u/ai_has_made_life_of_income_tax_payers_a_hell_in/</link>
      <description><![CDATA[以前，处理所得税申报表并获得退款需要 2-4 周的时间。 Infosys 在印度部署了 AI 来处理 IT 申报表，现在人们即使在 5 个月后也无法获得退款，Infosys 表示他们的 AI 支持的 IT 申报表处理可能需要到 2026 年 12 月。 印度政府已经支付了数千千万卢比（1 千万卢比） = 112k 美元）给印孚瑟斯，让人工智能能够处理所得税申报表。 所以我的问题是，除了印孚瑟斯赚了数千千万卢比之外，谁是人工智能炒作的实际受益者。   由   提交/u/msaussieandmrravana   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1os9z8u/ai_has_made_life_of_income_tax_payers_a_hell_in/</guid>
      <pubDate>Sun, 09 Nov 2025 04:26:58 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>