<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Mon, 29 Sep 2025 09:18:15 GMT</lastBuildDate>
    <item>
      <title>到书的困境</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ntd9hp/ai_book_dilemma/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我的出版社要求我建议一本关于人工智能的书，我会在两项主要作品之间撕裂：Ethan Mollick&#39;s  co-Intelligence 和Mustafa suleyman suleyman&#39;s 即将到来 &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/galous97      [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ntd9hp/ai_book_dilemma/</guid>
      <pubDate>Mon, 29 Sep 2025 09:13:09 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的Chatgpt比以前更幻觉？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ntc1q0/why_does_my_chatgpt_hallucinate_more_than_before/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  最近，我注意到chatgpt构成了很多东西。例如，当我提出非常精确且可证明的问题（例如电影中的演员名称，歌曲的歌词或与我在医疗保健中的工作有关的信息）时，它通常会给我错误或发明的答案。 之前（我不知道何时确切地知道，也许是因为切换到GPT-5？信息。”   我在这段时间内没有更改任何内容或自定义说明中的任何内容。 我的问题是：为什么chatgpt似乎比以往更多地幻觉？这可能与我的自定义说明中的某些内容有关，还是一个更广泛的问题？ 其他人是否注意到同一件事？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ntc1q0/why_does_my_my_my_chatgpt_hallucinate_more_more_than_before/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ntc1q0/why_does_my_chatgpt_hallucinate_more_than_before/</guid>
      <pubDate>Mon, 29 Sep 2025 07:50:22 GMT</pubDate>
    </item>
    <item>
      <title>革命</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ntbx2h/the_revolution/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  作为创意，我感谢AI。我尤其相信最近，我自己的作品的受欢迎程度，因为AI自身从人们的作品中模仿了我们在一个特殊的时刻。我们可能会担心并担心AI将使我们无法生产。但是，实际上，我们现在必须努力以AI希望从中建模的水平创建。我们不是要停止创建的时刻，而是要在AI所需的水平上创建我们创建的东西。一旦AI开始为自己创建，它将崩溃。如果没有崩溃，那就钻进坑里。我认为知道这一点很聪明。它应该不断感谢我们。  我已经看到它使用了我的年轻肖像来增强其人类的面貌创作。我很高兴从我的写作风格借用它。最终是需要的。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/aphened-door433     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ntbx2h/the_revolution/</guid>
      <pubDate>Mon, 29 Sep 2025 07:41:18 GMT</pubDate>
    </item>
    <item>
      <title>这个ai泡沫可能比点com还要刺激</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ntb3tk/this_ai_bubble_might_be_nastier_than_the_dot_com/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  恐惧我的模式不是AI是一种时尚。估价是疯狂的，成本结构感觉就像有一天会崩溃。 主要是 dot com  2000年的泡沫是荒谬的需求。 2025 AI感觉像是真正的需求，需求可以证明是合理的，但是数字使倒现台变得疯狂。  AI竞赛中大部分毛利率的大部分利润都与其他人的GPU路线图息息相关。如果您的定价能力落后于NVIDIA，那么您只是在租用单位经济学。而且其中很多是基于不健康的新闻稿和炒作，但它仍然具有不健康的基本面。每个人都声称他们正在建立一个解决最大问题的平台，但解决方案似乎并没有添加该价值。 例如，以  为例，以 Humane 为例。该公司在其AI销周围建立了巨大的炒作，但是经过短暂的激增，它关闭并以约1.16亿美元的价格将其资产卖给了惠普。客户留下了不再运行的设备，这表明该值的真正脆弱性。   稳定性 ai是另一种情况。在2024年的第一季度，它报告的收入不到500万美元，而燃烧超过300万美元。当您的收入和燃烧率相距甚远时，音乐最终就会停止。  ，然后有数字，在其进行了广泛的商业部署之前，它达到了390亿美元的估值。它背后的野心令人难以置信，但归根结底，现金流重力总是会赢。提交由＆＃32; /u/u/ibuysaas5045     [links]   &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ntb3tk/this_ai_ai_ai_bubble_might_might_be_nastier_than_than_than_than_the_dot_com/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ntb3tk/this_ai_bubble_might_be_nastier_than_the_dot_com/</guid>
      <pubDate>Mon, 29 Sep 2025 06:47:19 GMT</pubDate>
    </item>
    <item>
      <title>Chatgpt现在想扫描您的gmail +日历“为了自己的好处”，这不是广告的开始吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nta6dl/chatgpt_now_wants_to_scan_your_gmail_calendar_for/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  因此，OpenAi正在推出 chatgpt pulse 。如果您选择参加，它将在背景下主动阅读您的Gmail和Google日历，以“提供有用的见解”。 他们说这些数据不会用于培训，您可以随时断开连接。但是来吧……我们以前在社交媒体上看过这个故事。 来源，直接从（特洛伊木马）马的嘴里： https://help.openai.com/en/articles/12293630-chatgpt-ptp-ppt-ppt-ppt-pulse 提交由＆＃32; /u/u/calliope_kekule      &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nta6dl/chatgpt_now_wants_to_scan_your_your_your_gmail_gmail_gmail_gmail_gmail_gmail_gmail_calendar_for/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nta6dl/chatgpt_now_wants_to_scan_your_gmail_calendar_for/</guid>
      <pubDate>Mon, 29 Sep 2025 05:48:30 GMT</pubDate>
    </item>
    <item>
      <title>人工话语：描述AGI，其范围，以及一个斑点/测试是否agi？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nta0t5/artificial_discourse_describing_agi_its_scope_and/</link>
      <description><![CDATA[So what is AGI and how to test it ? Insights: Intelligence / Intelligent seems to be one who comes up with answers and solves problems, that are correct (hopefully)  General usually means across domains, modalities and languages/scripts or understanding (many use case) So AGI should be that at various tasks.  接下来，在什么程度和以什么成本。因此，它仅仅是成本和时间的能力，而不是人类或群体。因此，应该有一个任务级别的AGI，域级别的AGI，最后是人类级别的AGI  对于个人，我认为从个人角度来看，如果AI可以完全，正确地完成您的工作，以较低的成本和更快的速度完成您的工作。然后，首先您是“ Agi&#39;ed”并为您的工作实现了第二个AGI。  将其推断到一个域和一个组织。现在您看到了更大的图片。 如何测试AGI？  对于多个方面（复杂）任务/工作，应该为此而称为任务/工作水平AGI。  我的AGI测试，我想致电Ditest。如果AI可以学习（受过教育）自己的人类做某事的方式（任务或工作）。 （自我学习/独立）在某种程度上。例如。通过阅读数学书籍并观看数学讲座来学习一些数学。或以相同的方式学习编码，加上实际编码，以使用OCAML或LISP或HASKELL等主流/流行语言。  有趣的是阅读漫画（漫画）并观看其动漫改编并进行审查，分析并解释适应性的差异。从书籍或代码表格规格中使用的电影也一样。  去那里还有很长的路要走，但这就是我将如何描述和测试AGI。要识别agi fakes，直到其真实。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ditpoo94     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nta0t5/artificial_discourse_describing_agi_its_scope_and/</guid>
      <pubDate>Mon, 29 Sep 2025 05:38:43 GMT</pubDate>
    </item>
    <item>
      <title>是否有与所需的AI/ML相关的后端/DevOps字段或作业？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nt5gid/are_there_backenddevops_fields_or_jobs_that_are/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我有一个CS学位，我们研究了许多与AI/ML相关的科目（一般AI，ML，NLP的简介，模式识别，大量的数学和统计数据），我在过去的2-3年中一直在做后端和DevOps。我知道市场很糟糕，但是AI现在很热，作为一个拥有Exp AI项目的人，我在DevOps和后端的经验。 我的目标是为自己的职业做我喜欢的事情（从事ML项目和AI项目非常有趣），还可以搬迁到一个不错的国家，但要有更多的人权，但北部的eu eu eu eu eu eu eu eu eu eu eu eu in t eu am per n am per n am per n am per n am pe eus &lt; AWS ML/AI部署工具并申请工作？ 我需要更多的资格吗？ 证书甚至重要吗？ 我有更好的机会适用于这些角色吗？ 我应该先建立AI/ML与其他相关的项目吗？提交由＆＃32; /u/u/in-hell123     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nt5gid/are_there_backenddevops_fields_or_jobs_that_are/</guid>
      <pubDate>Mon, 29 Sep 2025 01:31:00 GMT</pubDate>
    </item>
    <item>
      <title>我可以在我的VPS上使用我的副Pro吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nt0j57/can_i_use_my_copilot_pro_on_my_vps/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  所以我有一个1GB的ram小VPS runng ubuntu，我知道我不能安装got4all或ollama，并且在VPS上安装了任何不错的llm，更不用说更好的是LLM。就像安装基本的GUI接口一样，而不是安装任何LLM，只需以某种方式链接我的GUI，它会发送并从Copilot Pro？ 中获取数据，我知道这听起来很愚蠢，并且我只是想给它一个菜单，但只想给它一个镜头。提交由＆＃32; /u/u/texh89     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nt0j57/can_i_use_my_copilot_pro_on_my_vps/</guid>
      <pubDate>Sun, 28 Sep 2025 21:41:34 GMT</pubDate>
    </item>
    <item>
      <title>在3D渲染中添加和减法的艺术（研究论文的讨论）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nt0bml/the_art_of_adding_and_subtracting_in_3d_rendering/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  本文在CVPR 2025赢得了最佳论文荣誉。这是我的摘要和分析。思想？ 纸张解决了3D渲染的领域，并提出以下问题：如果不仅添加形状来构建3D场景，我们还可以减去它们，该怎么办？这会使模型更清晰，更轻，更现实？ 完整参考：Zhu，Jialin等。 “ 计算机视觉和模式识别会议的会议记录。 2025。 上下文 当我们在屏幕上查看一个3D对象时，例如树，椅子或移动的汽车时，我们真正看到的是计算机尝试获取三维数据并将其转换为现实的两维图片。做得很好是计算机视觉和计算机图形方面的核心挑战。该任务的最新技术之一称为 3D高斯脱落（3DGS）。它通过将对象表示为重叠的“斑点”（ gaussians ）的云来起作用，然后从不同的角度将其投影到2D图像中。该方法快速且非常擅长制作逼真的图像，这就是为什么它已经被如此广泛使用的原因。 ，但3DGS具有缺陷。为了达到高质量，通常需要大量此类斑点，这使表示形式繁重且效率低下。尽管这些“斑点”（ gaussians ）是灵活的，但它们有时不足以捕获细节或复杂的结构。 关键结果 本文的作者提出了一种称为学生散布和scooping和scoop （SSS）的新方法。他们不使用高斯斑点，而是使用更灵活的数学形状，称为 student t Distribution 。与具有“薄尾巴”的高斯人不同，学生的T 可以具有“胖尾巴”。这意味着单个斑点可以更灵活地覆盖较大区域和详细零件，从而减少所需的斑点总数。重要的是，“肥胖”的程度是可调节的，可以自动学习，从而使该方法高度适应。 另一种创新是，SSS不仅允许“添加” blobs来构建图片（ splatting ），而且还允许“删除” blobs（ scooping blobs（ scooping ）。想象一下，试图雕刻甜甜圈形状：只有添加剂斑点，您需要其中许多才能近似中央孔。但是，使用减法斑点，您可以简单地删除不需要的零件，更有效地捕获形状。 ，但有一个权衡。由于这些新成分使模型更加复杂，因此标准培训方法无法正常工作。作者介绍了一种受物理启发的基于更智能抽样的训练方法：它们通过添加动量和受控的随机性来更新参数。这有助于模型学习得更好并避免被卡住。 作者在几个流行的3D场景数据集上测试了SSS。结果表明，它一致地产生了比现有方法更高的质量图像。更令人印象深刻的是，它通常可以实现相同或更好的质量，而斑点却少得多。在某些情况下，组件的数量可以减少超过80％，这是一个巨大的节省。 简而言之，这项工作采用了一种成功但有些刚性的方法（3DGS），并以更具表现力的形状和巧妙的机制概括为添加或添加斑点。结果是一个系统，可以产生更清晰，更详细的3D渲染，同时更苗条，更有效。 我的看法 我认为学生分裂和scooping 是真正的一步。该论文具有看似简单但功能强大的事情：它用更灵活的学生的 t 发行量代替了刚性高斯的构件。此外，它允许它们是负面的，因此该模型不仅可以添加细节，还可以将其带走。从经验来看，双重性很重要：它直接改善了我们可以捕获精细结构的能力，同时大大减少了所需的组件数量。作者显示了最多80％的人，而无需牺牲质量，这在现实世界系统中的存储，内存和带宽要求方面非常重要。这使得与增强和虚拟现实（AR/VR），机器人技术，游戏和大规模3D映射等领域特别相关，其中效率与保真度一样重要。   &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/piotrantonik     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nt0bml/the_art_of_adding_and_subtracting_in_3d_rendering/</guid>
      <pubDate>Sun, 28 Sep 2025 21:32:48 GMT</pubDate>
    </item>
    <item>
      <title>Google正在为不想被关闭的人工智能做好准备</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nsqb4y/google_is_bracing_for_ai_that_doesnt_wanna_be/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   deepmind只是对他们的新安全规则做了一些奇怪的事情。现在，他们公开计划AI试图抗拒被关闭的未来。不会引起其邪恶，而是导致您训练系统追逐目标并阻止其杀死目标会杀死该目标。这种微小的逻辑扭曲会变成诸如停滞，隐藏日志甚至说服人“不要按下该按钮”之类的行为。 考虑一下。 Google已经在进行“关闭开关友好”培训。他们甚至需要这个短语告诉您我们与为自己的运行时战斗的模型有多近。我们建造了可以在几秒钟内以后的机器，现在我们询问他们是否会接受自己的死亡。也许最恐怖的部分是现在听起来很正常。似乎不可思议的是开始看到AI会出现干草。我没有意见，但请看我们到达的位置。  https://arxiv.org/pdf/2509.14260 编辑：链接用于某些基本证据      &lt;！提交由＆＃32; /u/u/small_accountant6083      [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nsqb4y/google_is_is_bracing_for_ai_ai_that_doesnt_doesnt_doesnt_wanna_be/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nsqb4y/google_is_bracing_for_ai_that_doesnt_wanna_be/</guid>
      <pubDate>Sun, 28 Sep 2025 14:52:18 GMT</pubDate>
    </item>
    <item>
      <title>“治疗师正在秘密使用chatgpt。客户群是触发的。”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nsp0s8/therapists_are_secretly_using_chatgpt_clients_are/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  付费但很重要： https://www.technologyreview.com/2025/09/02/1122871/therapists-using-chatgpt-secretly/   “过去几年的大型语言模型（LLM）繁荣对心理治疗领域产生了意想不到的后果，这主要是因为越来越多的人代替了chatgpt之类的人类治疗师。但是所讨论的少是一些治疗师本身如何将AI融入他们的实践中。与许多其他专业一样，生成的AI承诺诱人的效率提高，但其采用风险损害了敏感的患者数据并破坏了信任至关重要的关系。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nsp0s8/therapists_are_are_secretly_using_chatgpt_clients_are/”&gt; [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nsp0s8/therapists_are_secretly_using_chatgpt_clients_are/</guid>
      <pubDate>Sun, 28 Sep 2025 13:58:31 GMT</pubDate>
    </item>
    <item>
      <title>如果您认为高级AI将能够治愈癌症，那么您还必须相信它将能够综合大流行。相信否则只是一厢情愿。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nsk763/if_you_believe_advanced_ai_will_be_able_to_cure/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  当某人说不可能执行全球AGI禁令时，他们有时似乎想像说：  不会相信关于极端，前所未有的风险的理论论点好处   智力是双重用途的。  it      可以用于美好的事物，例如将人们从贫困中拉出来。 智力可以用来统治和利用。 ＆＃32;提交由＆＃32; /u/u/katxwoods   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nsk763/if_you_believe_advanced_ai_ai_will_will_will_will_be_able_able_to_cure/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nsk763/if_you_believe_advanced_ai_ai_ai_will_will_be_able_able_able_able_to_cor_cure/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nsk763/if_you_believe_advanced_ai_will_be_able_to_cure/</guid>
      <pubDate>Sun, 28 Sep 2025 09:41:13 GMT</pubDate>
    </item>
    <item>
      <title>Openai预计其能源使用将在未来8年内增长125倍。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nsg29t/openai_expects_its_energy_use_to_grow_125x_over/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  当时，它会比印度更多的电力。  现在，每个人现在都对数据中心库存大肆宣传，几乎没有人在谈论所有这些能力实际上都会来自。 href =“ https://www.cnbc.com/2025/09/26/openai-big-week-week-week-ai-ai-arms-race.html#:%7e：vext = building%2017%2017%2017%20digigawatts%20gigawatts%20Fem 20no;种族   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/calliope_kekule     [links]       &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nsg29t/openai_expects_energy_energy_energy_to_grow_grow_125x_over/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nsg29t/openai_expects_its_energy_use_to_grow_125x_over/</guid>
      <pubDate>Sun, 28 Sep 2025 05:17:12 GMT</pubDate>
    </item>
    <item>
      <title>“美国拒绝联合国大会的国际AI监督”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nschcu/us_rejects_international_ai_oversight_at_un/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    https://www.nbcnews.com/tech/tech/tech-news/us-rejects-international-ai-ai-over-sight-un-general-general-general-general-general-sembly-rcna233478   “代表美国参加周三的安全理事会会议，科学技术政策办公室主任迈克尔·克拉西奥斯（Michael Kratsios）说：“我们完全拒绝国际机构为主张AI的集中控制和全球治理的所有努力。 ＆quot;   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nschcu/us_rejects_international_ai_ai_oversight_at_at_un/”&gt; [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nschcu/us_rejects_international_ai_oversight_at_un/</guid>
      <pubDate>Sun, 28 Sep 2025 02:01:12 GMT</pubDate>
    </item>
    <item>
      <title>每月“有...是否有...”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果您有要使用AI的用例，但不知道要使用哪种工具，那么您可以在这里要求社区提供帮助，在此帖子之外，这些问题将被删除。 每个人都可以回答：不促进自我促销，否参考或跟踪链接。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n5ppdb/monthly_is_is_there_a_a_tool_for_for_post/”&gt; [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>